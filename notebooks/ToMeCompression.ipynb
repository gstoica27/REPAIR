{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a9fd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam, lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sys import platform\n",
    "\n",
    "DEVICE = 'mps' if platform == 'darwin' else 'cuda'\n",
    "if DEVICE == 'mps':\n",
    "    DOWNLOAD_PATH = '/Users/georgestoica/Downloads' \n",
    "else:\n",
    "    DOWNLOAD_PATH = '/srv/share/gstoica3/checkpoints/REPAIR/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceea2c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, i):\n",
    "    sd = model.state_dict()\n",
    "    path = os.path.join(\n",
    "        DOWNLOAD_PATH,\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def load_model(model, i):\n",
    "    path = os.path.join(\n",
    "        DOWNLOAD_PATH,\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    sd = torch.load(path, map_location=torch.device(DEVICE))\n",
    "    model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3fde862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CIFAR_MEAN = [125.307, 122.961, 113.8575]\n",
    "CIFAR_STD = [51.5865, 50.847, 51.255]\n",
    "normalize = T.Normalize(np.array(CIFAR_MEAN)/255, np.array(CIFAR_STD)/255)\n",
    "denormalize = T.Normalize(-np.array(CIFAR_MEAN)/np.array(CIFAR_STD), 255/np.array(CIFAR_STD))\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "train_dset = torchvision.datasets.CIFAR10(root='/tmp', train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "test_dset = torchvision.datasets.CIFAR10(root='/tmp', train=False,\n",
    "                                        download=True, transform=test_transform)\n",
    "\n",
    "train_aug_loader = torch.utils.data.DataLoader(train_dset, batch_size=500, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=500, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "470fa4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "#             self.shortcut = LambdaLayer(lambda x:\n",
    "#                                         F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, w=1, num_classes=10, text_head=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = w*16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, w*16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(w*16)\n",
    "        self.layer1 = self._make_layer(block, w*16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, w*32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, w*64, num_blocks[2], stride=2)\n",
    "        if text_head:\n",
    "            num_classes = 512\n",
    "        self.linear = nn.Linear(w*64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def resnet20(w=1, text_head=False):\n",
    "    return ResNet(BasicBlock, [3, 3, 3], w=w, text_head=text_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d3580e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates accuracy\n",
    "def evaluate(model, loader=test_loader, return_confusion=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    confusion_matrix = np.zeros((10, 10))\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs.to(DEVICE))\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            correct += (labels.to(DEVICE) == pred).sum().item()\n",
    "            confusion_matrix[labels.cpu().numpy(), pred.cpu().numpy()] += 1\n",
    "    confusion_matrix /= confusion_matrix.sum(-1, keepdims=True)\n",
    "    if return_confusion:\n",
    "        return correct, confusion_matrix\n",
    "    else:\n",
    "        return correct\n",
    "\n",
    "# evaluates loss\n",
    "def evaluate1(model, loader=test_loader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs.to(DEVICE))\n",
    "            loss = F.cross_entropy(outputs, labels.to(DEVICE))\n",
    "            losses.append(loss.item())\n",
    "    return np.array(losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "946c2344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifies the weight matrices of a convolution and batchnorm\n",
    "# layer given a permutation of the output channels\n",
    "def permute_output(perm_map, conv, bn):\n",
    "    pre_weights = [\n",
    "        conv.weight,\n",
    "        bn.weight,\n",
    "        bn.bias,\n",
    "        bn.running_mean,\n",
    "        bn.running_var,\n",
    "    ]\n",
    "    for w in pre_weights:\n",
    "        if len(w.shape) == 4:\n",
    "            transform = torch.einsum('ab,bcde->acde', perm_map, w)\n",
    "        elif len(w.shape) == 2:\n",
    "            transform = perm_map @ w\n",
    "        else:\n",
    "            transform = w @ perm_map.t()\n",
    "#         assert torch.allclose(w[perm_map.argmax(-1)], transform)\n",
    "        w.data = transform\n",
    "#         w.data = w[perm_map]\n",
    "\n",
    "# modifies the weight matrix of a convolution layer for a given\n",
    "# permutation of the input channels\n",
    "def permute_input(perm_map, after_convs):\n",
    "    if not isinstance(after_convs, list):\n",
    "        after_convs = [after_convs]\n",
    "    post_weights = [c.weight for c in after_convs]\n",
    "    for w in post_weights:\n",
    "        if len(w.shape) == 4:\n",
    "            transform = torch.einsum('abcd,be->aecd', w, perm_map.t())\n",
    "        elif len(w.shape) == 2:\n",
    "            transform = w @ perm_map.t()\n",
    "    #     assert torch.allclose(w[:, perm_map.argmax(-1)], transform)\n",
    "        w.data = transform\n",
    "#         w.data = w[:, perm_map, :, :]\n",
    "\n",
    "def permute_cls_output(perm_map, linear):\n",
    "    for w in [linear.weight, linear.bias]:\n",
    "        w.data = perm_map @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5694238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the train loader with data augmentation as this gives better results\n",
    "def reset_bn_stats(model, epochs=1, loader=train_aug_loader):\n",
    "    # resetting stats to baseline first as below is necessary for stability\n",
    "    for m in model.modules():\n",
    "        if type(m) == nn.BatchNorm2d:\n",
    "            m.momentum = None # use simple average\n",
    "            m.reset_running_stats()\n",
    "    # run a single train epoch with augmentations to recalc stats\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        with torch.no_grad(), autocast():\n",
    "            for images, _ in loader:\n",
    "                output = model(images.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "ea480286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nothing(x, mode=\"mean\"):\n",
    "    return x\n",
    "\n",
    "def bipartite_soft_matching(\n",
    "    metric: torch.Tensor,\n",
    "    r: float,\n",
    "    class_token: bool = False,\n",
    "    distill_token: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Applies ToMe with a balanced matching set (50%, 50%).\n",
    "    Input size is [batch, tokens, channels].\n",
    "    r indicates the ratio of tokens to remove (max 50% of tokens).\n",
    "    Extra args:\n",
    "     - class_token: Whether or not there's a class token.\n",
    "     - distill_token: Whether or not there's also a distillation token.\n",
    "    When enabled, the class token and distillation tokens won't get merged.\n",
    "    \"\"\"\n",
    "    protected = 0\n",
    "    if class_token:\n",
    "        protected += 1\n",
    "    if distill_token:\n",
    "        protected += 1\n",
    "\n",
    "    # We can only reduce by a maximum of 50% tokens\n",
    "    t = metric.shape[1]\n",
    "    r = int(r * t)\n",
    "    r = min(r, (t - protected) // 2)\n",
    "\n",
    "    if r <= 0:\n",
    "        return do_nothing, do_nothing\n",
    "\n",
    "    with torch.no_grad():\n",
    "        metric = metric / metric.norm(dim=-1, keepdim=True)\n",
    "        a, b = metric[..., ::2, :], metric[..., 1::2, :]\n",
    "        scores = a @ b.transpose(-1, -2)\n",
    "        \n",
    "#         scores = torch.cov(torch.cat([a, b], dim=1)[0])[None, :r, r:t]\n",
    "#         scores = -torch.cdist(a, b)\n",
    "\n",
    "        if class_token:\n",
    "            scores[..., 0, :] = -math.inf\n",
    "        if distill_token:\n",
    "            scores[..., :, 0] = -math.inf\n",
    "\n",
    "        node_max, node_idx = scores.max(dim=-1)\n",
    "        edge_idx = node_max.argsort(dim=-1, descending=True)[..., None]\n",
    "\n",
    "        unm_idx = edge_idx[..., r:, :]  # Unmerged Tokens\n",
    "        src_idx = edge_idx[..., :r, :]  # Merged Tokens\n",
    "        dst_idx = node_idx[..., None].gather(dim=-2, index=src_idx)\n",
    "\n",
    "        if class_token:\n",
    "            # Sort to ensure the class token is at the start\n",
    "            unm_idx = unm_idx.sort(dim=1)[0]\n",
    "\n",
    "    def merge(x: torch.Tensor, mode=\"mean\") -> torch.Tensor:\n",
    "        src, dst = x[..., ::2, :], x[..., 1::2, :]\n",
    "        n, t1, c = src.shape\n",
    "        unm = src.gather(dim=-2, index=unm_idx.expand(n, t1 - r, c))\n",
    "        src = src.gather(dim=-2, index=src_idx.expand(n, r, c))\n",
    "        dst = dst.scatter_reduce(-2, dst_idx.expand(n, r, c), src, reduce=mode)\n",
    "\n",
    "        if distill_token:\n",
    "            return torch.cat([unm[:, :1], dst[:, :1], unm[:, 1:], dst[:, 1:]], dim=1)\n",
    "        else:\n",
    "            return torch.cat([unm, dst], dim=1)\n",
    "\n",
    "    def unmerge(x: torch.Tensor) -> torch.Tensor:\n",
    "        unm_len = unm_idx.shape[1]\n",
    "        unm, dst = x[..., :unm_len, :], x[..., unm_len:, :]\n",
    "        n, _, c = unm.shape\n",
    "\n",
    "        src = dst.gather(dim=-2, index=dst_idx.expand(n, r, c))\n",
    "\n",
    "        out = torch.zeros(n, metric.shape[1], c, device=x.device, dtype=x.dtype)\n",
    "\n",
    "        out[..., 1::2, :] = dst\n",
    "        out.scatter_(dim=-2, index=(2 * unm_idx).expand(n, unm_len, c), src=unm)\n",
    "        out.scatter_(dim=-2, index=(2 * src_idx).expand(n, r, c), src=src)\n",
    "\n",
    "        return out\n",
    "\n",
    "    return merge, unmerge\n",
    "\n",
    "def permutation_matching(metric, r):\n",
    "    with torch.no_grad():\n",
    "        metric = metric / metric.norm(dim=-1, keepdim=True)\n",
    "        a, b = metric[..., ::2, :], metric[..., 1::2, :]\n",
    "        scores = -(a @ b.transpose(-1, -2))\n",
    "#     pdb.set_trace()\n",
    "    row_ind, col_ind = scipy.optimize.linear_sum_assignment(scores[0].cpu().numpy().T)\n",
    "    row_ind = torch.from_numpy(col_ind)[None, :, None].to(metric.device)\n",
    "    \n",
    "#     print(row_ind, col_ind)\n",
    "    \n",
    "    def merge(x: torch.Tensor, mode=\"mean\") -> torch.Tensor:\n",
    "        src, dst = x[..., ::2, :], x[..., 1::2, :]\n",
    "        n, t1, c = src.shape\n",
    "        \n",
    "        src = src.gather(dim=-2, index=row_ind.expand(n, t1, c))\n",
    "        \n",
    "        if mode == \"sum\":\n",
    "            return dst + src\n",
    "        elif mode == \"mean\":\n",
    "            return (dst + src) / 2\n",
    "        else:\n",
    "            return 1 / 0\n",
    "    \n",
    "    def unmerge(x):\n",
    "        n, r, c = x.shape\n",
    "        out = torch.zeros(n, metric.shape[1], c, device=x.device, dtype=x.dtype)\n",
    "\n",
    "        out[..., 1::2, :] = x\n",
    "        out.scatter_(dim=-2, index=(2 * row_ind).expand(n, r, c), src=x)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    return merge, unmerge\n",
    "\n",
    "# bipartite_soft_matching = permutation_matching\n",
    "\n",
    "def svd_matching(metric, r):\n",
    "    U, S, V = torch.svd(metric[0])\n",
    "    return U[None, :, :r], (S @ V.T)[None, :r, :]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90ad3025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9536, 9510)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modela = resnet20(w=4).to(DEVICE)\n",
    "modelb = resnet20(w=4).to(DEVICE)\n",
    "load_model(modela, 'resnet20x4_v1')\n",
    "load_model(modelb, 'resnet20x4_v2')\n",
    "\n",
    "evaluate(modela), evaluate(modelb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "51a107fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_param_suffix(name):\n",
    "    return name.replace('.weight', '').replace('.bias', '')\n",
    "\n",
    "def naively_compress_model(model, ratio):\n",
    "    new_sd = {}\n",
    "    for key, val in model.state_dict().items():\n",
    "        shape = val.shape\n",
    "        if len(shape) == 4:\n",
    "            val = val.flatten(2).permute(2, 0, 1)\n",
    "            merge, unmerge = bipartite_soft_matching(val, r=ratio)\n",
    "            val = unmerge(merge(val))\n",
    "            if not key.startswith('conv1'):\n",
    "                val = val.transpose(2, 1)\n",
    "                merge, unmerge = bipartite_soft_matching(val, r=ratio)\n",
    "                val = unmerge(merge(val)).transpose(2, 1)\n",
    "            val = val.permute(1, 2, 0).reshape(*shape)\n",
    "        elif len(shape) == 2:\n",
    "            val = val[None]\n",
    "            merge, unmerge = bipartite_soft_matching(val, r=0)\n",
    "            val = unmerge(merge(val)).transpose(2, 1)\n",
    "            merge, unmerge = bipartite_soft_matching(val, r=ratio)\n",
    "            val = unmerge(merge(val)).transpose(2, 1)[0]\n",
    "        elif len(shape) == 1:\n",
    "            val = val[None, :, None]\n",
    "            merge, unmerge = bipartite_soft_matching(val, r=ratio)\n",
    "            val = unmerge(merge(val))[0, :, 0]\n",
    "        new_sd[key] = val\n",
    "    return new_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1be29ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcomp_sd = naively_compress_model(modela, ratio=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "9ff436e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7344"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelc = resnet20(w=4).to(DEVICE)\n",
    "modelc.load_state_dict(modelcomp_sd)\n",
    "reset_bn_stats(modelc)\n",
    "evaluate(modelc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78007d40",
   "metadata": {},
   "source": [
    "## Naive just merge into B without changing inputs:\n",
    "the strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "5b3a6c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8834"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = {}\n",
    "\n",
    "def interleave_vals(tensor1, tensor2):\n",
    "    # Assume tensor is of shape [B,H,D]\n",
    "    return torch.cat((tensor1.unsqueeze(2), tensor2.unsqueeze(2)), dim=2).flatten(1, 2)\n",
    "#     return torch.cat((tensor1, tensor2), dim=1)\n",
    "\n",
    "def prep_conv(weight):\n",
    "    return weight.flatten(1)[None, ...]\n",
    "\n",
    "def unprep_conv(weight, k=3):\n",
    "    weight = weight[0]\n",
    "    o, *_ = weight.shape\n",
    "    return weight.reshape(o, -1, k, k)\n",
    "\n",
    "def merge_conv(state_dict, prefix, a_conv, b_conv, in_merge=None, out_merge=None):\n",
    "    a_c1 = prep_conv(a_conv.weight)\n",
    "    b_c1 = prep_conv(b_conv.weight)\n",
    "    \n",
    "    c_c1 = interleave_vals(a_c1, b_c1)\n",
    "    c1_merge, _ = bipartite_soft_matching(c_c1, r=0.5)\n",
    "    \n",
    "    if out_merge is not None:\n",
    "        c1_merge = out_merge\n",
    "    \n",
    "    c_c1 = unprep_conv(c1_merge(c_c1))\n",
    "    \n",
    "    state_dict[prefix + \".weight\"] = c_c1\n",
    "    \n",
    "    return c1_merge\n",
    "\n",
    "def merge_bn(state_dict, prefix, a_bn, b_bn, merge):\n",
    "    # weight, bias, running_mean, running_var\n",
    "    \n",
    "    a_stats = torch.stack([a_bn.weight, a_bn.bias, a_bn.running_mean], dim=1)[None, ...]\n",
    "    b_stats = torch.stack([b_bn.weight, b_bn.bias, b_bn.running_mean], dim=1)[None, ...]\n",
    "    \n",
    "    c_stats = interleave_vals(a_stats, b_stats)\n",
    "    c_stats = merge(c_stats)[0]\n",
    "    \n",
    "    c_weight, c_bias, c_mean = c_stats.unbind(dim=-1)\n",
    "    \n",
    "    c_var = interleave_vals(a_bn.running_var[None, :, None], b_bn.running_var[None, :, None])\n",
    "    \n",
    "    ones = c_var * 0 + 1\n",
    "    c_denom = merge(ones, mode=\"sum\")\n",
    "    c_var = merge(c_var, mode=\"sum\")\n",
    "    c_var = c_var / (c_denom ** 2)\n",
    "    c_var = c_var[0, :, 0]\n",
    "    \n",
    "    state_dict[prefix + \".weight\"] = c_weight\n",
    "    state_dict[prefix + \".bias\"] = c_bias\n",
    "    state_dict[prefix + \".running_mean\"] = c_mean\n",
    "    state_dict[prefix + \".running_var\"] = c_var\n",
    "\n",
    "def merge_block(state_dict, prefix, a, b, in_merge):\n",
    "    c1_merge = merge_conv(state_dict, prefix + \".conv1\", a.conv1, b.conv1, in_merge)\n",
    "    merge_bn(state_dict, prefix + \".bn1\", a.bn1, b.bn1, c1_merge)\n",
    "    c2_merge = merge_conv(state_dict, prefix + \".conv2\", a.conv2, b.conv2, c1_merge, out_merge=in_merge)\n",
    "    merge_bn(state_dict, prefix + \".bn2\", a.bn2, b.bn2, c2_merge)\n",
    "    \n",
    "def merge_block_shortcut(state_dict, prefix, a, b, in_merge):\n",
    "    c1_merge = merge_conv(state_dict, prefix + \".conv1\", a.conv1, b.conv1, in_merge)\n",
    "    merge_bn(state_dict, prefix + \".bn1\", a.bn1, b.bn1, c1_merge)\n",
    "    c2_merge = merge_conv(state_dict, prefix + \".conv2\", a.conv2, b.conv2, c1_merge)\n",
    "    merge_bn(state_dict, prefix + \".bn2\", a.bn2, b.bn2, c2_merge)\n",
    "    \n",
    "    s_merge = merge_conv(state_dict, prefix + \".shortcut.0\", a.shortcut[0], b.shortcut[0], in_merge, out_merge=c2_merge)\n",
    "    merge_bn(state_dict, prefix + \".shortcut.1\", a.shortcut[1], b.shortcut[1], s_merge)\n",
    "    return s_merge\n",
    "\n",
    "def merge_resnet20(state_dict, a, b):\n",
    "    conv1_merge = merge_conv(state_dict, \"conv1\", a.conv1, b.conv1, None)\n",
    "    merge_bn(state_dict, \"bn1\", a.bn1, b.bn1, conv1_merge)\n",
    "    \n",
    "    for i in range(3):\n",
    "        merge_block(state_dict, f\"layer1.{i}\", a.layer1[i], b.layer1[i], conv1_merge)\n",
    "    \n",
    "    conv1_merge = merge_block_shortcut(state_dict, \"layer2.0\", a.layer2[0], b.layer2[0], conv1_merge)\n",
    "    for i in range(1, 3):\n",
    "        merge_block(state_dict, f\"layer2.{i}\", a.layer2[i], b.layer2[i], conv1_merge)\n",
    "        \n",
    "    conv1_merge = merge_block_shortcut(state_dict, \"layer3.0\", a.layer3[0], b.layer3[0], conv1_merge)\n",
    "    for i in range(1, 3):\n",
    "        merge_block(state_dict, f\"layer3.{i}\", a.layer3[i], b.layer3[i], conv1_merge)\n",
    "\n",
    "#     c_linear = interleave_vals(a.linear.weight.mT[None, ...], b.linear.weight.mT[None, ...])\n",
    "#     c_linear = conv1_merge(c_linear)[0].mT\n",
    "#     state_dict[\"linear.weight\"] = c_linear\n",
    "    state_dict[\"linear.weight\"] = b.linear.weight # (a.linear.weight + b.linear.weight) / 2\n",
    "    state_dict[\"linear.bias\"] = b.linear.bias # (a.linear.bias + b.linear.bias) / 2\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "def stoopid_dumb(state_dict, a, b):\n",
    "    for (k, v1), (_, v2) in zip(a.named_parameters(), b.named_parameters()):\n",
    "        state_dict[k] = (v1 + v2) / 2\n",
    "    for (k, v1), (_, v2) in zip(a.named_buffers(), b.named_buffers()):\n",
    "        state_dict[k] = (v1 + v2) / 2\n",
    "\n",
    "\n",
    "state_dict = {}\n",
    "modelc = resnet20(w=4).to(DEVICE)\n",
    "merge_resnet20(state_dict, modela, modelb)\n",
    "# stoopid_dumb(state_dict, modela, modelb)\n",
    "modelc.load_state_dict(state_dict)\n",
    "reset_bn_stats(modelc)\n",
    "evaluate(modelc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b910e",
   "metadata": {},
   "source": [
    "## Merge Inputs and Outputs\n",
    "don't think just do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "57c18215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4028"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = {}\n",
    "\n",
    "def interleave_vals(tensor1, tensor2, dim=1):\n",
    "    # Assume tensor is of shape [B,H,D]\n",
    "    return torch.cat((tensor1.unsqueeze(dim+1), tensor2.unsqueeze(dim+1)), dim=dim+1).flatten(dim, dim+1)\n",
    "#     return torch.cat((tensor1, tensor2), dim=dim)\n",
    "\n",
    "\n",
    "def merge_inconv(state_dict, prefix, a_conv, b_conv):\n",
    "    a_c1 = prep_conv(a_conv.weight)\n",
    "    b_c1 = prep_conv(b_conv.weight)\n",
    "    \n",
    "    c_c1 = interleave_vals(a_c1, b_c1)\n",
    "    c1_merge, _ = bipartite_soft_matching(c_c1, r=0.5)\n",
    "    \n",
    "    c_c1 = unprep_conv(c1_merge(c_c1))\n",
    "    \n",
    "    state_dict[prefix + \".weight\"] = c_c1\n",
    "    \n",
    "    return c1_merge\n",
    "\n",
    "def merge_conv(state_dict, prefix, a_conv, b_conv, in_merge, out_merge=None, eps=1e-7):\n",
    "    def move_kernel_to_output(x): # [out, in, h, w]\n",
    "        return x.transpose(0, 1).flatten(1)[None, ...] # output: [1, in, w*h*out]\n",
    "    \n",
    "    out, _in, k, _ = a_conv.weight.shape\n",
    "    \n",
    "    a_c1 = move_kernel_to_output(a_conv.weight)\n",
    "    b_c1 = move_kernel_to_output(b_conv.weight)\n",
    "    \n",
    "    ones = torch.ones_like(a_c1)\n",
    "    zeros = torch.zeros_like(a_c1)\n",
    "    \n",
    "    big_boy = torch.cat([interleave_vals(a_c1, zeros), interleave_vals(zeros, b_c1)], dim=-1)\n",
    "    counter = torch.cat([interleave_vals(ones, zeros), interleave_vals(zeros, ones)], dim=-1)\n",
    "    \n",
    "    merged_boy = in_merge(big_boy, mode=\"sum\")\n",
    "    counter = in_merge(counter, mode=\"sum\")\n",
    "    \n",
    "    a_boy, b_boy = merged_boy.view(1, counter.shape[1], 2, -1).unbind(-2)\n",
    "    a_count, b_count = counter.view(1, counter.shape[1], 2, -1).unbind(-2)\n",
    "    \n",
    "    def move_kernel_to_input(x):\n",
    "        return x.transpose(1, 2).reshape(1, -1, k*k*x.shape[1]) # [1, out, h*w*in]\n",
    "    \n",
    "    c_boy = interleave_vals(move_kernel_to_input(a_boy), move_kernel_to_input(b_boy))\n",
    "    c_count = interleave_vals(move_kernel_to_input(a_count), move_kernel_to_input(b_count))\n",
    "    \n",
    "    c_boy = c_boy / (c_count + eps)\n",
    "    \n",
    "    \n",
    "    if out_merge is None:\n",
    "        out_merge, _ = bipartite_soft_matching(c_boy, r=0.5)\n",
    "    \n",
    "    c_boy = out_merge(c_boy, mode=\"sum\")\n",
    "    c_count = out_merge((c_count > eps).float(), mode=\"sum\")\n",
    "#     c_count = out_merge(c_count, mode=\"sum\")\n",
    "    \n",
    "    c_boy = c_boy / (c_count + eps)\n",
    "    \n",
    "    \n",
    "    c_boy = c_boy.reshape(1, out, k, k, _in)[0].permute(0, 3, 1, 2)\n",
    "    \n",
    "    state_dict[prefix + \".weight\"] = c_boy\n",
    "    return out_merge\n",
    "\n",
    "def merge_bn(state_dict, prefix, a_bn, b_bn, merge):\n",
    "    # weight, bias, running_mean, running_var\n",
    "    \n",
    "    a_stats = torch.stack([a_bn.weight, a_bn.bias, a_bn.running_mean], dim=1)[None, ...]\n",
    "    b_stats = torch.stack([b_bn.weight, b_bn.bias, b_bn.running_mean], dim=1)[None, ...]\n",
    "    \n",
    "    c_stats = interleave_vals(a_stats, b_stats)\n",
    "    c_stats = merge(c_stats)[0]\n",
    "    \n",
    "    c_weight, c_bias, c_mean = c_stats.unbind(dim=-1)\n",
    "    \n",
    "    c_var = interleave_vals(a_bn.running_var[None, :, None], b_bn.running_var[None, :, None])\n",
    "    \n",
    "    ones = c_var * 0 + 1\n",
    "    c_denom = merge(ones, mode=\"sum\")\n",
    "    c_var = merge(c_var, mode=\"sum\")\n",
    "    c_var = c_var / (c_denom ** 2)\n",
    "    c_var = c_var[0, :, 0]\n",
    "    \n",
    "    state_dict[prefix + \".weight\"] = c_weight\n",
    "    state_dict[prefix + \".bias\"] = c_bias\n",
    "    state_dict[prefix + \".running_mean\"] = c_mean\n",
    "    state_dict[prefix + \".running_var\"] = c_var\n",
    "\n",
    "def merge_block(state_dict, prefix, a, b, in_merge):\n",
    "    c1_merge = merge_conv(state_dict, prefix + \".conv1\", a.conv1, b.conv1, in_merge)\n",
    "    merge_bn(state_dict, prefix + \".bn1\", a.bn1, b.bn1, c1_merge)\n",
    "    c2_merge = merge_conv(state_dict, prefix + \".conv2\", a.conv2, b.conv2, c1_merge, out_merge=in_merge)\n",
    "    merge_bn(state_dict, prefix + \".bn2\", a.bn2, b.bn2, c2_merge)\n",
    "    \n",
    "def merge_block_shortcut(state_dict, prefix, a, b, in_merge):\n",
    "    c1_merge = merge_conv(state_dict, prefix + \".conv1\", a.conv1, b.conv1, in_merge)\n",
    "    merge_bn(state_dict, prefix + \".bn1\", a.bn1, b.bn1, c1_merge)\n",
    "    c2_merge = merge_conv(state_dict, prefix + \".conv2\", a.conv2, b.conv2, c1_merge)\n",
    "    merge_bn(state_dict, prefix + \".bn2\", a.bn2, b.bn2, c2_merge)\n",
    "    \n",
    "    s_merge = merge_conv(state_dict, prefix + \".shortcut.0\", a.shortcut[0], b.shortcut[0], in_merge, out_merge=c2_merge)\n",
    "    merge_bn(state_dict, prefix + \".shortcut.1\", a.shortcut[1], b.shortcut[1], s_merge)\n",
    "    return s_merge\n",
    "\n",
    "class conv_wrapper:\n",
    "    def __init__(self, linear):\n",
    "        self.weight = linear.weight[:, :, None, None]\n",
    "\n",
    "def merge_resnet20(state_dict, a, b): #, merge_output=False):\n",
    "    conv1_merge = merge_inconv(state_dict, \"conv1\", a.conv1, b.conv1)\n",
    "    merge_bn(state_dict, \"bn1\", a.bn1, b.bn1, conv1_merge)\n",
    "    \n",
    "    for i in range(3):\n",
    "        merge_block(state_dict, f\"layer1.{i}\", a.layer1[i], b.layer1[i], conv1_merge)\n",
    "    \n",
    "    conv1_merge = merge_block_shortcut(state_dict, \"layer2.0\", a.layer2[0], b.layer2[0], conv1_merge)\n",
    "    for i in range(1, 3):\n",
    "        merge_block(state_dict, f\"layer2.{i}\", a.layer2[i], b.layer2[i], conv1_merge)\n",
    "        \n",
    "    conv1_merge = merge_block_shortcut(state_dict, \"layer3.0\", a.layer3[0], b.layer3[0], conv1_merge)\n",
    "    for i in range(1, 3):\n",
    "        merge_block(state_dict, f\"layer3.{i}\", a.layer3[i], b.layer3[i], conv1_merge)\n",
    "\n",
    "#     if merge_output:\n",
    "    merge_conv(state_dict, \"linear\", conv_wrapper(a.linear), conv_wrapper(b.linear), conv1_merge)\n",
    "    state_dict[\"linear.weight\"] = state_dict[\"linear.weight\"][:, :, 0, 0]\n",
    "#     else:\n",
    "#         c_linear = interleave_vals(a.linear.weight.mT[None, ...], b.linear.weight.mT[None, ...])\n",
    "#         c_linear = conv1_merge(c_linear)[0].mT\n",
    "#         state_dict[\"linear.weight\"] = c_linear\n",
    "    state_dict[\"linear.bias\"] = (a.linear.bias + b.linear.bias) / 2\n",
    "\n",
    "# in_merge, _ = bipartite_soft_matching(torch.rand(1, 128, 20, device=DEVICE), r=0.5)\n",
    "\n",
    "state_dict = {}\n",
    "modelc = resnet20(w=4).to(DEVICE)\n",
    "# merge_conv(state_dict, \"layer1.0.conv1\", modela.layer1[0].conv1, modelb.layer1[0].conv1, in_merge)\n",
    "merge_resnet20(state_dict, modelb, modela)\n",
    "modelc.load_state_dict(state_dict)\n",
    "reset_bn_stats(modelc)\n",
    "evaluate(modelc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "ba564899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7489"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_mats(merge, unmerge, n, t, r):\n",
    "    merge_mat   = merge(torch.eye(t, device=DEVICE)[None, ...].expand(n, t, t))\n",
    "    unmerge_mat = unmerge(torch.eye(t-r, device=DEVICE)[None, ...].expand(n, t-r, t-r))\n",
    "    return merge_mat, unmerge_mat\n",
    "\n",
    "state_dict = {}\n",
    "\n",
    "def interleave_vals(tensor1, tensor2, dim=1):\n",
    "    # Assume tensor is of shape [B,H,D]\n",
    "    return torch.cat((tensor1.unsqueeze(dim+1), tensor2.unsqueeze(dim+1)), dim=dim+1).flatten(dim, dim+1)\n",
    "#     return torch.cat((tensor1, tensor2), dim=dim)\n",
    "\n",
    "def unterleave_vals(tensor):\n",
    "    return tensor[:, ::2, :], tensor[:, 1::2, :]\n",
    "#     return tensor.chunk(2, dim=1)\n",
    "\n",
    "\n",
    "def merge_inconv(state_dict, prefix, a_conv, b_conv):\n",
    "    a_c1 = prep_conv(a_conv.weight)\n",
    "    b_c1 = prep_conv(b_conv.weight)\n",
    "    \n",
    "    c_c1 = interleave_vals(a_c1, b_c1)\n",
    "    merge, unmerge = bipartite_soft_matching(c_c1, r=0.5)\n",
    "    \n",
    "    _, t, _ = c_c1.shape\n",
    "    r = int(0.5*t)\n",
    "    \n",
    "    _, out_unmerge = make_mats(merge, unmerge, 1, t, r)\n",
    "    \n",
    "    c_c1 = unprep_conv(merge(c_c1))\n",
    "    \n",
    "    state_dict[prefix + \".weight\"] = c_c1\n",
    "    \n",
    "    return merge, out_unmerge\n",
    "\n",
    "def merge_conv(state_dict, prefix, a_conv, b_conv, unmerge, out_merge=None, eps=1e-7):\n",
    "    def move_kernel_to_output(x): # [out, in, h, w]\n",
    "        return x.transpose(0, 1).flatten(1)[None, ...] # output: [1, in, w*h*out]\n",
    "    \n",
    "    out, _in, k, _ = a_conv.weight.shape\n",
    "    \n",
    "    a_c1 = move_kernel_to_output(a_conv.weight)\n",
    "    b_c1 = move_kernel_to_output(b_conv.weight)\n",
    "    \n",
    "    unmerge_a, unmerge_b = unterleave_vals(unmerge)\n",
    "    \n",
    "    a_c1 = unmerge_a @ a_c1\n",
    "    b_c1 = unmerge_b @ b_c1\n",
    "    \n",
    "    def move_kernel_to_input(x):\n",
    "        return x.transpose(1, 2).reshape(1, -1, k*k*x.shape[1]) # [1, out, h*w*in]\n",
    "    \n",
    "    c_c1 = interleave_vals(move_kernel_to_input(a_c1), move_kernel_to_input(b_c1))\n",
    "    \n",
    "    if out_merge is None:\n",
    "        out_merge, out_unmerge = bipartite_soft_matching(c_c1, r=0.5)\n",
    "    else:\n",
    "        out_unmerge = None\n",
    "    \n",
    "    _, t, _ = c_c1.shape\n",
    "    r = int(0.5*t)\n",
    "    \n",
    "    if out_unmerge is not None:\n",
    "        _, out_unmerge = make_mats(out_merge, out_unmerge, 1, t, r)\n",
    "    \n",
    "    c_c1 = out_merge(c_c1)\n",
    "    c_c1 = c_c1.reshape(1, out, k, k, _in)[0].permute(0, 3, 1, 2)\n",
    "    \n",
    "    state_dict[prefix + \".weight\"] = c_c1\n",
    "    return out_merge, out_unmerge\n",
    "\n",
    "\n",
    "def merge_bn(state_dict, prefix, a_bn, b_bn, merge):\n",
    "    # weight, bias, running_mean, running_var\n",
    "    \n",
    "    a_stats = torch.stack([a_bn.weight, a_bn.bias, a_bn.running_mean], dim=1)[None, ...]\n",
    "    b_stats = torch.stack([b_bn.weight, b_bn.bias, b_bn.running_mean], dim=1)[None, ...]\n",
    "    \n",
    "    c_stats = interleave_vals(a_stats, b_stats)\n",
    "    c_stats = merge(c_stats)[0]\n",
    "    \n",
    "    c_weight, c_bias, c_mean = c_stats.unbind(dim=-1)\n",
    "    \n",
    "    c_var = interleave_vals(a_bn.running_var[None, :, None], b_bn.running_var[None, :, None])\n",
    "    \n",
    "    ones = c_var * 0 + 1\n",
    "    c_denom = merge(ones, mode=\"sum\")\n",
    "    c_var = merge(c_var, mode=\"sum\")\n",
    "    c_var = c_var / (c_denom ** 2)\n",
    "    c_var = c_var[0, :, 0]\n",
    "    \n",
    "    state_dict[prefix + \".weight\"] = c_weight\n",
    "    state_dict[prefix + \".bias\"] = c_bias\n",
    "    state_dict[prefix + \".running_mean\"] = c_mean\n",
    "    state_dict[prefix + \".running_var\"] = c_var\n",
    "\n",
    "def merge_block(state_dict, prefix, a, b, conv1_merge, conv1_unmerge):\n",
    "    c1_merge, c1_unmerge = merge_conv(state_dict, prefix + \".conv1\", a.conv1, b.conv1, conv1_unmerge)\n",
    "    merge_bn(state_dict, prefix + \".bn1\", a.bn1, b.bn1, c1_merge)\n",
    "    c2_merge, c2_unmerge = merge_conv(state_dict, prefix + \".conv2\", a.conv2, b.conv2, c1_unmerge, out_merge=conv1_merge)\n",
    "    merge_bn(state_dict, prefix + \".bn2\", a.bn2, b.bn2, c2_merge)\n",
    "    \n",
    "def merge_block_shortcut(state_dict, prefix, a, b, conv1_merge, conv1_unmerge):\n",
    "    c1_merge, c1_unmerge = merge_conv(state_dict, prefix + \".conv1\", a.conv1, b.conv1, conv1_unmerge)\n",
    "    merge_bn(state_dict, prefix + \".bn1\", a.bn1, b.bn1, c1_merge)\n",
    "    c2_merge, c2_unmerge = merge_conv(state_dict, prefix + \".conv2\", a.conv2, b.conv2, c1_unmerge)\n",
    "    merge_bn(state_dict, prefix + \".bn2\", a.bn2, b.bn2, c2_merge)\n",
    "    \n",
    "    s_merge, s_unmerge = merge_conv(state_dict, prefix + \".shortcut.0\", a.shortcut[0], b.shortcut[0], conv1_unmerge, out_merge=c2_merge)\n",
    "    merge_bn(state_dict, prefix + \".shortcut.1\", a.shortcut[1], b.shortcut[1], s_merge)\n",
    "    return s_merge, c2_unmerge\n",
    "\n",
    "class conv_wrapper:\n",
    "    def __init__(self, linear):\n",
    "        self.weight = linear.weight[:, :, None, None]\n",
    "\n",
    "def merge_resnet20(state_dict, a, b): #, merge_output=False):\n",
    "    conv1_merge, conv1_unmerge = merge_inconv(state_dict, \"conv1\", a.conv1, b.conv1)\n",
    "    merge_bn(state_dict, \"bn1\", a.bn1, b.bn1, conv1_merge)\n",
    "    \n",
    "    for i in range(3):\n",
    "        merge_block(state_dict, f\"layer1.{i}\", a.layer1[i], b.layer1[i], conv1_merge, conv1_unmerge)\n",
    "    \n",
    "    conv1_merge, conv1_unmerge = merge_block_shortcut(state_dict, \"layer2.0\", a.layer2[0], b.layer2[0], conv1_merge, conv1_unmerge)\n",
    "    for i in range(1, 3):\n",
    "        merge_block(state_dict, f\"layer2.{i}\", a.layer2[i], b.layer2[i], conv1_merge, conv1_unmerge)\n",
    "        \n",
    "    conv1_merge, conv1_unmerge = merge_block_shortcut(state_dict, \"layer3.0\", a.layer3[0], b.layer3[0], conv1_merge, conv1_unmerge)\n",
    "    for i in range(1, 3):\n",
    "        merge_block(state_dict, f\"layer3.{i}\", a.layer3[i], b.layer3[i], conv1_merge, conv1_unmerge)\n",
    "\n",
    "#     if merge_output:\n",
    "    merge_conv(state_dict, \"linear\", conv_wrapper(a.linear), conv_wrapper(b.linear), conv1_unmerge)\n",
    "    state_dict[\"linear.weight\"] = state_dict[\"linear.weight\"][:, :, 0, 0]\n",
    "#     else:\n",
    "#         c_linear = interleave_vals(a.linear.weight.mT[None, ...], b.linear.weight.mT[None, ...])\n",
    "#         c_linear = conv1_merge(c_linear)[0].mT\n",
    "#         state_dict[\"linear.weight\"] = c_linear\n",
    "    state_dict[\"linear.bias\"] = (a.linear.bias + b.linear.bias) / 2\n",
    "\n",
    "# in_merge, _ = bipartite_soft_matching(torch.rand(1, 128, 20, device=DEVICE), r=0.5)\n",
    "\n",
    "state_dict = {}\n",
    "modelc = resnet20(w=4).to(DEVICE)\n",
    "# merge_conv(state_dict, \"layer1.0.conv1\", modela.layer1[0].conv1, modelb.layer1[0].conv1, in_merge)\n",
    "merge_resnet20(state_dict, modelb, modela)\n",
    "modelc.load_state_dict(state_dict)\n",
    "reset_bn_stats(modelc)\n",
    "evaluate(modelc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "11567592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.92144775390625, 6.855426788330078)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modela.linear.weight.norm().item(), modelb.linear.weight.norm().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ffbdedbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9536, 9510)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(modela), evaluate(modelb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801a1d9",
   "metadata": {},
   "source": [
    "# Merge Inputs and Outputs Using all Corresponding  and Output Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "f4f61c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9222"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = {}\n",
    "\n",
    "def interleave_vals(tensor1, tensor2, dim=1):\n",
    "    # Assume tensor is of shape [B,H,D]\n",
    "    b, h, d = tensor1.shape\n",
    "#     a = torch.cat((tensor1.unsqueeze(dim+1), tensor2.unsqueeze(dim+1)), dim=dim+1).flatten(dim, dim+1)\n",
    "#     tensor1, tensor2 = a.view(b, 2, h, d).unbind(1)\n",
    "    \n",
    "    return torch.cat((tensor1.unsqueeze(dim+1), tensor2.unsqueeze(dim+1)), dim=dim+1).flatten(dim, dim+1)\n",
    "#     return torch.cat((tensor1, tensor2), dim=dim)\n",
    "\n",
    "\n",
    "def merge_inconv(state_dict, prefix, a_conv, b_conv):\n",
    "    a_c1 = prep_conv(a_conv.weight)\n",
    "    b_c1 = prep_conv(b_conv.weight)\n",
    "    \n",
    "    c_c1 = interleave_vals(a_c1, b_c1)\n",
    "    c1_merge, _ = bipartite_soft_matching(c_c1, r=0.5)\n",
    "    \n",
    "    c_c1 = unprep_conv(c1_merge(c_c1))\n",
    "    \n",
    "    state_dict[prefix + \".weight\"] = c_c1\n",
    "    \n",
    "    return c1_merge\n",
    "\n",
    "def merge_conv(state_dict, prefix, a_conv, b_conv, in_merge, out_merge=None, eps=1e-7):\n",
    "    def move_kernel_to_output(x): # [out, in, h, w]\n",
    "        return x.transpose(0, 1).flatten(1)[None, ...] # output: [1, in, w*h*out]\n",
    "    \n",
    "    out, _in, k, _ = a_conv.weight.shape\n",
    "    \n",
    "    a_c1 = move_kernel_to_output(a_conv.weight)\n",
    "    b_c1 = move_kernel_to_output(b_conv.weight)\n",
    "    \n",
    "    ones = torch.ones_like(a_c1)\n",
    "    zeros = torch.zeros_like(a_c1)\n",
    "    \n",
    "    big_boy = torch.cat([interleave_vals(a_c1, zeros), interleave_vals(zeros, b_c1)], dim=-1)\n",
    "    counter = torch.cat([interleave_vals(ones, zeros), interleave_vals(zeros, ones)], dim=-1)\n",
    "    \n",
    "    merged_boy = in_merge(big_boy, mode=\"sum\")\n",
    "    counter = in_merge(counter, mode=\"sum\")\n",
    "    \n",
    "    a_boy, b_boy = merged_boy.view(1, counter.shape[1], 2, -1).unbind(-2)\n",
    "    a_count, b_count = counter.view(1, counter.shape[1], 2, -1).unbind(-2)\n",
    "    \n",
    "    def move_kernel_to_input(x):\n",
    "        return x.transpose(1, 2).reshape(1, -1, k*k*x.shape[1]) # [1, out, h*w*in]\n",
    "    \n",
    "    c_boy = interleave_vals(move_kernel_to_input(a_boy), move_kernel_to_input(b_boy))\n",
    "    c_count = interleave_vals(move_kernel_to_input(a_count), move_kernel_to_input(b_count))\n",
    "    \n",
    "    c_boy = c_boy / (c_count + eps)\n",
    "    \n",
    "    \n",
    "    if out_merge is None:\n",
    "        out_merge, _ = bipartite_soft_matching(c_boy, r=0.5)\n",
    "    \n",
    "    c_boy = out_merge(c_boy, mode=\"sum\")\n",
    "    c_count = out_merge((c_count > eps).float(), mode=\"sum\")\n",
    "    \n",
    "    c_boy = c_boy / (c_count + eps)\n",
    "    \n",
    "    \n",
    "    c_boy = c_boy.reshape(1, out, k, k, _in)[0].permute(0, 3, 1, 2)\n",
    "    \n",
    "    state_dict[prefix + \".weight\"] = c_boy\n",
    "    return out_merge\n",
    "\n",
    "def merge_bn(state_dict, prefix, a_bn, b_bn, merge):\n",
    "    # weight, bias, running_mean, running_var\n",
    "    \n",
    "    a_stats = torch.stack([a_bn.weight, a_bn.bias, a_bn.running_mean], dim=1)[None, ...]\n",
    "    b_stats = torch.stack([b_bn.weight, b_bn.bias, b_bn.running_mean], dim=1)[None, ...]\n",
    "    \n",
    "    c_stats = interleave_vals(a_stats, b_stats)\n",
    "    c_stats = merge(c_stats)[0]\n",
    "    \n",
    "    c_weight, c_bias, c_mean = c_stats.unbind(dim=-1)\n",
    "    \n",
    "    c_var = interleave_vals(a_bn.running_var[None, :, None], b_bn.running_var[None, :, None])\n",
    "    \n",
    "    ones = c_var * 0 + 1\n",
    "    c_denom = merge(ones, mode=\"sum\")\n",
    "    c_var = merge(c_var, mode=\"sum\")\n",
    "    c_var = c_var / (c_denom ** 2)\n",
    "    c_var = c_var[0, :, 0]\n",
    "    \n",
    "    state_dict[prefix + \".weight\"] = c_weight\n",
    "    state_dict[prefix + \".bias\"] = c_bias\n",
    "    state_dict[prefix + \".running_mean\"] = c_mean\n",
    "    state_dict[prefix + \".running_var\"] = c_var\n",
    "\n",
    "def merge_block(state_dict, prefix, a, b, in_merge):\n",
    "    c1_merge = merge_conv(state_dict, prefix + \".conv1\", a.conv1, b.conv1, in_merge)\n",
    "    merge_bn(state_dict, prefix + \".bn1\", a.bn1, b.bn1, c1_merge)\n",
    "    c2_merge = merge_conv(state_dict, prefix + \".conv2\", a.conv2, b.conv2, c1_merge, out_merge=in_merge)\n",
    "    merge_bn(state_dict, prefix + \".bn2\", a.bn2, b.bn2, c2_merge)\n",
    "    \n",
    "def merge_block_shortcut(state_dict, prefix, a, b, in_merge):\n",
    "    c1_merge = merge_conv(state_dict, prefix + \".conv1\", a.conv1, b.conv1, in_merge)\n",
    "    merge_bn(state_dict, prefix + \".bn1\", a.bn1, b.bn1, c1_merge)\n",
    "    c2_merge = merge_conv(state_dict, prefix + \".conv2\", a.conv2, b.conv2, c1_merge)\n",
    "    merge_bn(state_dict, prefix + \".bn2\", a.bn2, b.bn2, c2_merge)\n",
    "    \n",
    "    s_merge = merge_conv(state_dict, prefix + \".shortcut.0\", a.shortcut[0], b.shortcut[0], in_merge, out_merge=c2_merge)\n",
    "    merge_bn(state_dict, prefix + \".shortcut.1\", a.shortcut[1], b.shortcut[1], s_merge)\n",
    "    return s_merge\n",
    "\n",
    "class conv_wrapper:\n",
    "    def __init__(self, linear):\n",
    "        self.weight = linear.weight[:, :, None, None]\n",
    "\n",
    "def merge_resnet20(state_dict, a, b): #, merge_output=False):\n",
    "    conv1_merge = merge_inconv(state_dict, \"conv1\", a.conv1, b.conv1)\n",
    "    merge_bn(state_dict, \"bn1\", a.bn1, b.bn1, conv1_merge)\n",
    "    \n",
    "    for i in range(3):\n",
    "        merge_block(state_dict, f\"layer1.{i}\", a.layer1[i], b.layer1[i], conv1_merge)\n",
    "    \n",
    "    conv1_merge = merge_block_shortcut(state_dict, \"layer2.0\", a.layer2[0], b.layer2[0], conv1_merge)\n",
    "    for i in range(1, 3):\n",
    "        merge_block(state_dict, f\"layer2.{i}\", a.layer2[i], b.layer2[i], conv1_merge)\n",
    "        \n",
    "    conv1_merge = merge_block_shortcut(state_dict, \"layer3.0\", a.layer3[0], b.layer3[0], conv1_merge)\n",
    "    for i in range(1, 3):\n",
    "        merge_block(state_dict, f\"layer3.{i}\", a.layer3[i], b.layer3[i], conv1_merge)\n",
    "\n",
    "#     if merge_output:\n",
    "    merge_conv(state_dict, \"linear\", conv_wrapper(a.linear), conv_wrapper(b.linear), conv1_merge)\n",
    "    state_dict[\"linear.weight\"] = state_dict[\"linear.weight\"][:, :, 0, 0]\n",
    "#     else:\n",
    "#         c_linear = interleave_vals(a.linear.weight.mT[None, ...], b.linear.weight.mT[None, ...])\n",
    "#         c_linear = conv1_merge(c_linear)[0].mT\n",
    "#         state_dict[\"linear.weight\"] = c_linear\n",
    "    state_dict[\"linear.bias\"] = (a.linear.bias + b.linear.bias) / 2\n",
    "\n",
    "# in_merge, _ = bipartite_soft_matching(torch.rand(1, 128, 20, device=DEVICE), r=0.5)\n",
    "\n",
    "state_dict = {}\n",
    "modelc = resnet20(w=4).to(DEVICE)\n",
    "# merge_conv(state_dict, \"layer1.0.conv1\", modela.layer1[0].conv1, modelb.layer1[0].conv1, in_merge)\n",
    "merge_resnet20(state_dict, modelb, modela)\n",
    "modelc.load_state_dict(state_dict)\n",
    "reset_bn_stats(modelc)\n",
    "evaluate(modelc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "918e60e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, confusion = evaluate(modelc, return_confusion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "45b9ccdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.408, 0.606, 0.278, 0.25, 0.4, 0.278, 0.455, 0.385, 0.392, 0.455]\n",
      "[0.4, 0.556, 0.29, 0.253, 0.392, 0.328, 0.465, 0.435, 0.476, 0.408]\n",
      "[0.417, 0.625, 0.286, 0.253, 0.4, 0.303, 0.476, 0.392, 0.4, 0.465]\n"
     ]
    }
   ],
   "source": [
    "_, confusion_b = evaluate(modelb, return_confusion=True)\n",
    "_, confusion_a = evaluate(modela, return_confusion=True)\n",
    "print(np.diag(confusion).round(3).tolist())\n",
    "print(np.diag(confusion_b).round(3).tolist())\n",
    "print(np.diag(confusion_a).round(3).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307856ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5995f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34c6ffd6",
   "metadata": {},
   "source": [
    "# CIFAR10 Disjoint Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f8a67da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:13, 3764.02it/s]\n",
      "50000it [00:13, 3762.17it/s]\n",
      "10000it [00:01, 5769.96it/s]\n",
      "10000it [00:01, 5815.04it/s]\n"
     ]
    }
   ],
   "source": [
    "model1_classes= np.array([3, 2, 0, 6, 4])\n",
    "model2_classes = np.array([5, 7, 9, 8, 1])\n",
    "\n",
    "valid_examples1 = [i for i, (_, label) in tqdm(enumerate(train_dset)) if label in model1_classes]\n",
    "valid_examples2 = [i for i, (_, label) in tqdm(enumerate(train_dset)) if label in model2_classes]\n",
    "\n",
    "assert len(set(valid_examples1).intersection(set(valid_examples2))) == 0, 'sets should be disjoint'\n",
    "\n",
    "train_aug_loader1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dset, valid_examples1), batch_size=500, shuffle=True, num_workers=8\n",
    ")\n",
    "train_aug_loader2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dset, valid_examples2), batch_size=500, shuffle=True, num_workers=8\n",
    ")\n",
    "\n",
    "test_valid_examples1 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model1_classes]\n",
    "test_valid_examples2 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model2_classes]\n",
    "\n",
    "test_loader1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dset, test_valid_examples1), batch_size=500, shuffle=False, num_workers=8\n",
    ")\n",
    "test_loader2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dset, test_valid_examples2), batch_size=500, shuffle=False, num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b02732fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 1, 0, 4, 0, 3, 1, 3, 2])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_idxs = np.zeros(10, dtype=int)\n",
    "class_idxs[model1_classes] = np.arange(5)\n",
    "class_idxs[model2_classes] = np.arange(5)\n",
    "class_idxs = torch.from_numpy(class_idxs)\n",
    "class_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5c9b7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in test_dset.classes]).to(DEVICE)\n",
    "model, preprocess = clip.load('ViT-B/32', DEVICE)\n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "class_vecs1 = text_features[model1_classes]\n",
    "class_vecs2 = text_features[model2_classes]\n",
    "\n",
    "if not os.path.exists(\n",
    "    os.path.join(\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}.pth.tar'\n",
    "    )\n",
    "):\n",
    "    print('training model...')\n",
    "    model1 = resnet20(w=4).to(DEVICE)\n",
    "    train(\n",
    "        f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}', \n",
    "        model=model1, \n",
    "        class_vectors=class_vecs1,\n",
    "        train_loader=train_aug_loader1,\n",
    "        test_loader=test_loader1,\n",
    "        remap_class_idxs=class_idxs\n",
    "    )\n",
    "if not os.path.exists(\n",
    "    os.path.join(\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}.pth.tar'\n",
    "    )\n",
    "):\n",
    "    print('training model...')\n",
    "    model2 = resnet20(w=4).to(DEVICE)\n",
    "    train(\n",
    "        f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}', \n",
    "        model=model2, \n",
    "        class_vectors=class_vecs2,\n",
    "        train_loader=train_aug_loader2,\n",
    "        test_loader=test_loader2,\n",
    "        remap_class_idxs=class_idxs\n",
    "    )\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "92e6f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates accuracy\n",
    "def evaluate_texthead(model, loader, class_vectors, remap_class_idxs=None, return_confusion=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    confusion = np.zeros((10, 10))\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            encodings = model(inputs.to(DEVICE))\n",
    "            normed_encodings = encodings / encodings.norm(dim=-1, keepdim=True)\n",
    "            outputs = normed_encodings @ class_vectors.T\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            if remap_class_idxs is not None:\n",
    "                correct += (remap_class_idxs[labels].to(DEVICE) == pred).sum().item()\n",
    "            else:\n",
    "                correct += (labels.to(DEVICE) == pred).sum().item()\n",
    "            confusion[labels.cpu().numpy(), pred.cpu().numpy()] += 1\n",
    "            total += inputs.shape[0]\n",
    "    if return_confusion:\n",
    "        return correct / total, confusion / confusion.sum(-1, keepdims=True)\n",
    "    else:\n",
    "        return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "81d3287f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9558\n",
      "0.9726\n"
     ]
    }
   ],
   "source": [
    "model1 = resnet20(w=4, text_head=True).to(DEVICE)\n",
    "model2 = resnet20(w=4, text_head=True).to(DEVICE)\n",
    "load_model(model1, f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}')\n",
    "load_model(model2, f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}')\n",
    "\n",
    "print(evaluate_texthead(model1, test_loader1, class_vecs1, remap_class_idxs=class_idxs))\n",
    "print(evaluate_texthead(model2, test_loader2, class_vecs2, remap_class_idxs=class_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "f6f95e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4407"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = {}\n",
    "merge_resnet20(state_dict, model1, model2)\n",
    "modelc = resnet20(w=4, text_head=True).to(DEVICE)\n",
    "modelc.load_state_dict(state_dict)\n",
    "reset_bn_stats(modelc)\n",
    "acc, confusion_disj = evaluate_texthead(modelc, test_loader, class_vectors=text_features, return_confusion=True)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "3f16886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16806722689075632, 0.3508771929824561, 0.0, 0.0, 0.0, 0.20833333333333334, 0.0, 0.22727272727272727, 0.23809523809523808, 0.3225806451612903]\n"
     ]
    }
   ],
   "source": [
    "print(np.diag(confusion_disj).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "fcbf7694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5263157894736842, 0.0, 0.26666666666666666, 0.2777777777777778, 0.4878048780487805, 0.0, 0.47619047619047616, 0.0, 0.1794871794871795, 0.0]\n"
     ]
    }
   ],
   "source": [
    "acc, confusion_disj_1 = evaluate_texthead(model1, test_loader, class_vectors=text_features, return_confusion=True)\n",
    "print(np.diag(confusion_disj_1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "63e094a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08108108108108109, 0.5555555555555556, 0.0, 0.046511627906976744, 0.02702702702702703, 0.5128205128205128, 0.0, 0.5263157894736842, 0.5263157894736842, 0.40816326530612246]\n"
     ]
    }
   ],
   "source": [
    "acc, confusion_disj_2 = evaluate_texthead(model2, test_loader, class_vectors=text_features, return_confusion=True)\n",
    "print(np.diag(confusion_disj_2).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8c8591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
