{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam, lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, i):\n",
    "    sd = model.state_dict()\n",
    "    torch.save(model.state_dict(), '/Users/georgestoica/Downloads/%s.pth.tar' % i)\n",
    "\n",
    "def load_model(model, i):\n",
    "    sd = torch.load('/Users/georgestoica/Downloads/%s.pth.tar' % i, map_location=torch.device('mps'))\n",
    "    model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CIFAR_MEAN = [125.307, 122.961, 113.8575]\n",
    "CIFAR_STD = [51.5865, 50.847, 51.255]\n",
    "normalize = T.Normalize(np.array(CIFAR_MEAN)/255, np.array(CIFAR_STD)/255)\n",
    "denormalize = T.Normalize(-np.array(CIFAR_MEAN)/np.array(CIFAR_STD), 255/np.array(CIFAR_STD))\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "train_dset = torchvision.datasets.CIFAR10(root='/tmp', train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "test_dset = torchvision.datasets.CIFAR10(root='/tmp', train=False,\n",
    "                                        download=True, transform=test_transform)\n",
    "\n",
    "train_aug_loader = torch.utils.data.DataLoader(train_dset, batch_size=500, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=500, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates accuracy\n",
    "def evaluate(model, loader=test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs.to('mps'))\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            correct += (labels.to('mps') == pred).sum().item()\n",
    "    return correct\n",
    "\n",
    "# evaluates loss\n",
    "def evaluate1(model, loader=test_loader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs.to('mps'))\n",
    "            loss = F.cross_entropy(outputs, labels.to('mps'))\n",
    "            losses.append(loss.item())\n",
    "    return np.array(losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "#             self.shortcut = LambdaLayer(lambda x:\n",
    "#                                         F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, w=1, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = w*16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, w*16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(w*16)\n",
    "        self.layer1 = self._make_layer(block, w*16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, w*32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, w*64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(w*64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def resnet20(w=1):\n",
    "    return ResNet(BasicBlock, [3, 3, 3], w=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given two networks net0, net1 which each output a feature map of shape NxCxWxH\n",
    "# this will reshape both outputs to (N*W*H)xC\n",
    "# and then compute a CxC correlation matrix between the outputs of the two networks\n",
    "def run_corr_matrix(net0, net1, epochs=1, norm=True, loader=train_aug_loader):\n",
    "    n = epochs*len(loader)\n",
    "    mean0 = mean1 = std0 = std1 = None\n",
    "    with torch.no_grad():\n",
    "        net0.eval()\n",
    "        net1.eval()\n",
    "        for _ in range(epochs):\n",
    "            for i, (images, _) in enumerate(tqdm(loader)):\n",
    "                img_t = images.float().to('mps')\n",
    "                out0 = net0(img_t)\n",
    "                out0 = out0.reshape(out0.shape[0], out0.shape[1], -1).permute(0, 2, 1)\n",
    "                out0 = out0.reshape(-1, out0.shape[2])#.double()\n",
    "\n",
    "                out1 = net1(img_t)\n",
    "                out1 = out1.reshape(out1.shape[0], out1.shape[1], -1).permute(0, 2, 1)\n",
    "                out1 = out1.reshape(-1, out1.shape[2])#.double()\n",
    "\n",
    "                mean0_b = out0.mean(dim=0)\n",
    "                mean1_b = out1.mean(dim=0)\n",
    "                std0_b = out0.std(dim=0)\n",
    "                std1_b = out1.std(dim=0)\n",
    "                outer_b = (out0.T @ out1) / out0.shape[0]\n",
    "\n",
    "                if i == 0:\n",
    "                    mean0 = torch.zeros_like(mean0_b)\n",
    "                    mean1 = torch.zeros_like(mean1_b)\n",
    "                    std0 = torch.zeros_like(std0_b)\n",
    "                    std1 = torch.zeros_like(std1_b)\n",
    "                    outer = torch.zeros_like(outer_b)\n",
    "                mean0 += mean0_b / n\n",
    "                mean1 += mean1_b / n\n",
    "                std0 += std0_b / n\n",
    "                std1 += std1_b / n\n",
    "                outer += outer_b / n\n",
    "\n",
    "    cov = outer - torch.outer(mean0, mean1)\n",
    "    if norm:\n",
    "        corr = cov / (torch.outer(std0, std1) + 1e-4)\n",
    "        return corr\n",
    "    else:\n",
    "        return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perm_map(corr_mtx):\n",
    "    # sort the (i, j) channel pairs by correlation\n",
    "    nchan = corr_mtx.shape[0]\n",
    "    triples = [(i, j, corr_mtx[i, j].item()) for i in range(nchan) for j in range(nchan)]\n",
    "    triples = sorted(triples, key=lambda p: -p[2])\n",
    "    # greedily find a matching\n",
    "    perm_d = {}\n",
    "    for i, j, c in triples:\n",
    "        if not (i in perm_d.keys() or j in perm_d.values()):\n",
    "            perm_d[i] = j\n",
    "    perm_map = torch.tensor([perm_d[i] for i in range(nchan)])\n",
    "\n",
    "    # qual_map will be a permutation of the indices in the order\n",
    "    # of the quality / degree of correlation between the neurons found in the permutation.\n",
    "    # this just for visualization purposes.\n",
    "    qual_l = [corr_mtx[i, perm_map[i]].item() for i in range(nchan)]\n",
    "    qual_map = torch.tensor(sorted(range(nchan), key=lambda i: -qual_l[i]))\n",
    "\n",
    "    return perm_map, qual_map\n",
    "\n",
    "def get_layer_perm1(corr_mtx, method='max_weight', vizz=False, prune_type='threshold', bound=-torch.inf):\n",
    "    if method == 'greedy':\n",
    "        perm_map, qual_map = compute_perm_map(corr_mtx)\n",
    "        if vizz:\n",
    "            corr_mtx_viz = (corr_mtx[qual_map].T[perm_map[qual_map]]).T\n",
    "            viz(corr_mtx_viz)\n",
    "    elif method == 'max_weight':\n",
    "        corr_mtx_a = corr_mtx.cpu().numpy()\n",
    "        row_ind, col_ind = scipy.optimize.linear_sum_assignment(corr_mtx_a, maximize=True)\n",
    "        assert (row_ind == np.arange(len(corr_mtx_a))).all()\n",
    "        perm_map = torch.tensor(col_ind).long()\n",
    "        perm_map = torch.eye(corr_mtx.shape[0], device=corr_mtx.device)[perm_map]\n",
    "    else:\n",
    "        raise Exception('Unknown method: %s' % method)\n",
    "    \n",
    "    scores_np = corr_mtx_a[row_ind, col_ind]\n",
    "    scores = torch.from_numpy(scores_np).to(perm_map.device)\n",
    "    if prune_type == 'threshold':\n",
    "        pruned_elements = (scores >= bound).to(torch.float32)\n",
    "    elif prune_type == 'topk':\n",
    "        bound_score = -np.sort(-scores_np)[bound-1]\n",
    "        pruned_elements = (scores >= bound_score).to(torch.float32)\n",
    "    else:\n",
    "        pruned_elements = torch.ones(\n",
    "            perm_map.shape[0], device=perm_map.device, dtype=torch.float32\n",
    "        )\n",
    "    return perm_map, pruned_elements\n",
    "\n",
    "# returns the channel-permutation to make layer1's activations most closely\n",
    "# match layer0's.\n",
    "def get_layer_perm(net0, net1, method='max_weight', vizz=False, prune_type='threshold', bound=-torch.inf):\n",
    "    corr_mtx = run_corr_matrix(net0, net1)\n",
    "    return get_layer_perm1(corr_mtx, method, vizz, prune_type=prune_type, bound=bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifies the weight matrices of a convolution and batchnorm\n",
    "# layer given a permutation of the output channels\n",
    "def permute_output(perm_map, conv, bn):\n",
    "    pre_weights = [\n",
    "        conv.weight,\n",
    "        bn.weight,\n",
    "        bn.bias,\n",
    "        bn.running_mean,\n",
    "        bn.running_var,\n",
    "    ]\n",
    "    for w in pre_weights:\n",
    "        if len(w.shape) == 4:\n",
    "            transform = torch.einsum('ab,bcde->acde', perm_map, w)\n",
    "        elif len(w.shape) == 2:\n",
    "            transform = perm_map @ w\n",
    "        else:\n",
    "            transform = w @ perm_map.t()\n",
    "#         assert torch.allclose(w[perm_map.argmax(-1)], transform)\n",
    "        w.data = transform\n",
    "#         w.data = w[perm_map]\n",
    "\n",
    "# modifies the weight matrix of a convolution layer for a given\n",
    "# permutation of the input channels\n",
    "def permute_input(perm_map, after_convs):\n",
    "    if not isinstance(after_convs, list):\n",
    "        after_convs = [after_convs]\n",
    "    post_weights = [c.weight for c in after_convs]\n",
    "    for w in post_weights:\n",
    "        if len(w.shape) == 4:\n",
    "            transform = torch.einsum('abcd,be->aecd', w, perm_map.t())\n",
    "        elif len(w.shape) == 2:\n",
    "            transform = w @ perm_map.t()\n",
    "    #     assert torch.allclose(w[:, perm_map.argmax(-1)], transform)\n",
    "        w.data = transform\n",
    "#         w.data = w[:, perm_map, :, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95.4, 95.21)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0 = resnet20(w=4).to('mps')\n",
    "model1 = resnet20(w=4).to('mps')\n",
    "load_model(model0, 'resnet20x4_v2')\n",
    "load_model(model1, 'resnet20x4_v1')\n",
    "\n",
    "evaluate(model0)/100, evaluate(model1)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "module2io = defaultdict(lambda: dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:33<00:00,  3.01it/s]\n"
     ]
    }
   ],
   "source": [
    "class Subnet(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        self = self.model\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        return x\n",
    "# corr = run_corr_matrix(Subnet(model0), Subnet(model1))\n",
    "# perm_map1 = get_layer_perm1(corr)\n",
    "perm_map, collapse_totals = get_layer_perm(Subnet(model0), Subnet(model1), prune_type='topk', bound=bound)\n",
    "permute_output(perm_map, model1.conv1, model1.bn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "module2io['conv1']['output'] = collapse_totals\n",
    "module2io['bn1']['output'] = collapse_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], device='mps:0')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapse_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model1, f'resnet20x4_v1_perm1_conv1oneparam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the train loader with data augmentation as this gives better results\n",
    "def reset_bn_stats(model, epochs=1, loader=train_aug_loader):\n",
    "    # resetting stats to baseline first as below is necessary for stability\n",
    "    for m in model.modules():\n",
    "        if type(m) == nn.BatchNorm2d:\n",
    "            m.momentum = None # use simple average\n",
    "            m.reset_running_stats()\n",
    "    # run a single train epoch with augmentations to recalc stats\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        with torch.no_grad(), autocast():\n",
    "            for images, _ in loader:\n",
    "                output = model(images.to('mps'))\n",
    "\n",
    "def strip_param_suffix(name):\n",
    "    return name.replace('.weight', '').replace('.bias', '')\n",
    "\n",
    "def combine_io_masks(io, param):\n",
    "    mask = torch.zeros_like(param, device=param.device)\n",
    "    try:\n",
    "        if 'output' in io:\n",
    "            mask[io['output'].view(-1) == 0] = 1.\n",
    "        if 'input' in io and len(mask.shape) > 1:\n",
    "            mask[:, io['input'].view(-1) == 0] = 1.\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "    return mask\n",
    "\n",
    "def mix_weights(model, alpha, key0, key1, module2io=None):\n",
    "    sd0 = torch.load('/Users/georgestoica/Downloads/%s.pth.tar' % key0, map_location=torch.device('mps'))\n",
    "    sd1 = torch.load('/Users/georgestoica/Downloads/%s.pth.tar' % key1, map_location=torch.device('mps'))\n",
    "    sd_alpha = {}\n",
    "    for k in sd0.keys():\n",
    "        if module2io is not None and strip_param_suffix(k) not in module2io:\n",
    "            sd_alpha[k] = sd0[k].to('mps')\n",
    "            continue\n",
    "        \n",
    "        param0 = sd0[k].to('mps')\n",
    "        param1 = sd1[k].to('mps')\n",
    "        sd_alpha[k] = (1 - alpha) * param0 + alpha * param1\n",
    "        \n",
    "        if module2io is not None:\n",
    "            param_base = strip_param_suffix(k)\n",
    "            mask = combine_io_masks(module2io[param_base], param1)\n",
    "            sd_alpha[k][mask == 1] = param0[mask == 1].to(sd_alpha[k].dtype)\n",
    "            \n",
    "    model.load_state_dict(sd_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-reset:\n",
      "Accuracy=95.39%, Loss=0.172\n",
      "Post-reset:\n",
      "Accuracy=95.35%, Loss=0.170\n"
     ]
    }
   ],
   "source": [
    "model_a = resnet20(w=4).to('mps') # W_\\alpha\n",
    "mix_weights(model_a, 0.5, 'resnet20x4_v2', f'resnet20x4_v1_perm1_conv1oneparam', module2io=module2io)\n",
    "\n",
    "print('Pre-reset:')\n",
    "print('Accuracy=%.2f%%, Loss=%.3f' % (evaluate(model_a)/100, evaluate1(model_a)))\n",
    "\n",
    "reset_bn_stats(model_a)\n",
    "print('Post-reset:')\n",
    "print('Accuracy=%.2f%%, Loss=%.3f' % (evaluate(model_a)/100, evaluate1(model_a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENAS-pytorch",
   "language": "python",
   "name": "enas-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
