{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "431d4ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam, lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sys import platform\n",
    "from collections import defaultdict\n",
    "\n",
    "DEVICE = 'mps' if platform == 'darwin' else 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb7e16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:13, 3741.44it/s]\n",
      "50000it [00:13, 3773.18it/s]\n",
      "10000it [00:01, 5689.69it/s]\n",
      "10000it [00:01, 5744.98it/s]\n"
     ]
    }
   ],
   "source": [
    "CIFAR_MEAN = [125.307, 122.961, 113.8575]\n",
    "CIFAR_STD = [51.5865, 50.847, 51.255]\n",
    "normalize = T.Normalize(np.array(CIFAR_MEAN)/255, np.array(CIFAR_STD)/255)\n",
    "denormalize = T.Normalize(-np.array(CIFAR_MEAN)/np.array(CIFAR_STD), 255/np.array(CIFAR_STD))\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "train_dset = torchvision.datasets.CIFAR100(\n",
    "    root='/nethome/gstoica3/research/pytorch-cifar100/data/cifar-100-python', \n",
    "    train=True,\n",
    "    download=True, transform=train_transform\n",
    ")\n",
    "test_dset = torchvision.datasets.CIFAR100(\n",
    "    root='/nethome/gstoica3/research/pytorch-cifar100/data/cifar-100-python',\n",
    "    train=False,\n",
    "    download=True, \n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "model1_classes= np.arange(50) # np.array([3, 2, 0, 6, 4])\n",
    "model2_classes = np.arange(50, 100) # np.array([5, 7, 9, 8, 1])\n",
    "\n",
    "valid_examples1 = [i for i, (_, label) in tqdm(enumerate(train_dset)) if label in model1_classes]\n",
    "valid_examples2 = [i for i, (_, label) in tqdm(enumerate(train_dset)) if label in model2_classes]\n",
    "\n",
    "assert len(set(valid_examples1).intersection(set(valid_examples2))) == 0, 'sets should be disjoint'\n",
    "\n",
    "train_aug_loader1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dset, valid_examples1), batch_size=500, shuffle=True, num_workers=8\n",
    ")\n",
    "train_aug_loader2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dset, valid_examples2), batch_size=500, shuffle=True, num_workers=8\n",
    ")\n",
    "\n",
    "test_valid_examples1 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model1_classes]\n",
    "test_valid_examples2 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model2_classes]\n",
    "\n",
    "test_loader1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dset, test_valid_examples1), batch_size=500, shuffle=False, num_workers=8\n",
    ")\n",
    "test_loader2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dset, test_valid_examples2), batch_size=500, shuffle=False, num_workers=8\n",
    ")\n",
    "\n",
    "train_aug_loader = torch.utils.data.DataLoader(train_dset, batch_size=500, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=500, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474eb49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269fd89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_valid_examples1 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model1_classes]\n",
    "# test_valid_examples2 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model2_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc598da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader1 = torch.utils.data.DataLoader(\n",
    "#     torch.utils.data.Subset(test_dset, test_valid_examples1), batch_size=500, shuffle=False, num_workers=8\n",
    "# )\n",
    "# test_loader2 = torch.utils.data.DataLoader(\n",
    "#     torch.utils.data.Subset(test_dset, test_valid_examples2), batch_size=500, shuffle=False, num_workers=8\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3f75f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
       " array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,\n",
       "        67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83,\n",
       "        84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_classes, model2_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e9aa20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,  0,  1,  2,  3,\n",
       "         4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "        22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n",
       "        40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_idxs = np.zeros(100, dtype=int)\n",
    "class_idxs[model1_classes] = np.arange(50)\n",
    "class_idxs[model2_classes] = np.arange(50)\n",
    "class_idxs = torch.from_numpy(class_idxs)\n",
    "class_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "061bef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, i):\n",
    "    sd = model.state_dict()\n",
    "    path = os.path.join(\n",
    "        # '/Users/georgestoica/Downloads',\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def load_model(model, i):\n",
    "    path = os.path.join(\n",
    "        # '/Users/georgestoica/Downloads',\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    sd = torch.load(path, map_location=torch.device(DEVICE))\n",
    "    model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84af4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "#             self.shortcut = LambdaLayer(lambda x:\n",
    "#                                         F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, w=1, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = w*16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, w*16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(w*16)\n",
    "        self.layer1 = self._make_layer(block, w*16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, w*32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, w*64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(w*64, 512)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def resnet20(w=1):\n",
    "    return ResNet(BasicBlock, [3, 3, 3], w=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99402c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(save_key, model, train_loader, test_loader, class_vectors, remap_class_idxs):\n",
    "    optimizer = SGD(model.parameters(), lr=0.4, momentum=0.9, weight_decay=5e-4)\n",
    "    # optimizer = Adam(model.parameters(), lr=0.05)\n",
    "    \n",
    "    # Adam seems to perform worse than SGD for training ResNets on CIFAR-10.\n",
    "    # To make Adam work, we find that we need a very high learning rate: 0.05 (50x the default)\n",
    "    # At this LR, Adam gives 1.0-1.5% worse accuracy than SGD.\n",
    "    \n",
    "    # It is not yet clear whether the increased interpolation barrier for Adam-trained networks\n",
    "    # is simply due to the increased test loss of said networks relative to those trained with SGD.\n",
    "    # We include the option of using Adam in this notebook to explore this question.\n",
    "\n",
    "    EPOCHS = 100\n",
    "    ne_iters = len(train_loader)\n",
    "    lr_schedule = np.interp(np.arange(1+EPOCHS*ne_iters), [0, 5*ne_iters, EPOCHS*ne_iters], [0, 1, 0])\n",
    "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_schedule.__getitem__)\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    \n",
    "    losses = []\n",
    "    for _ in tqdm(range(EPOCHS)):\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with autocast():\n",
    "                encodings = model(inputs.to(DEVICE))\n",
    "                normed_encodings = encodings / encodings.norm(dim=-1, keepdim=True)\n",
    "                logits = (100.0 * normed_encodings @ class_vectors.T)\n",
    "                remapped_labels = remap_class_idxs[labels].to(DEVICE)\n",
    "                loss = loss_fn(logits, remapped_labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            losses.append(loss.item())\n",
    "    print(evaluate(\n",
    "        model, test_loader, \n",
    "        class_vectors=class_vectors, \n",
    "        remap_class_idxs=remap_class_idxs\n",
    "    ))\n",
    "    save_model(model, save_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f4308b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates accuracy\n",
    "def evaluate(model, loader, class_vectors, remap_class_idxs=None, return_confusion=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    confusion = np.zeros((100, 100))\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            encodings = model(inputs.to(DEVICE))\n",
    "            normed_encodings = encodings / encodings.norm(dim=-1, keepdim=True)\n",
    "            outputs = normed_encodings @ class_vectors.T\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            if remap_class_idxs is not None:\n",
    "                correct += (remap_class_idxs[labels].to(DEVICE) == pred).sum().item()\n",
    "            else:\n",
    "                correct += (labels.to(DEVICE) == pred).sum().item()\n",
    "            confusion[labels.cpu().numpy(), pred.cpu().numpy()] += 1\n",
    "            total += inputs.shape[0]\n",
    "    if return_confusion:\n",
    "        return correct / total, confusion / confusion.sum(-1, keepdims=True)\n",
    "    else:\n",
    "        return correct / total\n",
    "# evaluates loss\n",
    "def evaluate1(model, loader, class_vectors, remap_class_idxs):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    pdb.set_trace()\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            encodings = model(inputs.to(DEVICE))\n",
    "            normed_encodings = encodings / encodings.norm(dim=-1, keepdim=True)\n",
    "            outputs = normed_encodings @ class_vectors.T\n",
    "            loss = F.cross_entropy(outputs, remap_class_idxs[labels].to(DEVICE))\n",
    "            losses.append(loss.item())\n",
    "    return np.array(losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "974500a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given two networks net0, net1 which each output a feature map of shape NxCxWxH\n",
    "# this will reshape both outputs to (N*W*H)xC\n",
    "# and then compute a CxC correlation matrix between the outputs of the two networks\n",
    "def run_corr_matrix(net0, net1, epochs=1, norm=True, loader=train_aug_loader, interleave=False):\n",
    "    n = epochs*len(loader)\n",
    "    mean0 = mean1 = std0 = std1 = None\n",
    "    with torch.no_grad():\n",
    "        net0.eval()\n",
    "        net1.eval()\n",
    "        for _ in range(epochs):\n",
    "            for i, (images, _) in enumerate(tqdm(loader)):\n",
    "                img_t = images.float().to(DEVICE)\n",
    "                out0 = net0(img_t)\n",
    "                out1 = net1(img_t)\n",
    "                out0 = out0.reshape(out0.shape[0], out0.shape[1], -1).permute(0, 2, 1)\n",
    "                out1 = out1.reshape(out1.shape[0], out1.shape[1], -1).permute(0, 2, 1)\n",
    "                \n",
    "                if interleave:\n",
    "                    A1, A2 = out0.chunk(2, dim=0)\n",
    "                    B1, B2 = out1.chunk(2, dim=0)\n",
    "                    out0 = torch.cat((A1, B1), dim=0)\n",
    "                    out1 = torch.cat((A2, B2), dim=0)\n",
    "                \n",
    "                out0 = out0.reshape(-1, out0.shape[2]).double()\n",
    "                out1 = out1.reshape(-1, out1.shape[2]).double()\n",
    "\n",
    "                mean0_b = out0.mean(dim=0)\n",
    "                mean1_b = out1.mean(dim=0)\n",
    "                std0_b = out0.std(dim=0)\n",
    "                std1_b = out1.std(dim=0)\n",
    "                \n",
    "                outer_b = (out0.T @ out1) / out0.shape[0]\n",
    "\n",
    "                if i == 0:\n",
    "                    mean0 = torch.zeros_like(mean0_b)\n",
    "                    mean1 = torch.zeros_like(mean1_b)\n",
    "                    std0 = torch.zeros_like(std0_b)\n",
    "                    std1 = torch.zeros_like(std1_b)\n",
    "                    outer = torch.zeros_like(outer_b)\n",
    "                mean0 += mean0_b / n\n",
    "                mean1 += mean1_b / n\n",
    "                std0 += std0_b / n\n",
    "                std1 += std1_b / n\n",
    "                outer += outer_b / n\n",
    "                \n",
    "    cov = outer - torch.outer(mean0, mean1)\n",
    "    if cov.isnan().sum() > 0: pdb.set_trace()\n",
    "    if norm:\n",
    "        corr = cov / (torch.outer(std0, std1) + 1e-4)\n",
    "        return corr.to(torch.float32)\n",
    "    else:\n",
    "        return cov.to(torch.float32)\n",
    "\n",
    "def interleave_tensors(a, b):\n",
    "    A1, A2 = a.chunk(2, dim=0)\n",
    "    B1, B2 = b.chunk(2, dim=0)\n",
    "    return (\n",
    "        torch.cat((A1, B1), dim=0), \n",
    "        torch.cat((A2, B2), dim=0)\n",
    "    )\n",
    "    \n",
    "# modifies the weight matrices of a convolution and batchnorm\n",
    "# layer given a permutation of the output channels\n",
    "def permute_output(perm_map, module2tuple, interleave=False):\n",
    "    if 'conv' in module2tuple:\n",
    "        for (a_conv, b_conv) in module2tuple['conv']:\n",
    "            a_weight = a_conv.weight\n",
    "            b_weight = b_conv.weight\n",
    "            if interleave:\n",
    "                a_weight, b_weight = interleave_tensors(a_weight, b_weight)\n",
    "            b_weight = (torch.einsum('ab,bcde->acde', perm_map, b_weight) + a_weight) / 2.\n",
    "            b_conv.weight.data = b_weight\n",
    "            a_conv.weight.data = b_weight\n",
    "            \n",
    "    if 'bn' in module2tuple:\n",
    "        for (a_bn, b_bn) in module2tuple['bn']:\n",
    "            a_weight, a_bias, a_mean, a_var = a_bn.weight, a_bn.bias, a_bn.running_mean, a_bn.running_var\n",
    "            b_weight, b_bias, b_mean, b_var = b_bn.weight, b_bn.bias, b_bn.running_mean, b_bn.running_var\n",
    "            if interleave:\n",
    "                a_weight, b_weight = interleave_tensors(a_weight, b_weight)\n",
    "                a_bias, b_bias = interleave_tensors(a_bias, b_bias)\n",
    "                a_mean, b_mean = interleave_tensors(a_mean, b_mean)\n",
    "                a_var, b_var = interleave_tensors(a_var, b_var)\n",
    "                \n",
    "            b_bn.weight.data = a_bn.weight.data = (b_weight @ perm_map.t() + a_weight) / 2.\n",
    "            b_bn.bias.data = a_bn.bias.data = (b_bias @ perm_map.t() + a_bias) / 2.\n",
    "            b_bn.running_var.data = a_bn.running_var.data = (b_var @ perm_map.t() + a_var) / 2.\n",
    "            b_bn.running_mean.data = a_bn.running_mean.data = (b_mean @ perm_map.t() + a_mean) / 2.\n",
    "#             c_bn.num_batches_tracked = (a_bn.num_batches_tracked + b_bn.num_batches_tracked) // 2\n",
    "\n",
    "# modifies the weight matrix of a convolution layer for a given\n",
    "# permutation of the input channels\n",
    "def permute_input(perm_map, conv_triples, interleave=False):\n",
    "    if not isinstance(conv_triples, list):\n",
    "        conv_triples = [conv_triples]\n",
    "    post_weights = [(c[0].weight, c[1].weight) for c in conv_triples]\n",
    "    for (a, b) in post_weights:\n",
    "        if interleave:\n",
    "            a, b = interleave_tensors(a, b)\n",
    "        if len(a.shape) == 4:\n",
    "            transform = (torch.einsum('abcd,be->aecd', b, perm_map.t()))# + a) / 2.\n",
    "        elif len(w.shape) == 2:\n",
    "            transform = (b @ perm_map.t())# + a) / 2.\n",
    "        b.data = transform\n",
    "        \n",
    "\n",
    "def permute_cls_output(perm_map, linear):\n",
    "    for w in [linear.weight, linear.bias]:\n",
    "        w.data = perm_map @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ab8c8d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_param_suffix(name):\n",
    "    for param in ['weight', 'bias', 'running_mean', 'running_var', 'num_batches_tracked']:\n",
    "        name = name.replace('.' + param, '')\n",
    "    return name\n",
    "#     return name.replace('.weight', '').replace('.bias', '').replace('.running_mean', '').replace('.')\n",
    "\n",
    "def check_similarities(model0, model1, whitelist_layers=None):\n",
    "    true_keys = []\n",
    "    false_keys = []\n",
    "    true_modules = []\n",
    "    false_modules = []\n",
    "    \n",
    "    for key, param in model0.state_dict().items():\n",
    "        module = strip_param_suffix(key)\n",
    "        if torch.allclose(param, model1.state_dict()[key]):\n",
    "            true_keys += [key]\n",
    "            true_modules += [module] if module not in true_modules else []\n",
    "        else:\n",
    "            false_keys += [key]\n",
    "            false_modules += [module] if module not in false_modules else []\n",
    "#     print('------- Aligned Keys -------')\n",
    "#     print(true_keys)\n",
    "#     print(true_modules)\n",
    "#     print('----------------------------')\n",
    "    print('------ Unaligned Keys ------')\n",
    "    print(false_keys)\n",
    "    print(false_modules)\n",
    "    return true_keys, false_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28c23bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_model(\n",
    "    model0, \n",
    "    model1,\n",
    "    model_merge,\n",
    "    transform_fn, \n",
    "    prune_threshold=-torch.inf, \n",
    "    module2io=defaultdict(lambda: dict()),\n",
    "    interleave=False,\n",
    "    check_model=None\n",
    "):\n",
    "    class Subnet(nn.Module):\n",
    "        def __init__(self, model):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "        def forward(self, x):\n",
    "            self = self.model\n",
    "            x = F.relu(self.bn1(self.conv1(x)))\n",
    "            x = self.layer1(x)\n",
    "            return x\n",
    "    models = [model0, model1]#, model1]\n",
    "    perm_map, collapse_totals = transform_fn(Subnet(model0), Subnet(model1), interleave=interleave)\n",
    "    permute_output(\n",
    "        perm_map,\n",
    "        {\n",
    "            'conv': [\n",
    "                [model.conv1 for model in  models],\n",
    "                [model.layer1[0].conv2 for model in models],\n",
    "                [model.layer1[1].conv2 for model in models],\n",
    "                [model.layer1[2].conv2 for model in models],\n",
    "            ],\n",
    "            'bn': [\n",
    "                [model.bn1 for model in models],\n",
    "                [model.layer1[0].bn2 for model in models],\n",
    "                [model.layer1[1].bn2 for model in models],\n",
    "                [model.layer1[2].bn2 for model in models],\n",
    "            ]\n",
    "        },\n",
    "        interleave=interleave\n",
    "    )\n",
    "    permute_input(\n",
    "        perm_map, \n",
    "        [\n",
    "            [model.layer1[0].conv1 for model in models],\n",
    "            [model.layer1[1].conv1 for model in models],\n",
    "            [model.layer1[2].conv1 for model in models],\n",
    "            [model.layer2[0].conv1 for model in models],\n",
    "            [model.layer2[0].shortcut[0] for model in models]\n",
    "        ],\n",
    "        interleave=interleave\n",
    "    )\n",
    "    \n",
    "    module2io['conv1']['output'] = collapse_totals\n",
    "    module2io['bn1']['output'] = collapse_totals\n",
    "    module2io['layer1.0.conv2']['output'] = collapse_totals\n",
    "    module2io['layer1.0.bn2']['output'] = collapse_totals\n",
    "    module2io['layer1.1.conv2']['output'] = collapse_totals\n",
    "    module2io['layer1.1.bn2']['output'] = collapse_totals\n",
    "    module2io['layer1.2.conv2']['output'] = collapse_totals\n",
    "    module2io['layer1.2.bn2']['output'] = collapse_totals\n",
    "\n",
    "    module2io['layer1.0.conv1']['input'] = collapse_totals\n",
    "    module2io['layer1.1.conv1']['input'] = collapse_totals\n",
    "    module2io['layer1.2.conv1']['input'] = collapse_totals\n",
    "    module2io['layer2.0.conv1']['input'] = collapse_totals\n",
    "    module2io['layer2.0.shortcut.0']['input'] = collapse_totals\n",
    "    reset_bn_stats(model0)\n",
    "    reset_bn_stats(model1)\n",
    "    class Subnet(nn.Module):\n",
    "        def __init__(self, model):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "        def forward(self, x):\n",
    "            self = self.model\n",
    "            x = F.relu(self.bn1(self.conv1(x)))\n",
    "            x = self.layer1(x)\n",
    "            x = self.layer2(x)\n",
    "            return x\n",
    "\n",
    "    perm_map, collapse_totals = transform_fn(Subnet(model0), Subnet(model1), interleave=interleave)\n",
    "\n",
    "    permute_output(\n",
    "        perm_map,\n",
    "        {\n",
    "            'conv': [\n",
    "                [model.layer2[0].conv2 for model in models],\n",
    "                [model.layer2[0].shortcut[0] for model in models],\n",
    "                [model.layer2[1].conv2 for model in models],\n",
    "                [model.layer2[2].conv2 for model in models]\n",
    "            ],\n",
    "            'bn': [\n",
    "                [model.layer2[0].bn2 for model in models],\n",
    "                [model.layer2[0].shortcut[1] for model in models],\n",
    "                [model.layer2[1].bn2 for model in models],\n",
    "                [model.layer2[2].bn2 for model in models],\n",
    "            ]\n",
    "        },\n",
    "        interleave=interleave\n",
    "    )\n",
    "    permute_input(\n",
    "        perm_map,\n",
    "        [\n",
    "            [model.layer2[1].conv1 for model in models],\n",
    "            [model.layer2[2].conv1 for model in models],\n",
    "            [model.layer3[0].conv1 for model in models],\n",
    "            [model.layer3[0].shortcut[0] for model in models]\n",
    "        ],\n",
    "        interleave=interleave\n",
    "    )\n",
    "    reset_bn_stats(model0)\n",
    "    reset_bn_stats(model1)\n",
    "    module2io['layer2.0.conv2']['output'] = collapse_totals\n",
    "    module2io['layer2.0.bn2']['output'] = collapse_totals\n",
    "    module2io['layer2.0.shortcut.0']['output'] = collapse_totals\n",
    "    module2io['layer2.0.shortcut.1']['output'] = collapse_totals\n",
    "    module2io['layer2.1.conv2']['output'] = collapse_totals\n",
    "    module2io['layer2.1.bn2']['output'] = collapse_totals\n",
    "    module2io['layer2.2.conv2']['output'] = collapse_totals\n",
    "    module2io['layer2.2.bn2']['output'] = collapse_totals\n",
    "\n",
    "    module2io['layer2.1.conv1']['input'] = collapse_totals\n",
    "    module2io['layer2.2.conv1']['input'] = collapse_totals\n",
    "    module2io['layer3.0.conv1']['input'] = collapse_totals\n",
    "    module2io['layer3.0.shortcut.0']['input'] = collapse_totals\n",
    "    \n",
    "    class Subnet(nn.Module):\n",
    "        def __init__(self, model):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "        def forward(self, x):\n",
    "            self = self.model\n",
    "            x = F.relu(self.bn1(self.conv1(x)))\n",
    "            x = self.layer1(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.layer3(x)\n",
    "            return x\n",
    "\n",
    "    perm_map, collapse_totals = transform_fn(Subnet(model0), Subnet(model1), interleave=interleave)\n",
    "\n",
    "    permute_output(\n",
    "        perm_map,\n",
    "        {\n",
    "            'conv': [\n",
    "                [model.layer3[0].conv2 for model in models],\n",
    "                [model.layer3[0].shortcut[0] for model in models],\n",
    "                [model.layer3[1].conv2 for model in models],\n",
    "                [model.layer3[2].conv2 for model in models]\n",
    "            ],\n",
    "            'bn': [\n",
    "                [model.layer3[0].bn2 for model in models],\n",
    "                [model.layer3[0].shortcut[1] for model in models],\n",
    "                [model.layer3[1].bn2 for model in models],\n",
    "                [model.layer3[2].bn2 for model in models]\n",
    "            ]\n",
    "        },\n",
    "        interleave=interleave\n",
    "    )\n",
    "    permute_input(\n",
    "        perm_map,\n",
    "        [\n",
    "            [model.layer3[1].conv1 for model in models],\n",
    "            [model.layer3[2].conv1 for model in models],\n",
    "        ],\n",
    "        interleave=interleave\n",
    "    )\n",
    "    \n",
    "    model_merge.linear.weight.data = (model1.linear.weight @ perm_map.t())# + model0.linear.weight) / 2.\n",
    "#     model_merge.linear.bias.data = (model1.linear.bias)# + model0.linear.bias) / 2.\n",
    "    reset_bn_stats(model0)\n",
    "    reset_bn_stats(model1)\n",
    "    module2io['layer3.0.conv2']['output'] = collapse_totals\n",
    "    module2io['layer3.0.bn2']['output'] = collapse_totals\n",
    "    module2io['layer3.0.shortcut.0']['output'] = collapse_totals\n",
    "    module2io['layer3.0.shortcut.1']['output'] = collapse_totals\n",
    "    module2io['layer3.1.conv2']['output'] = collapse_totals\n",
    "    module2io['layer3.1.bn2']['output'] = collapse_totals\n",
    "    module2io['layer3.2.conv2']['output'] = collapse_totals\n",
    "    module2io['layer3.2.bn2']['output'] = collapse_totals\n",
    "\n",
    "    module2io['layer3.1.conv1']['input'] = collapse_totals\n",
    "    module2io['layer3.2.conv1']['input'] = collapse_totals\n",
    "    module2io['linear']['input'] = collapse_totals\n",
    "\n",
    "    class Subnet(nn.Module):\n",
    "        def __init__(self, model, nb=9):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "            self.blocks = []\n",
    "            self.blocks += list(model.layer1)\n",
    "            self.blocks += list(model.layer2)\n",
    "            self.blocks += list(model.layer3)\n",
    "            self.blocks = nn.Sequential(*self.blocks)\n",
    "            self.bn1 = model.bn1\n",
    "            self.conv1 = model.conv1\n",
    "            self.linear = model.linear\n",
    "            self.nb = nb\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.bn1(self.conv1(x)))\n",
    "            x = self.blocks[:self.nb](x)\n",
    "            block = self.blocks[self.nb]\n",
    "            x = block.conv1(x)\n",
    "            x = block.bn1(x)\n",
    "            x = F.relu(x)\n",
    "            return x\n",
    "    \n",
    "#     blocks1 = []\n",
    "#     blocks1 += list(model1.layer1)\n",
    "#     blocks1 += list(model1.layer2)\n",
    "#     blocks1 += list(model1.layer3)\n",
    "#     blocks1 = nn.Sequential(*blocks1)\n",
    "    \n",
    "    block_idx2name = {\n",
    "        0: ('layer1.0', [model.layer1[0] for model in models]),\n",
    "        1: ('layer1.1', [model.layer1[1] for model in models]),\n",
    "        2: ('layer1.2', [model.layer1[2] for model in models]),\n",
    "        3: ('layer2.0', [model.layer2[0] for model in models]),\n",
    "        4: ('layer2.1', [model.layer2[1] for model in models]),\n",
    "        5: ('layer2.2', [model.layer2[2] for model in models]),\n",
    "        6: ('layer3.0', [model.layer3[0] for model in models]),\n",
    "        7: ('layer3.1', [model.layer3[1] for model in models]),\n",
    "        8: ('layer3.2', [model.layer3[2] for model in models]),\n",
    "    }\n",
    "\n",
    "    for nb, (block_idx, (layer_name, layers)) in zip(range(9), block_idx2name.items()):\n",
    "        perm_map, collapse_totals = transform_fn(\n",
    "            Subnet(model0, nb=nb), \n",
    "            Subnet(model1, nb=nb), \n",
    "            interleave=interleave\n",
    "        )\n",
    "        # block = blocks1[nb]\n",
    "        permute_output(\n",
    "            perm_map,\n",
    "            {\n",
    "                'conv': [\n",
    "                    [layer.conv1 for layer in layers],\n",
    "                ],\n",
    "                'bn': [\n",
    "                    [layer.bn1 for layer in layers]\n",
    "                ]\n",
    "            },\n",
    "            interleave=interleave\n",
    "        )\n",
    "        permute_input(\n",
    "            perm_map,\n",
    "            [\n",
    "                [layer.conv2 for layer in layers]\n",
    "            ],\n",
    "            interleave=interleave\n",
    "        )\n",
    "        module2io[layer_name + '.conv1']['output'] = collapse_totals\n",
    "        module2io[layer_name + '.bn1']['output'] = collapse_totals\n",
    "        module2io[layer_name + '.conv2']['output'] = collapse_totals\n",
    "        reset_bn_stats(model0)\n",
    "        reset_bn_stats(model1)\n",
    "#     _ = check_similarities(model_merge, model1)\n",
    "    return model_merge, module2io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3df0252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72907742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n"
     ]
    }
   ],
   "source": [
    "print(test_dset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7517521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in test_dset.classes]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "853aab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_model, preprocess = clip.load('ViT-B/32', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "324617b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    text_features = clip_model.encode_text(text_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daa330f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87412ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features /= text_features.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de3a92d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_vecs1 = text_features[model1_classes]\n",
    "class_vecs2 = text_features[model2_classes]\n",
    "# class_vecs1 /= class_vecs1.norm(dim=-1, keepdim=True)\n",
    "# class_vecs2 /= class_vecs2.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a36c5c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n"
     ]
    }
   ],
   "source": [
    "print(model1_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81721d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resnet20x4_v5.pth.tar',\n",
       " 'resnet20x4_v1.pth.tar',\n",
       " 'resnet20x4_CIFAR5_perm1_-infthreshold_new.pth.tar',\n",
       " 'resnet20x4_CIFAR5_procrustes_greedy.pth.tar',\n",
       " 'resnet20x4_v1_perm1_-infthreshold.pth.tar',\n",
       " 'resnet20x4_CIFAR5_bipartite_-infthreshold_new.pth.tar',\n",
       " 'resnet20x4_CIFAR5_clses[5, 7, 9, 8, 1].pth.tar',\n",
       " 'resnet20x3_v1.pth.tar',\n",
       " 'resnet20x4_v4_perm1_conv1_0param.pth.tar',\n",
       " 'resnet20x4_CIFAR5_procrustes_-infthreshold.pth.tar',\n",
       " 'resnet20x4_v5_perm1_conv1_5param.pth.tar',\n",
       " 'resnet20x4_CIFAR50_perm1_-infthreshold_new2.pth.tar',\n",
       " 'resnet20x4_v4_perm1_conv1_1param.pth.tar',\n",
       " 'resnet20x4_CIFAR50_perm1_-infthreshold_new.pth.tar',\n",
       " 'resnet20x4_v4_perm1_conv1_3param.pth.tar',\n",
       " 'resnet20x4_v4_perm1_conv1_2param.pth.tar',\n",
       " 'resnet20x4_CIFAR50_clses[50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99].pth.tar',\n",
       " 'resnet20x4_v4.pth.tar',\n",
       " 'resnet20x4_CIFAR5_procrustes.pth.tar',\n",
       " 'resnet20x4_v4_perm1_conv1_5param.pth.tar',\n",
       " 'resnet20x4_v4_perm1_conv1_10param.pth.tar',\n",
       " 'resnet20x4_CIFAR50_clses[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49].pth.tar',\n",
       " 'resnet20x4_CIFAR5_clses[3, 2, 0, 6, 4].pth.tar',\n",
       " 'resnet20x4_v6.pth.tar',\n",
       " 'resnet20x4_v2.pth.tar',\n",
       " 'resnet20x4_CIFAR5_bipartite_-infthreshold.pth.tar',\n",
       " 'resnet20x4_v3.pth.tar',\n",
       " 'resnet20x4_v1_bipartite_-infthreshold.pth.tar',\n",
       " 'resnet20x2_v1.pth.tar',\n",
       " 'resnet20x4_v2_perm1_-infthreshold.pth.tar',\n",
       " 'resnet20x4_CIFAR5_perm1_-infthreshold.pth.tar',\n",
       " 'resnet20x4_v4_perm1_conv1_32param.pth.tar',\n",
       " 'resnet20x4_v2_bipartite_-infthreshold.pth.tar']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/srv/share/gstoica3/checkpoints/REPAIR/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fb75853",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\n",
    "    os.path.join(\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}.pth.tar'\n",
    "    )\n",
    "):\n",
    "    print('training model...')\n",
    "    model1 = resnet20(w=4).to(DEVICE)\n",
    "    train(\n",
    "        f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}', \n",
    "        model=model1, \n",
    "        class_vectors=class_vecs1,\n",
    "        train_loader=train_aug_loader1,\n",
    "        test_loader=test_loader1,\n",
    "        remap_class_idxs=class_idxs\n",
    "    )\n",
    "if not os.path.exists(\n",
    "    os.path.join(\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}.pth.tar'\n",
    "    )89\n",
    "):\n",
    "    print('training model...')\n",
    "    model2 = resnet20(w=4).to(DEVICE)\n",
    "    train(\n",
    "        f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}', \n",
    "        model=model2, \n",
    "        class_vectors=class_vecs2,\n",
    "        train_loader=train_aug_loader2,\n",
    "        test_loader=test_loader2,\n",
    "        remap_class_idxs=class_idxs\n",
    "    )\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef35cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1342bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b7d2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808828fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7562bd57",
   "metadata": {},
   "source": [
    "# Combine models and evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03612a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_param_suffix(name):\n",
    "    return name.replace('.weight', '').replace('.bias', '')\n",
    "\n",
    "def combine_io_masks(io, param):\n",
    "    mask = torch.zeros_like(param, device=param.device)\n",
    "    try:\n",
    "        if 'output' in io:\n",
    "            mask[io['output'].view(-1) == 0] = 1.\n",
    "        if 'input' in io and len(mask.shape) > 1:\n",
    "            mask[:, io['input'].view(-1) == 0] = 1.\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "    return mask\n",
    "\n",
    "def mix_weights(model, alpha, key0, key1, module2io=None, whitelist_fn=lambda x: True):\n",
    "    sd0 = torch.load(\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/%s.pth.tar' % key0, \n",
    "        map_location=torch.device(DEVICE)\n",
    "    )\n",
    "    sd1 = torch.load(\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/%s.pth.tar' % key1, \n",
    "        map_location=torch.device(DEVICE)\n",
    "    )\n",
    "    sd_alpha = {}\n",
    "    for k in sd0.keys():\n",
    "        param0 = sd0[k].to(DEVICE)\n",
    "        param1 = sd1[k].to(DEVICE)\n",
    "        sd_alpha[k] = (1 - alpha) * param0 + alpha * param1\n",
    "        \n",
    "        if module2io is not None:\n",
    "            param_base = strip_param_suffix(k)\n",
    "#             pdb.set_trace()\n",
    "            mask = combine_io_masks(module2io[param_base], param1)\n",
    "            sd_alpha[k][mask == 1] = param0[mask == 1].to(sd_alpha[k].dtype)\n",
    "        \n",
    "        if not whitelist_fn(k):\n",
    "            sd_alpha[k] = param0\n",
    "    model.load_state_dict(sd_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09128919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4c690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b418e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_model = resnet20(w=4).to(DEVICE)\n",
    "\n",
    "mix_weights(\n",
    "    avg_model, \n",
    "    .5, \n",
    "    f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}',\n",
    "    f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "713afe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "_, confusion = evaluate_texthead(avg_model, test_loader, class_vectors=text_features, return_confusion=True) \n",
    "print(np.diag(confusion).round(3).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27448814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the train loader with data augmentation as this gives better results\n",
    "def reset_bn_stats(model, epochs=1, loader=train_aug_loader):\n",
    "    # resetting stats to baseline first as below is necessary for stability\n",
    "    for m in model.modules():\n",
    "        if type(m) == nn.BatchNorm2d:\n",
    "            m.momentum = None # use simple average\n",
    "            m.reset_running_stats()\n",
    "    # run a single train epoch with augmentations to recalc stats\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        with torch.no_grad(), autocast():\n",
    "            for images, _ in loader:\n",
    "                output = model(images.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a379cc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-reset:\n",
      "0.4192\n"
     ]
    }
   ],
   "source": [
    "reset_bn_stats(avg_model)\n",
    "print('Post-reset:')\n",
    "print(\n",
    "    evaluate(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575128d",
   "metadata": {},
   "source": [
    "# Combine models via permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccdaa9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perm_map(corr_mtx):\n",
    "    # sort the (i, j) channel pairs by correlation\n",
    "    nchan = corr_mtx.shape[0]\n",
    "    triples = [(i, j, corr_mtx[i, j].item()) for i in range(nchan) for j in range(nchan)]\n",
    "    triples = sorted(triples, key=lambda p: -p[2])\n",
    "    # greedily find a matching\n",
    "    perm_d = {}\n",
    "    for i, j, c in triples:\n",
    "        if not (i in perm_d.keys() or j in perm_d.values()):\n",
    "            perm_d[i] = j\n",
    "    perm_map = torch.tensor([perm_d[i] for i in range(nchan)])\n",
    "\n",
    "    # qual_map will be a permutation of the indices in the order\n",
    "    # of the quality / degree of correlation between the neurons found in the permutation.\n",
    "    # this just for visualization purposes.\n",
    "    qual_l = [corr_mtx[i, perm_map[i]].item() for i in range(nchan)]\n",
    "    qual_map = torch.tensor(sorted(range(nchan), key=lambda i: -qual_l[i]))\n",
    "\n",
    "    return perm_map, qual_map\n",
    "\n",
    "def get_layer_perm1(\n",
    "    corr_mtx, method='max_weight', vizz=False, \n",
    "    prune_threshold=-torch.inf, interleave=False\n",
    "):\n",
    "    if method == 'greedy':\n",
    "        perm_map, qual_map = compute_perm_map(corr_mtx)\n",
    "        if vizz:\n",
    "            corr_mtx_viz = (corr_mtx[qual_map].T[perm_map[qual_map]]).T\n",
    "            viz(corr_mtx_viz)\n",
    "    elif method == 'max_weight':\n",
    "        corr_mtx_a = corr_mtx.cpu().numpy()\n",
    "        row_ind, col_ind = scipy.optimize.linear_sum_assignment(corr_mtx_a, maximize=True)\n",
    "        assert (row_ind == np.arange(len(corr_mtx_a))).all()\n",
    "        perm_map = torch.tensor(col_ind).long()\n",
    "        perm_map = torch.eye(corr_mtx.shape[0], device=corr_mtx.device)[perm_map]\n",
    "    else:\n",
    "        raise Exception('Unknown method: %s' % method)\n",
    "    \n",
    "#     pdb.set_trace()\n",
    "    pruned_elements = torch.from_numpy(\n",
    "        corr_mtx_a[row_ind, col_ind] >= prune_threshold\n",
    "    ).to(perm_map.device).to(torch.float32)\n",
    "    return perm_map, pruned_elements\n",
    "\n",
    "# returns the channel-permutation to make layer1's activations most closely\n",
    "# match layer0's.\n",
    "def get_layer_perm(net0, net1, method='max_weight', vizz=False, prune_threshold=-torch.inf, interleave=False):\n",
    "    corr_mtx = run_corr_matrix(net0, net1, interleave=interleave)\n",
    "    return get_layer_perm1(\n",
    "        corr_mtx, method=method, vizz=vizz, \n",
    "        prune_threshold=prune_threshold, \n",
    "        interleave=interleave\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee033a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3633cd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778\n",
      "0.7758\n"
     ]
    }
   ],
   "source": [
    "modela = resnet20(w=4).to(DEVICE)\n",
    "modelb = resnet20(w=4).to(DEVICE)\n",
    "load_model(modela, f'resnet20x4_CIFAR50_clses{model1_classes.tolist()}')\n",
    "load_model(modelb, f'resnet20x4_CIFAR50_clses{model2_classes.tolist()}')\n",
    "\n",
    "print(evaluate(modela, test_loader1, class_vecs1, remap_class_idxs=class_idxs))\n",
    "print(evaluate(modelb, test_loader2, class_vecs2, remap_class_idxs=class_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2c1ad63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model = resnet20(w=4).to(DEVICE)\n",
    "load_model(check_model, f'resnet20x4_CIFAR50_perm1_{prune_threshold}threshold_new2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b01a2697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3904\n",
      "0.3884\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(modela, test_loader, class_vectors=text_features))\n",
    "print(evaluate(modelb, test_loader, class_vectors=text_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "941a6624",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_threshold = -torch.inf\n",
    "from collections import defaultdict\n",
    "module2io = defaultdict(lambda: dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b23f393",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:10<00:00,  9.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 24.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:05<00:00, 18.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 12.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:10<00:00,  9.96it/s]\n"
     ]
    }
   ],
   "source": [
    "model_merge = resnet20(w=4).to(DEVICE)\n",
    "# model_merge.eval()\n",
    "# modela.eval()\n",
    "# modelb.eval()\n",
    "model_merge, module2io = transform_model(\n",
    "    modela, \n",
    "    modelb, \n",
    "    model_merge=modelb,\n",
    "    transform_fn=get_layer_perm, \n",
    "    prune_threshold=-torch.inf, \n",
    "    module2io=module2io,\n",
    "    interleave=True,\n",
    "    check_model=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbeeae43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0103"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model_merge, test_loader, class_vectors=text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54453145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0103"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_bn_stats(model_merge)\n",
    "evaluate(model_merge, test_loader, class_vectors=text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4f3f5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model_merge, f'resnet20x4_CIFAR50_perm1_{prune_threshold}threshold_new3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c61fa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0168\n",
      "Post-reset:\n",
      "0.3594\n"
     ]
    }
   ],
   "source": [
    "avg_model = resnet20(w=4).to(DEVICE)\n",
    "\n",
    "mix_weights(\n",
    "    avg_model, \n",
    "    .5, \n",
    "    f'resnet20x4_CIFAR50_clses{model1_classes.tolist()}',\n",
    "    f'resnet20x4_CIFAR50_perm1_{prune_threshold}threshold_new3',\n",
    "    whitelist_fn =lambda x: True#lambda x: 'bn' not in strip_param_suffix(x)\n",
    ")\n",
    "\n",
    "print(\n",
    "    evaluate_texthead(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ")\n",
    "reset_bn_stats(avg_model)\n",
    "print('Post-reset:')\n",
    "acc, confusion = evaluate_texthead(\n",
    "    avg_model, \n",
    "    test_loader, \n",
    "    class_vectors=text_features,\n",
    "    return_confusion=True\n",
    ")\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b11d07f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.2, 0.02, 0.31, 0.59, 0.22, 0.28, 0.25, 0.5, 0.27, 0.19, 0.0, 0.36, 0.19, 0.19, 0.29, 0.33, 0.59, 0.44, 0.13, 0.92, 0.18, 0.26, 0.53, 0.47, 0.25, 0.18, 0.35, 0.35, 0.17, 0.36, 0.09, 0.3, 0.34, 0.57, 0.09, 0.84, 0.05, 0.13, 0.32, 0.33, 0.45, 0.35, 0.38, 0.21, 0.11, 0.02, 0.67, 0.81, 0.67, 0.1, 0.16, 0.41, 0.67, 0.63, 0.1, 0.57, 0.79, 0.84, 0.31, 0.24, 0.74, 0.44, 0.13, 0.1, 0.02, 0.35, 0.02, 0.84, 0.29, 0.17, 0.14, 0.12, 0.15, 0.46, 0.5, 0.82, 0.1, 0.56, 0.65, 0.01, 0.66, 0.73, 0.36, 0.15, 0.31, 0.61, 0.1, 0.69, 0.38, 0.51, 0.29, 0.06, 0.18, 0.86, 0.69, 0.26, 0.16, 0.86, 0.54]\n"
     ]
    }
   ],
   "source": [
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "457c964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates accuracy\n",
    "def evaluate_texthead(model, loader, class_vectors, remap_class_idxs=None, return_confusion=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    confusion = np.zeros((100, 100))\n",
    "    \n",
    "    totals = [0] * class_vectors.shape[0]\n",
    "    corrects = [0] * class_vectors.shape[0]\n",
    "    \n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            encodings = model(inputs.to(DEVICE))\n",
    "            normed_encodings = encodings / encodings.norm(dim=-1, keepdim=True)\n",
    "            outputs = normed_encodings @ class_vectors.T\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            if remap_class_idxs is not None:\n",
    "                correct += (remap_class_idxs[labels].to(DEVICE) == pred).sum().item()\n",
    "            else:\n",
    "                for gt, p in zip(labels, pred):\n",
    "                    totals[gt] += 1\n",
    "                    \n",
    "                    if gt == p:\n",
    "                        correct += 1\n",
    "                        corrects[gt] += 1\n",
    "                \n",
    "#                 correct += (labels.to(DEVICE) == pred).sum().item()\n",
    "                \n",
    "            confusion[labels.cpu().numpy(), pred.cpu().numpy()] += 1\n",
    "            total += inputs.shape[0]\n",
    "    if return_confusion:\n",
    "        return correct / sum(totals), list(map(lambda a: a[0] / a[1], zip(corrects, totals)))\n",
    "    else:\n",
    "        return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b6e4b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.18, 0.03, 0.31, 0.58, 0.19, 0.33, 0.23, 0.41, 0.27, 0.17, 0.0, 0.35, 0.19, 0.21, 0.33, 0.37, 0.61, 0.42, 0.11, 0.94, 0.22, 0.24, 0.53, 0.43, 0.28, 0.18, 0.36, 0.38, 0.18, 0.42, 0.12, 0.33, 0.35, 0.57, 0.07, 0.81, 0.05, 0.16, 0.31, 0.29, 0.45, 0.37, 0.42, 0.23, 0.1, 0.01, 0.68, 0.74, 0.63, 0.05, 0.16, 0.43, 0.65, 0.64, 0.09, 0.63, 0.79, 0.84, 0.27, 0.24, 0.72, 0.42, 0.13, 0.11, 0.03, 0.34, 0.02, 0.84, 0.31, 0.15, 0.12, 0.1, 0.13, 0.42, 0.46, 0.8, 0.05, 0.55, 0.59, 0.01, 0.69, 0.72, 0.37, 0.09, 0.29, 0.59, 0.12, 0.63, 0.5, 0.5, 0.35, 0.07, 0.19, 0.89, 0.71, 0.23, 0.16, 0.88, 0.46]\n"
     ]
    }
   ],
   "source": [
    "_, confusion = evaluate_texthead(avg_model, test_loader, class_vectors=text_features, return_confusion=True) \n",
    "# print(np.diag(confusion).round(3).tolist())\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915a7269",
   "metadata": {},
   "source": [
    "# Combine Models via Bipartite Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ed86e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bipartite_perm(corr, prune_threshold=-torch.inf):\n",
    "    scores, idx = corr.max(0)\n",
    "    valid_elements = scores >= prune_threshold\n",
    "    idx = torch.where(valid_elements, idx, corr.shape[0])\n",
    "    location_lookup = torch.eye(corr.shape[0]+1, corr.shape[0], device=corr.device)\n",
    "    matches = location_lookup[idx]\n",
    "    totals = matches.sum(0, keepdim=True)\n",
    "    matches = matches / (totals + 1)\n",
    "    return matches.t(), totals\n",
    "\n",
    "def get_layer_bipartite_transform(net0, net1, prune_threshold=-torch.inf, interleave=False):\n",
    "    corr_mtx = run_corr_matrix(net0, net1)\n",
    "    return get_bipartite_perm(corr_mtx, prune_threshold=prune_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "deff07b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778\n",
      "0.7758\n"
     ]
    }
   ],
   "source": [
    "modela = resnet20(w=4).to(DEVICE)\n",
    "modelb = resnet20(w=4).to(DEVICE)\n",
    "modelc = resnet20(w=4).to(DEVICE)\n",
    "load_model(modela, f'resnet20x4_CIFAR50_clses{model1_classes.tolist()}')\n",
    "load_model(modelb, f'resnet20x4_CIFAR50_clses{model2_classes.tolist()}')\n",
    "load_model(modelc, f'resnet20x4_CIFAR50_clses{model2_classes.tolist()}')\n",
    "\n",
    "print(evaluate(modela, test_loader1, class_vecs1, remap_class_idxs=class_idxs))\n",
    "print(evaluate(modelb, test_loader2, class_vecs2, remap_class_idxs=class_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78c9232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_threshold = -torch.inf\n",
    "from collections import defaultdict\n",
    "module2io = defaultdict(lambda: dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ccbfde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 23.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:05<00:00, 19.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 12.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.16it/s]\n"
     ]
    }
   ],
   "source": [
    "model_to_alter, module2io = transform_model(\n",
    "    modela, \n",
    "    modelb, \n",
    "    model_merge=modelb,\n",
    "    transform_fn=get_layer_bipartite_transform, \n",
    "    prune_threshold=-torch.inf, \n",
    "    module2io=module2io\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7491c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model_to_alter, f'resnet20x4_CIFAR50_bipartite_{prune_threshold}threshold_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b978cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014\n",
      "Post-reset:\n",
      "0.3977\n"
     ]
    }
   ],
   "source": [
    "avg_model = resnet20(w=4).to(DEVICE)\n",
    "\n",
    "mix_weights(\n",
    "    avg_model, \n",
    "    .5, \n",
    "    f'resnet20x4_CIFAR50_clses{model1_classes.tolist()}',\n",
    "    f'resnet20x4_CIFAR50_bipartite_{prune_threshold}threshold_new',\n",
    "    whitelist_fn=lambda x: 'bn' not in strip_param_suffix(x)\n",
    ")\n",
    "\n",
    "print(\n",
    "    evaluate(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ")\n",
    "reset_bn_stats(avg_model)\n",
    "print('Post-reset:')\n",
    "# print(\n",
    "#     evaluate(\n",
    "#         avg_model, \n",
    "#         test_loader, \n",
    "#         class_vectors=text_features\n",
    "#     )\n",
    "# )\n",
    "\n",
    "acc, confusion = evaluate_texthead(\n",
    "    avg_model, \n",
    "    test_loader, \n",
    "    class_vectors=text_features,\n",
    "    return_confusion=True\n",
    ")\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9a660cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93, 0.91, 0.68, 0.65, 0.79, 0.78, 0.83, 0.76, 0.95, 0.88, 0.57, 0.54, 0.87, 0.82, 0.77, 0.85, 0.76, 0.91, 0.7, 0.67, 0.9, 0.88, 0.8, 0.9, 0.87, 0.64, 0.72, 0.62, 0.82, 0.79, 0.82, 0.71, 0.77, 0.76, 0.86, 0.65, 0.93, 0.87, 0.68, 0.92, 0.8, 0.93, 0.85, 0.84, 0.57, 0.57, 0.58, 0.9, 0.93, 0.91, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.1, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905ffd7b",
   "metadata": {},
   "source": [
    "# Combine Via Procrustes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "5d7d7c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_procrustes(corr_mtx):\n",
    "    U, _, Vh = torch.linalg.svd(corr_mtx)\n",
    "    return U @ Vh\n",
    "\n",
    "# returns the channel-permutation to make layer1's activations most closely\n",
    "# match layer0's.\n",
    "def get_layer_procrustes(net0, net1, prune_threshold=None):\n",
    "    corr_mtx = run_corr_matrix(net0, net1)\n",
    "    try:\n",
    "        return get_procrustes(corr_mtx), torch.ones(corr_mtx.shape[0], device=corr_mtx.device)\n",
    "    except:\n",
    "        print('Applying Permutation')\n",
    "        pdb.set_trace()\n",
    "        return get_layer_perm1(corr_mtx, 'max_weight', vizz=False, prune_threshold=prune_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "93505eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9558\n",
      "0.9726\n",
      "0.9726\n"
     ]
    }
   ],
   "source": [
    "model0 = resnet20(w=4).to(DEVICE)\n",
    "model1 = resnet20(w=4).to(DEVICE)\n",
    "model_to_alter = resnet20(w=4).to(DEVICE)\n",
    "\n",
    "load_model(model0, f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}')\n",
    "load_model(model1, f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}')\n",
    "load_model(model_to_alter, f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}')\n",
    "\n",
    "print(evaluate(model0, test_loader1, class_vecs1, remap_class_idxs=class_idxs))\n",
    "print(evaluate(model1, test_loader2, class_vecs2, remap_class_idxs=class_idxs))\n",
    "print(evaluate(model_to_alter, test_loader2, class_vecs2, remap_class_idxs=class_idxs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "c096ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_threshold = -torch.inf\n",
    "from collections import defaultdict\n",
    "module2io = defaultdict(lambda: dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "0211cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given two networks net0, net1 which each output a feature map of shape NxCxWxH\n",
    "# this will reshape both outputs to (N*W*H)xC\n",
    "# and then compute a CxC correlation matrix between the outputs of the two networks\n",
    "def run_corr_matrix(net0, net1, epochs=1, norm=True, loader=train_aug_loader):\n",
    "    n = epochs*len(loader)\n",
    "    mean0 = mean1 = std0 = std1 = None\n",
    "    with torch.no_grad():\n",
    "        net0.eval()\n",
    "        net1.eval()\n",
    "        for _ in range(epochs):\n",
    "            for i, (images, _) in enumerate(tqdm(loader)):\n",
    "                img_t = images.float().to(DEVICE)\n",
    "                out0 = net0(img_t)\n",
    "                out0 = out0.reshape(out0.shape[0], out0.shape[1], -1).permute(0, 2, 1)\n",
    "                out0 = out0.reshape(-1, out0.shape[2]).double()\n",
    "\n",
    "                out1 = net1(img_t)\n",
    "                out1 = out1.reshape(out1.shape[0], out1.shape[1], -1).permute(0, 2, 1)\n",
    "                out1 = out1.reshape(-1, out1.shape[2]).double()\n",
    "\n",
    "                mean0_b = out0.mean(dim=0)\n",
    "                mean1_b = out1.mean(dim=0)\n",
    "                std0_b = out0.std(dim=0)\n",
    "                std1_b = out1.std(dim=0)\n",
    "                outer_b = (out0.T @ out1) / out0.shape[0]\n",
    "\n",
    "                if i == 0:\n",
    "                    mean0 = torch.zeros_like(mean0_b)\n",
    "                    mean1 = torch.zeros_like(mean1_b)\n",
    "                    std0 = torch.zeros_like(std0_b)\n",
    "                    std1 = torch.zeros_like(std1_b)\n",
    "                    outer = torch.zeros_like(outer_b)\n",
    "                mean0 += mean0_b / n\n",
    "                mean1 += mean1_b / n\n",
    "                std0 += std0_b / n\n",
    "                std1 += std1_b / n\n",
    "                outer += outer_b / n\n",
    "                if outer.isnan().sum() > 0: pdb.set_trace()\n",
    "                \n",
    "    cov = outer - torch.outer(mean0, mean1)\n",
    "    if cov.isnan().sum() > 0: pdb.set_trace()\n",
    "    if norm:\n",
    "        corr = cov / (torch.outer(std0, std1) + 1e-4)\n",
    "        return corr.to(torch.float32)\n",
    "    else:\n",
    "        return cov.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "d3ea55f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.57it/s]\n"
     ]
    }
   ],
   "source": [
    "class Subnet(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        self = self.model\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        return x\n",
    "# corr = run_corr_matrix(Subnet(model0), Subnet(model1))\n",
    "# perm_map1 = get_layer_perm1(corr)\n",
    "perm_map, collapse_totals = get_layer_procrustes(Subnet(model0), Subnet(model1))\n",
    "permute_output(perm_map, model_to_alter.conv1, model_to_alter.bn1)\n",
    "permute_output(perm_map, model_to_alter.layer1[0].conv2, model_to_alter.layer1[0].bn2)\n",
    "permute_output(perm_map, model_to_alter.layer1[1].conv2, model_to_alter.layer1[1].bn2)\n",
    "permute_output(perm_map, model_to_alter.layer1[2].conv2, model_to_alter.layer1[2].bn2)\n",
    "permute_input(perm_map, [model_to_alter.layer1[0].conv1, model_to_alter.layer1[1].conv1, model_to_alter.layer1[2].conv1])\n",
    "permute_input(perm_map, [model_to_alter.layer2[0].conv1, model_to_alter.layer2[0].shortcut[0]])\n",
    "\n",
    "module2io['conv1']['output'] = collapse_totals\n",
    "module2io['bn1']['output'] = collapse_totals\n",
    "module2io['layer1.0.conv2']['output'] = collapse_totals\n",
    "module2io['layer1.0.bn2']['output'] = collapse_totals\n",
    "module2io['layer1.1.conv2']['output'] = collapse_totals\n",
    "module2io['layer1.1.bn2']['output'] = collapse_totals\n",
    "module2io['layer1.2.conv2']['output'] = collapse_totals\n",
    "module2io['layer1.2.bn2']['output'] = collapse_totals\n",
    "\n",
    "module2io['layer1.0.conv1']['input'] = collapse_totals\n",
    "module2io['layer1.1.conv1']['input'] = collapse_totals\n",
    "module2io['layer1.2.conv1']['input'] = collapse_totals\n",
    "module2io['layer2.0.conv1']['input'] = collapse_totals\n",
    "module2io['layer2.0.shortcut.0']['input'] = collapse_totals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "24775f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subnet(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        self = self.model\n",
    "        x = self.conv1(x)\n",
    "#         x = F.relu(self.bn1(self.conv1(x)))\n",
    "#         x = self.layer1(x)\n",
    "#         x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "f5fa1306",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_alter.eval()\n",
    "for (images, _) in train_aug_loader:\n",
    "    if model_to_alter.bn1(Subnet(model_to_alter)(images.to(DEVICE))).isnan().sum() > 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "b0c67a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.eval()\n",
    "model_to_alter.eval()\n",
    "x = Subnet(model_to_alter)(images.to(DEVICE))\n",
    "y = Subnet(model1)(images.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0859b2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.30it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:10<00:00,  9.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 23.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:05<00:00, 18.30it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 14.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 12.78it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:10<00:00, 10.00it/s]\n"
     ]
    }
   ],
   "source": [
    "model_to_alter, module2io = transform_model(\n",
    "    model0, \n",
    "    model1, \n",
    "    model_to_alter, \n",
    "    transform_fn=get_layer_procrustes, \n",
    "    prune_threshold=-torch.inf, \n",
    "    module2io=module2io\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "dfe4a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model_to_alter, f'resnet20x4_CIFAR5_procrustes_{prune_threshold}threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "40475731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-reset:\n",
      "0.1\n",
      "Post-reset:\n",
      "0.4774\n"
     ]
    }
   ],
   "source": [
    "avg_model = resnet20(w=4).to(DEVICE)\n",
    "\n",
    "mix_weights(\n",
    "    avg_model, \n",
    "    .5, \n",
    "    f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}',\n",
    "    f'resnet20x4_CIFAR5_procrustes_{prune_threshold}threshold',\n",
    "#     whitelist_fn=lambda x: x in ['conv1']\n",
    ")\n",
    "\n",
    "print('Pre-reset:')\n",
    "print(\n",
    "    evaluate(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ")\n",
    "reset_bn_stats(avg_model)\n",
    "print('Post-reset:')\n",
    "print(\n",
    "    evaluate(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556b7b06",
   "metadata": {},
   "source": [
    "# Procrustes Via Weight Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2c32e2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_procrustes(corr_mtx):\n",
    "    U, _, Vh = torch.linalg.svd(corr_mtx)\n",
    "    return U @ Vh\n",
    "\n",
    "# returns the channel-permutation to make layer1's activations most closely\n",
    "# match layer0's.\n",
    "def get_layer_procrustes(pairs):\n",
    "    objective = None\n",
    "    for pair in pairs:\n",
    "#         pdb.set_trace()\n",
    "        pair_obj = pair[0] @ pair[1].t()\n",
    "        objective = objective + pair_obj if objective is not None else pair_obj\n",
    "    return get_procrustes(objective)\n",
    "\n",
    "prep_input_conv = lambda conv: conv.weight.permute(1, 0, 2, 3).flatten(1)\n",
    "prep_output_conv = lambda conv: conv.weight.flatten(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "250d34f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9558\n",
      "0.9726\n"
     ]
    }
   ],
   "source": [
    "model0 = resnet20(w=4).to(DEVICE)\n",
    "model1 = resnet20(w=4).to(DEVICE)\n",
    "model_to_alter = resnet20(w=4).to(DEVICE)\n",
    "\n",
    "load_model(model0, f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}')\n",
    "load_model(model1, f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}')\n",
    "# load_model(model_to_alter, f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}')\n",
    "\n",
    "print(evaluate(model0, test_loader1, class_vecs1, remap_class_idxs=class_idxs))\n",
    "print(evaluate(model1, test_loader2, class_vecs2, remap_class_idxs=class_idxs))\n",
    "# print(evaluate(model_to_alter, test_loader2, class_vecs2, remap_class_idxs=class_idxs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d559d",
   "metadata": {},
   "source": [
    "### Alter Inputs and Outputs of fir Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1ff2463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 | Norm Differences:  Models - 195.26661682128906, Inter Iters - 195.26661682128906\n",
      "Iteration 100 | Norm Differences:  Models - 153.6870574951172, Inter Iters - 0.0\n",
      "Iteration 200 | Norm Differences:  Models - 152.7029571533203, Inter Iters - 0.0\n"
     ]
    }
   ],
   "source": [
    "def compare_state_dicts(sd0, sd1):\n",
    "    total_norm = 0.\n",
    "    for key in sd0:\n",
    "        p0 = sd0[key]\n",
    "        p1 = sd1[key]\n",
    "        total_norm += torch.square(p0-p1).sum().sqrt()\n",
    "    return total_norm\n",
    "\n",
    "prev_sd = model0.state_dict()\n",
    "\n",
    "for j in range(300):\n",
    "    if j % 100 == 0:\n",
    "        print('Iteration {} | Norm Differences:  Models - {}, Inter Iters - {}'.format(\n",
    "            j, \n",
    "            compare_state_dicts(model0.state_dict(), model1.state_dict()),\n",
    "            compare_state_dicts(prev_sd, model1.state_dict()),\n",
    "        ))\n",
    "    conv1_procrustes = get_layer_procrustes(\n",
    "        [\n",
    "            # Affected Outputs\n",
    "            (\n",
    "                prep_output_conv(model0.conv1), \n",
    "                prep_output_conv(model1.conv1)\n",
    "            ),\n",
    "            (\n",
    "                prep_output_conv(model0.layer1[0].conv2),\n",
    "                prep_output_conv(model1.layer1[0].conv2),\n",
    "            ),\n",
    "            (\n",
    "                prep_output_conv(model0.layer1[1].conv2),\n",
    "                prep_output_conv(model1.layer1[1].conv2),\n",
    "            ),\n",
    "            (\n",
    "                prep_output_conv(model0.layer1[2].conv2),\n",
    "                prep_output_conv(model1.layer1[2].conv2),\n",
    "            ),\n",
    "            # Affected Inputs\n",
    "            (\n",
    "                prep_input_conv(model0.layer1[0].conv1), \n",
    "                prep_input_conv(model1.layer1[0].conv1)\n",
    "            ),\n",
    "            (\n",
    "                prep_input_conv(model0.layer1[1].conv1), \n",
    "                prep_input_conv(model1.layer1[1].conv1)\n",
    "            ),\n",
    "            (\n",
    "                prep_input_conv(model0.layer1[2].conv1), \n",
    "                prep_input_conv(model1.layer1[2].conv1)\n",
    "            ),\n",
    "            (\n",
    "                prep_input_conv(model0.layer2[0].conv1), \n",
    "                prep_input_conv(model1.layer2[0].conv1)\n",
    "            ),\n",
    "            (\n",
    "                prep_input_conv(model0.layer2[0].shortcut[0]), \n",
    "                prep_input_conv(model1.layer2[0].shortcut[0])\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    permute_output(conv1_procrustes, model1.conv1, model1.bn1)\n",
    "    permute_output(conv1_procrustes, model1.layer1[0].conv2, model1.layer1[0].bn2)\n",
    "    permute_output(conv1_procrustes, model1.layer1[1].conv2, model1.layer1[1].bn2)\n",
    "    permute_output(conv1_procrustes, model1.layer1[2].conv2, model1.layer1[2].bn2)\n",
    "\n",
    "    permute_input(conv1_procrustes, [model1.layer1[0].conv1, model1.layer1[1].conv1, model1.layer1[2].conv1])\n",
    "    permute_input(conv1_procrustes, [model1.layer2[0].conv1, model1.layer2[0].shortcut[0]])\n",
    "\n",
    "    second_residual_transform = get_layer_procrustes(\n",
    "        [\n",
    "            # Affected Outputs\n",
    "            (\n",
    "                prep_output_conv(model0.layer2[0].shortcut[0]),\n",
    "                prep_output_conv(model1.layer2[0].shortcut[0]),\n",
    "            ),\n",
    "            (\n",
    "                prep_output_conv(model0.layer2[0].conv2),\n",
    "                prep_output_conv(model1.layer2[0].conv2)\n",
    "            ),\n",
    "            (\n",
    "                prep_output_conv(model0.layer2[1].conv2),\n",
    "                prep_output_conv(model1.layer2[1].conv2)\n",
    "            ),\n",
    "            (\n",
    "                prep_output_conv(model0.layer2[2].conv2),\n",
    "                prep_output_conv(model1.layer2[2].conv2)\n",
    "            ),\n",
    "            # Affected Inputs\n",
    "            (\n",
    "                prep_input_conv(model0.layer2[1].conv1),\n",
    "                prep_input_conv(model1.layer2[1].conv1)\n",
    "            ),\n",
    "            (\n",
    "                prep_input_conv(model0.layer2[2].conv1),\n",
    "                prep_input_conv(model1.layer2[2].conv1),\n",
    "            ),\n",
    "            (\n",
    "                prep_input_conv(model0.layer3[0].conv1),\n",
    "                prep_input_conv(model1.layer3[0].conv1),\n",
    "            ),\n",
    "            (\n",
    "                prep_input_conv(model0.layer3[0].shortcut[0]),\n",
    "                prep_input_conv(model1.layer3[0].shortcut[0]),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    permute_output(second_residual_transform, model1.layer2[0].shortcut[0], model1.layer2[0].shortcut[1])\n",
    "    permute_output(second_residual_transform, model1.layer2[0].conv2, model1.layer2[0].bn2)\n",
    "    permute_output(second_residual_transform, model1.layer2[1].conv2, model1.layer2[1].bn2)\n",
    "    permute_output(second_residual_transform, model1.layer2[2].conv2, model1.layer2[2].bn2)\n",
    "\n",
    "    permute_input(second_residual_transform, [model1.layer2[1].conv1, model1.layer2[2].conv1])\n",
    "    permute_input(second_residual_transform, [model1.layer3[0].conv1, model1.layer3[0].shortcut[0]])\n",
    "    \n",
    "    third_residual_transform = get_layer_procrustes(\n",
    "        [\n",
    "            # Affected Outputs\n",
    "            (\n",
    "                prep_output_conv(model0.layer3[0].shortcut[0]),\n",
    "                prep_output_conv(model1.layer3[0].shortcut[0])\n",
    "            ),\n",
    "            (\n",
    "                prep_output_conv(model0.layer3[0].conv2),\n",
    "                prep_output_conv(model1.layer3[0].conv2)\n",
    "            ),\n",
    "            (\n",
    "                prep_output_conv(model0.layer3[1].conv2),\n",
    "                prep_output_conv(model1.layer3[1].conv2),\n",
    "            ),\n",
    "            (\n",
    "                prep_output_conv(model0.layer3[2].conv2),\n",
    "                prep_output_conv(model1.layer3[2].conv2),\n",
    "            ),\n",
    "            # Affected Inputs\n",
    "            (\n",
    "                prep_input_conv(model0.layer3[1].conv1),\n",
    "                prep_input_conv(model1.layer3[1].conv1)\n",
    "            ),\n",
    "            (\n",
    "                prep_input_conv(model0.layer3[2].conv1),\n",
    "                prep_input_conv(model1.layer3[2].conv1)\n",
    "            ),\n",
    "            (\n",
    "                model0.linear.weight.T,\n",
    "                model1.linear.weight.T\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    permute_output(third_residual_transform, model1.layer3[0].shortcut[0], model1.layer3[0].shortcut[1])\n",
    "    permute_output(third_residual_transform, model1.layer3[0].conv2, model1.layer3[0].bn2)\n",
    "    permute_output(third_residual_transform, model1.layer3[1].conv2, model1.layer3[1].bn2)\n",
    "    permute_output(third_residual_transform, model1.layer3[2].conv2, model1.layer3[2].bn2)\n",
    "\n",
    "    permute_input(third_residual_transform, [model1.layer3[1].conv1, model1.layer3[2].conv1, model1.linear])\n",
    "    \n",
    "    for i in range(3):\n",
    "        intermediate_transform = get_layer_procrustes(\n",
    "            [\n",
    "                (\n",
    "                    prep_output_conv(model0.layer1[i].conv1),\n",
    "                    prep_output_conv(model1.layer1[i].conv1),\n",
    "                ),\n",
    "                (\n",
    "                    prep_input_conv(model0.layer1[i].conv2),\n",
    "                    prep_input_conv(model1.layer1[i].conv2)\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        permute_output(intermediate_transform, model1.layer1[i].conv1, model1.layer1[i].bn1)\n",
    "        permute_input(intermediate_transform, [model1.layer1[i].conv2])\n",
    "    \n",
    "    for i in range(3):\n",
    "        intermediate_transform = get_layer_procrustes(\n",
    "            [\n",
    "                (\n",
    "                    prep_output_conv(model0.layer2[i].conv1),\n",
    "                    prep_output_conv(model1.layer2[i].conv1),\n",
    "                ),\n",
    "                (\n",
    "                    prep_input_conv(model0.layer2[i].conv2),\n",
    "                    prep_input_conv(model1.layer2[i].conv2)\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        permute_output(intermediate_transform, model1.layer2[i].conv1, model1.layer2[i].bn1)\n",
    "        permute_input(intermediate_transform, [model1.layer2[i].conv2])\n",
    "    \n",
    "    for i in range(3):\n",
    "        intermediate_transform = get_layer_procrustes(\n",
    "            [\n",
    "                (\n",
    "                    prep_output_conv(model0.layer3[i].conv1),\n",
    "                    prep_output_conv(model1.layer3[i].conv1),\n",
    "                ),\n",
    "                (\n",
    "                    prep_input_conv(model0.layer3[i].conv2),\n",
    "                    prep_input_conv(model1.layer3[i].conv2)\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        permute_output(intermediate_transform, model1.layer3[i].conv1, model1.layer3[i].bn1)\n",
    "        permute_input(intermediate_transform, [model1.layer3[i].conv2])\n",
    "    \n",
    "    prev_sd = model1.state_dict()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2b1e2976",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in model1.state_dict().items():\n",
    "    if 'bn' in key and 'running_var' in key:\n",
    "        model1.state_dict()[key] = torch.nn.functional.relu(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf14d0d",
   "metadata": {},
   "source": [
    "### Alter Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b77ff82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_transform = get_layer_procrustes(\n",
    "#     [\n",
    "#         (\n",
    "#             model0.linear.weight,\n",
    "#             model1.linear.weight,\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# permute_cls_output(linear_transform, model1.linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cd4b6422",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model1, f'resnet20x4_CIFAR5_procrustes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b13e35c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-reset:\n",
      "0.1\n",
      "Post-reset:\n",
      "0.4245\n"
     ]
    }
   ],
   "source": [
    "avg_model = resnet20(w=4).to(DEVICE)\n",
    "\n",
    "mix_weights(\n",
    "    avg_model, \n",
    "    .5, \n",
    "    f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}',\n",
    "    'resnet20x4_CIFAR5_procrustes',\n",
    "#     whitelist_fn=lambda x: 'bn' not in strip_param_suffix(x)\n",
    ")\n",
    "\n",
    "print('Pre-reset:')\n",
    "print(\n",
    "    evaluate(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ")\n",
    "reset_bn_stats(avg_model)\n",
    "print('Post-reset:')\n",
    "print(\n",
    "    evaluate(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae10d3ac",
   "metadata": {},
   "source": [
    "score to beat : .4759"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d33bac2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9558\n",
      "0.9726\n"
     ]
    }
   ],
   "source": [
    "model0 = resnet20(w=4).to(DEVICE)\n",
    "model1 = resnet20(w=4).to(DEVICE)\n",
    "model_to_alter = resnet20(w=4).to(DEVICE)\n",
    "\n",
    "load_model(model0, f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}')\n",
    "load_model(model1, f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}')\n",
    "\n",
    "print(evaluate(model0, test_loader1, class_vecs1, remap_class_idxs=class_idxs))\n",
    "print(evaluate(model1, test_loader2, class_vecs2, remap_class_idxs=class_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "89d39c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_proc = get_layer_procrustes([(prep_output_conv(model0.conv1), prep_output_conv(model1.conv1))])\n",
    "\n",
    "permute_output(conv1_proc, model1.conv1, model1.bn1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5abd9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model1, f'resnet20x4_CIFAR5_procrustes_greedy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "70e3b11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-reset:\n",
      "0.4212\n",
      "Post-reset:\n",
      "0.4687\n"
     ]
    }
   ],
   "source": [
    "avg_model = resnet20(w=4).to(DEVICE)\n",
    "\n",
    "mix_weights(\n",
    "    avg_model, \n",
    "    .5, \n",
    "    f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}',\n",
    "    'resnet20x4_CIFAR5_procrustes_greedy',\n",
    "    whitelist_fn=lambda x: strip_param_suffix(x) in ['conv1']\n",
    ")\n",
    "\n",
    "print('Pre-reset:')\n",
    "print(\n",
    "    evaluate(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ")\n",
    "reset_bn_stats(avg_model)\n",
    "print('Post-reset:')\n",
    "print(\n",
    "    evaluate(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c9bce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
