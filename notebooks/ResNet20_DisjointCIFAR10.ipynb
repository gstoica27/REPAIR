{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431d4ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam, lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sys import platform\n",
    "from collections import defaultdict\n",
    "\n",
    "DEVICE = 'mps' if platform == 'darwin' else 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb7e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_MEAN = [125.307, 122.961, 113.8575]\n",
    "CIFAR_STD = [51.5865, 50.847, 51.255]\n",
    "normalize = T.Normalize(np.array(CIFAR_MEAN)/255, np.array(CIFAR_STD)/255)\n",
    "denormalize = T.Normalize(-np.array(CIFAR_MEAN)/np.array(CIFAR_STD), 255/np.array(CIFAR_STD))\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "train_dset = torchvision.datasets.CIFAR10(root='/tmp', train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "test_dset = torchvision.datasets.CIFAR10(root='/tmp', train=False,\n",
    "                                        download=True, transform=test_transform)\n",
    "\n",
    "# class_idxs = np.arange(10)\n",
    "# np.random.shuffle(class_idxs)\n",
    "# model1_classes = class_idxs[:5]\n",
    "# model2_classes = class_idxs[5:]\n",
    "\n",
    "model1_classes= np.array([3, 2, 0, 6, 4])\n",
    "model2_classes = np.array([5, 7, 9, 8, 1])\n",
    "\n",
    "valid_examples1 = [i for i, (_, label) in tqdm(enumerate(train_dset)) if label in model1_classes]\n",
    "valid_examples2 = [i for i, (_, label) in tqdm(enumerate(train_dset)) if label in model2_classes]\n",
    "\n",
    "assert len(set(valid_examples1).intersection(set(valid_examples2))) == 0, 'sets should be disjoint'\n",
    "\n",
    "train_aug_loader1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dset, valid_examples1), batch_size=500, shuffle=True, num_workers=8\n",
    ")\n",
    "train_aug_loader2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dset, valid_examples2), batch_size=500, shuffle=True, num_workers=8\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=500, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug_loader = torch.utils.data.DataLoader(train_dset, batch_size=500, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269fd89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_valid_examples1 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model1_classes]\n",
    "test_valid_examples2 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model2_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc598da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dset, test_valid_examples1), batch_size=500, shuffle=False, num_workers=8\n",
    ")\n",
    "test_loader2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dset, test_valid_examples2), batch_size=500, shuffle=False, num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f75f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_classes, model2_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9aa20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idxs = np.zeros(10, dtype=int)\n",
    "class_idxs[model1_classes] = np.arange(5)\n",
    "class_idxs[model2_classes] = np.arange(5)\n",
    "class_idxs = torch.from_numpy(class_idxs)\n",
    "class_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061bef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, i):\n",
    "    sd = model.state_dict()\n",
    "    path = os.path.join(\n",
    "        # '/Users/georgestoica/Downloads',\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def load_model(model, i):\n",
    "    path = os.path.join(\n",
    "        # '/Users/georgestoica/Downloads',\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    sd = torch.load(path, map_location=torch.device(DEVICE))\n",
    "    model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974500a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given two networks net0, net1 which each output a feature map of shape NxCxWxH\n",
    "# this will reshape both outputs to (N*W*H)xC\n",
    "# and then compute a CxC correlation matrix between the outputs of the two networks\n",
    "def run_corr_matrix(net0, net1, epochs=1, norm=True, loader=train_aug_loader):\n",
    "    n = epochs*len(loader)\n",
    "    mean0 = mean1 = std0 = std1 = None\n",
    "    with torch.no_grad():\n",
    "        net0.eval()\n",
    "        net1.eval()\n",
    "        for _ in range(epochs):\n",
    "            for i, (images, _) in enumerate(tqdm(loader)):\n",
    "                img_t = images.float().to(DEVICE)\n",
    "                out0 = net0(img_t)\n",
    "                out0 = out0.reshape(out0.shape[0], out0.shape[1], -1).permute(0, 2, 1)\n",
    "                out0 = out0.reshape(-1, out0.shape[2]).double()\n",
    "\n",
    "                out1 = net1(img_t)\n",
    "                out1 = out1.reshape(out1.shape[0], out1.shape[1], -1).permute(0, 2, 1)\n",
    "                out1 = out1.reshape(-1, out1.shape[2]).double()\n",
    "\n",
    "                mean0_b = out0.mean(dim=0)\n",
    "                mean1_b = out1.mean(dim=0)\n",
    "                std0_b = out0.std(dim=0)\n",
    "                std1_b = out1.std(dim=0)\n",
    "                outer_b = (out0.T @ out1) / out0.shape[0]\n",
    "\n",
    "                if i == 0:\n",
    "                    mean0 = torch.zeros_like(mean0_b)\n",
    "                    mean1 = torch.zeros_like(mean1_b)\n",
    "                    std0 = torch.zeros_like(std0_b)\n",
    "                    std1 = torch.zeros_like(std1_b)\n",
    "                    outer = torch.zeros_like(outer_b)\n",
    "                mean0 += mean0_b / n\n",
    "                mean1 += mean1_b / n\n",
    "                std0 += std0_b / n\n",
    "                std1 += std1_b / n\n",
    "                outer += outer_b / n\n",
    "                \n",
    "    cov = outer - torch.outer(mean0, mean1)\n",
    "    if cov.isnan().sum() > 0: pdb.set_trace()\n",
    "    if norm:\n",
    "        corr = cov / (torch.outer(std0, std1) + 1e-4)\n",
    "        return corr.to(torch.float32)\n",
    "    else:\n",
    "        return cov.to(torch.float32)\n",
    "\n",
    "# modifies the weight matrices of a convolution and batchnorm\n",
    "# layer given a permutation of the output channels\n",
    "def permute_output(perm_map, conv, bn):\n",
    "    pre_weights = [\n",
    "        conv.weight,\n",
    "        bn.weight,\n",
    "        bn.bias,\n",
    "        bn.running_mean,\n",
    "        bn.running_var,\n",
    "    ]\n",
    "    for i, w in enumerate(pre_weights):\n",
    "        if len(pre_weights) == i + 1:\n",
    "            w @ (perm_map * perm_map).t()\n",
    "        if len(w.shape) == 4:\n",
    "            transform = torch.einsum('ab,bcde->acde', perm_map, w)\n",
    "        elif len(w.shape) == 2:\n",
    "            transform = perm_map @ w\n",
    "        else:\n",
    "            transform = w @ perm_map.t()\n",
    "        # assert torch.allclose(w[perm_map.argmax(-1)], transform)\n",
    "        w.data = transform\n",
    "        # w.data = w[perm_map]\n",
    "            \n",
    "\n",
    "# modifies the weight matrix of a convolution layer for a given\n",
    "# permutation of the input channels\n",
    "def permute_input(perm_map, after_convs):\n",
    "    if not isinstance(after_convs, list):\n",
    "        after_convs = [after_convs]\n",
    "    post_weights = [c.weight for c in after_convs]\n",
    "    for w in post_weights:\n",
    "        if len(w.shape) == 4:\n",
    "            transform = torch.einsum('abcd,be->aecd', w, perm_map.t())\n",
    "        elif len(w.shape) == 2:\n",
    "            transform = w @ perm_map.t()\n",
    "    #     assert torch.allclose(w[:, perm_map.argmax(-1)], transform)\n",
    "        w.data = transform\n",
    "#         w.data = w[:, perm_map, :, :]\n",
    "\n",
    "def permute_cls_output(perm_map, linear):\n",
    "    for w in [linear.weight, linear.bias]:\n",
    "        w.data = perm_map @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c23bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_model(\n",
    "    model0, \n",
    "    model1, \n",
    "    model_to_alter, \n",
    "    transform_fn, \n",
    "    prune_threshold=-torch.inf, \n",
    "    module2io=defaultdict(lambda: dict())\n",
    "):\n",
    "    class Subnet(nn.Module):\n",
    "        def __init__(self, model):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "        def forward(self, x):\n",
    "            self = self.model\n",
    "            x = F.relu(self.bn1(self.conv1(x)))\n",
    "            x = self.layer1(x)\n",
    "            return x\n",
    "\n",
    "    perm_map, collapse_totals = transform_fn(Subnet(model0), Subnet(model1))\n",
    "    permute_output(perm_map, model_to_alter.conv1, model_to_alter.bn1)\n",
    "    permute_output(perm_map, model_to_alter.layer1[0].conv2, model_to_alter.layer1[0].bn2)\n",
    "    permute_output(perm_map, model_to_alter.layer1[1].conv2, model_to_alter.layer1[1].bn2)\n",
    "    permute_output(perm_map, model_to_alter.layer1[2].conv2, model_to_alter.layer1[2].bn2)\n",
    "    permute_input(perm_map, \n",
    "                  [\n",
    "                      model_to_alter.layer1[0].conv1, \n",
    "                      model_to_alter.layer1[1].conv1, \n",
    "                      model_to_alter.layer1[2].conv1\n",
    "                  ]\n",
    "                 )\n",
    "    permute_input(perm_map, [model_to_alter.layer2[0].conv1, model_to_alter.layer2[0].shortcut[0]])\n",
    "    \n",
    "    module2io['conv1']['output'] = collapse_totals\n",
    "    module2io['bn1']['output'] = collapse_totals\n",
    "    module2io['layer1.0.conv2']['output'] = collapse_totals\n",
    "    module2io['layer1.0.bn2']['output'] = collapse_totals\n",
    "    module2io['layer1.1.conv2']['output'] = collapse_totals\n",
    "    module2io['layer1.1.bn2']['output'] = collapse_totals\n",
    "    module2io['layer1.2.conv2']['output'] = collapse_totals\n",
    "    module2io['layer1.2.bn2']['output'] = collapse_totals\n",
    "\n",
    "    module2io['layer1.0.conv1']['input'] = collapse_totals\n",
    "    module2io['layer1.1.conv1']['input'] = collapse_totals\n",
    "    module2io['layer1.2.conv1']['input'] = collapse_totals\n",
    "    module2io['layer2.0.conv1']['input'] = collapse_totals\n",
    "    module2io['layer2.0.shortcut.0']['input'] = collapse_totals\n",
    "    \n",
    "    class Subnet(nn.Module):\n",
    "        def __init__(self, model):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "        def forward(self, x):\n",
    "            self = self.model\n",
    "            x = F.relu(self.bn1(self.conv1(x)))\n",
    "            x = self.layer1(x)\n",
    "            x = self.layer2(x)\n",
    "            return x\n",
    "\n",
    "    perm_map, collapse_totals = transform_fn(Subnet(model0), Subnet(model1))\n",
    "    permute_output(perm_map, model_to_alter.layer2[0].conv2, model_to_alter.layer2[0].bn2)\n",
    "    permute_output(perm_map, model_to_alter.layer2[0].shortcut[0], model_to_alter.layer2[0].shortcut[1])\n",
    "    permute_output(perm_map, model_to_alter.layer2[1].conv2, model_to_alter.layer2[1].bn2)\n",
    "    permute_output(perm_map, model_to_alter.layer2[2].conv2, model_to_alter.layer2[2].bn2)\n",
    "\n",
    "    permute_input(perm_map, [model_to_alter.layer2[1].conv1, model_to_alter.layer2[2].conv1])\n",
    "    permute_input(perm_map, [model_to_alter.layer3[0].conv1, model_to_alter.layer3[0].shortcut[0]])\n",
    "    \n",
    "    module2io['layer2.0.conv2']['output'] = collapse_totals\n",
    "    module2io['layer2.0.bn2']['output'] = collapse_totals\n",
    "    module2io['layer2.0.shortcut.0']['output'] = collapse_totals\n",
    "    module2io['layer2.0.shortcut.1']['output'] = collapse_totals\n",
    "    module2io['layer2.1.conv2']['output'] = collapse_totals\n",
    "    module2io['layer2.1.bn2']['output'] = collapse_totals\n",
    "    module2io['layer2.2.conv2']['output'] = collapse_totals\n",
    "    module2io['layer2.2.bn2']['output'] = collapse_totals\n",
    "\n",
    "    module2io['layer2.1.conv1']['input'] = collapse_totals\n",
    "    module2io['layer2.2.conv1']['input'] = collapse_totals\n",
    "    module2io['layer3.0.conv1']['input'] = collapse_totals\n",
    "    module2io['layer3.0.shortcut.0']['input'] = collapse_totals\n",
    "    \n",
    "    class Subnet(nn.Module):\n",
    "        def __init__(self, model):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "        def forward(self, x):\n",
    "            self = self.model\n",
    "            x = F.relu(self.bn1(self.conv1(x)))\n",
    "            x = self.layer1(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.layer3(x)\n",
    "            return x\n",
    "\n",
    "    perm_map, collapse_totals = transform_fn(Subnet(model0), Subnet(model1))\n",
    "    permute_output(perm_map, model_to_alter.layer3[0].conv2, model_to_alter.layer3[0].bn2)\n",
    "    permute_output(perm_map, model_to_alter.layer3[0].shortcut[0], model_to_alter.layer3[0].shortcut[1])\n",
    "    permute_output(perm_map, model_to_alter.layer3[1].conv2, model_to_alter.layer3[1].bn2)\n",
    "    permute_output(perm_map, model_to_alter.layer3[2].conv2, model_to_alter.layer3[2].bn2)\n",
    "\n",
    "    permute_input(perm_map, [model_to_alter.layer3[1].conv1, model_to_alter.layer3[2].conv1])\n",
    "    model_to_alter.linear.weight.data = model_to_alter.linear.weight @ perm_map.t()\n",
    "    \n",
    "    module2io['layer3.0.conv2']['output'] = collapse_totals\n",
    "    module2io['layer3.0.bn2']['output'] = collapse_totals\n",
    "    module2io['layer3.0.shortcut.0']['output'] = collapse_totals\n",
    "    module2io['layer3.0.shortcut.1']['output'] = collapse_totals\n",
    "    module2io['layer3.1.conv2']['output'] = collapse_totals\n",
    "    module2io['layer3.1.bn2']['output'] = collapse_totals\n",
    "    module2io['layer3.2.conv2']['output'] = collapse_totals\n",
    "    module2io['layer3.2.bn2']['output'] = collapse_totals\n",
    "\n",
    "    module2io['layer3.1.conv1']['input'] = collapse_totals\n",
    "    module2io['layer3.2.conv1']['input'] = collapse_totals\n",
    "    module2io['linear']['input'] = collapse_totals\n",
    "    \n",
    "    class Subnet(nn.Module):\n",
    "        def __init__(self, model, nb=9):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "            self.blocks = []\n",
    "            self.blocks += list(model.layer1)\n",
    "            self.blocks += list(model.layer2)\n",
    "            self.blocks += list(model.layer3)\n",
    "            self.blocks = nn.Sequential(*self.blocks)\n",
    "            self.bn1 = model.bn1\n",
    "            self.conv1 = model.conv1\n",
    "            self.linear = model.linear\n",
    "            self.nb = nb\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.bn1(self.conv1(x)))\n",
    "            x = self.blocks[:self.nb](x)\n",
    "            block = self.blocks[self.nb]\n",
    "            x = block.conv1(x)\n",
    "            x = block.bn1(x)\n",
    "            x = F.relu(x)\n",
    "            return x\n",
    "\n",
    "    blocks1 = []\n",
    "    blocks1 += list(model_to_alter.layer1)\n",
    "    blocks1 += list(model_to_alter.layer2)\n",
    "    blocks1 += list(model_to_alter.layer3)\n",
    "    blocks1 = nn.Sequential(*blocks1)\n",
    "    \n",
    "    block_idx2name = {\n",
    "        0: 'layer1.0',\n",
    "        1: 'layer1.1',\n",
    "        2: 'layer1.2',\n",
    "        3: 'layer2.0',\n",
    "        4: 'layer2.1',\n",
    "        5: 'layer2.2',\n",
    "        6: 'layer3.0',\n",
    "        7: 'layer3.1',\n",
    "        8: 'layer3.2'\n",
    "    }\n",
    "    for nb, (block_idx, layer_name) in zip(range(9), block_idx2name.items()):\n",
    "        perm_map, collapse_totals = transform_fn(Subnet(model0, nb=nb), Subnet(model1, nb=nb))\n",
    "        block = blocks1[nb]\n",
    "        permute_output(perm_map, block.conv1, block.bn1)\n",
    "        permute_input(perm_map, [block.conv2])\n",
    "\n",
    "        module2io[layer_name + '.conv1']['output'] = collapse_totals\n",
    "        module2io[layer_name + '.bn1']['output'] = collapse_totals\n",
    "        module2io[layer_name + '.conv2']['output'] = collapse_totals\n",
    "    \n",
    "    return model_to_alter, module2io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84af4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "#             self.shortcut = LambdaLayer(lambda x:\n",
    "#                                         F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, w=1, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = w*16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, w*16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(w*16)\n",
    "        self.layer1 = self._make_layer(block, w*16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, w*32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, w*64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(w*64, 512)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def resnet20(w=1):\n",
    "    return ResNet(BasicBlock, [3, 3, 3], w=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99402c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(save_key, model, train_loader, test_loader, class_vectors, remap_class_idxs):\n",
    "    optimizer = SGD(model.parameters(), lr=0.4, momentum=0.9, weight_decay=5e-4)\n",
    "    # optimizer = Adam(model.parameters(), lr=0.05)\n",
    "    \n",
    "    # Adam seems to perform worse than SGD for training ResNets on CIFAR-10.\n",
    "    # To make Adam work, we find that we need a very high learning rate: 0.05 (50x the default)\n",
    "    # At this LR, Adam gives 1.0-1.5% worse accuracy than SGD.\n",
    "    \n",
    "    # It is not yet clear whether the increased interpolation barrier for Adam-trained networks\n",
    "    # is simply due to the increased test loss of said networks relative to those trained with SGD.\n",
    "    # We include the option of using Adam in this notebook to explore this question.\n",
    "\n",
    "    EPOCHS = 100\n",
    "    ne_iters = len(train_loader)\n",
    "    lr_schedule = np.interp(np.arange(1+EPOCHS*ne_iters), [0, 5*ne_iters, EPOCHS*ne_iters], [0, 1, 0])\n",
    "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_schedule.__getitem__)\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    \n",
    "    losses = []\n",
    "    for _ in tqdm(range(EPOCHS)):\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with autocast():\n",
    "                encodings = model(inputs.to(DEVICE))\n",
    "                normed_encodings = encodings / encodings.norm(dim=-1, keepdim=True)\n",
    "                logits = (100.0 * normed_encodings @ class_vectors.T)\n",
    "                remapped_labels = remap_class_idxs[labels].to(DEVICE)\n",
    "                loss = loss_fn(logits, remapped_labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            losses.append(loss.item())\n",
    "    print(evaluate(\n",
    "        model, test_loader, \n",
    "        class_vectors=class_vectors, \n",
    "        remap_class_idxs=remap_class_idxs\n",
    "    ))\n",
    "    save_model(model, save_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4308b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates accuracy\n",
    "def evaluate(model, loader, class_vectors, remap_class_idxs=None):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            encodings = model(inputs.to(DEVICE))\n",
    "            normed_encodings = encodings / encodings.norm(dim=-1, keepdim=True)\n",
    "            outputs = normed_encodings @ class_vectors.T\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            if remap_class_idxs is not None:\n",
    "                correct += (remap_class_idxs[labels].to(DEVICE) == pred).sum().item()\n",
    "            else:\n",
    "                correct += (labels.to(DEVICE) == pred).sum().item()\n",
    "            total += inputs.shape[0]\n",
    "    return correct / total\n",
    "\n",
    "# evaluates loss\n",
    "def evaluate1(model, loader, class_vectors, remap_class_idxs):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    pdb.set_trace()\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            encodings = model(inputs.to(DEVICE))\n",
    "            normed_encodings = encodings / encodings.norm(dim=-1, keepdim=True)\n",
    "            outputs = normed_encodings @ class_vectors.T\n",
    "            loss = F.cross_entropy(outputs, remap_class_idxs[labels].to(DEVICE))\n",
    "            losses.append(loss.item())\n",
    "    return np.array(losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df0252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72907742",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in test_dset.classes]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853aab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load('ViT-B/32', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324617b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa330f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87412ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features /= text_features.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3a92d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_vecs1 = text_features[model1_classes]\n",
    "class_vecs2 = text_features[model2_classes]\n",
    "# class_vecs1 /= class_vecs1.norm(dim=-1, keepdim=True)\n",
    "# class_vecs2 /= class_vecs2.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c5c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81721d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/srv/share/gstoica3/checkpoints/REPAIR/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb75853",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\n",
    "    os.path.join(\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}.pth.tar'\n",
    "    )\n",
    "):\n",
    "    print('training model...')\n",
    "    model1 = resnet20(w=4).to(DEVICE)\n",
    "    train(\n",
    "        f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}', \n",
    "        model=model1, \n",
    "        class_vectors=class_vecs1,\n",
    "        train_loader=train_aug_loader1,\n",
    "        test_loader=test_loader1,\n",
    "        remap_class_idxs=class_idxs\n",
    "    )\n",
    "if not os.path.exists(\n",
    "    os.path.join(\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}.pth.tar'\n",
    "    )\n",
    "):\n",
    "    print('training model...')\n",
    "    model2 = resnet20(w=4).to(DEVICE)\n",
    "    train(\n",
    "        f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}', \n",
    "        model=model2, \n",
    "        class_vectors=class_vecs2,\n",
    "        train_loader=train_aug_loader2,\n",
    "        test_loader=test_loader2,\n",
    "        remap_class_idxs=class_idxs\n",
    "    )\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef35cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1342bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b7d2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808828fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7562bd57",
   "metadata": {},
   "source": [
    "# Combine models and evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03612a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_param_suffix(name):\n",
    "    return name.replace('.weight', '').replace('.bias', '')\n",
    "\n",
    "def combine_io_masks(io, param):\n",
    "    mask = torch.zeros_like(param, device=param.device)\n",
    "    try:\n",
    "        if 'output' in io:\n",
    "            mask[io['output'].view(-1) == 0] = 1.\n",
    "        if 'input' in io and len(mask.shape) > 1:\n",
    "            mask[:, io['input'].view(-1) == 0] = 1.\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "    return mask\n",
    "\n",
    "def mix_weights(model, alpha, key0, key1, module2io=None, whitelist_fn=lambda x: True):\n",
    "    sd0 = torch.load(\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/%s.pth.tar' % key0, \n",
    "        map_location=torch.device(DEVICE)\n",
    "    )\n",
    "    sd1 = torch.load(\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/%s.pth.tar' % key1, \n",
    "        map_location=torch.device(DEVICE)\n",
    "    )\n",
    "    sd_alpha = {}\n",
    "    for k in sd0.keys():\n",
    "        param0 = sd0[k].to(DEVICE)\n",
    "        param1 = sd1[k].to(DEVICE)\n",
    "        sd_alpha[k] = (1 - alpha) * param0 + alpha * param1\n",
    "        \n",
    "        if module2io is not None:\n",
    "            param_base = strip_param_suffix(k)\n",
    "#             pdb.set_trace()\n",
    "            mask = combine_io_masks(module2io[param_base], param1)\n",
    "            sd_alpha[k][mask == 1] = param0[mask == 1].to(sd_alpha[k].dtype)\n",
    "        \n",
    "        if not whitelist_fn(k):\n",
    "            sd_alpha[k] = param0\n",
    "    model.load_state_dict(sd_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09128919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4c690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b418e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_model = resnet20(w=4).to(DEVICE)\n",
    "\n",
    "mix_weights(\n",
    "    avg_model, \n",
    "    .5, \n",
    "    f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}',\n",
    "    f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "713afe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    evaluate(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27448814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the train loader with data augmentation as this gives better results\n",
    "def reset_bn_stats(model, epochs=1, loader=train_aug_loader):\n",
    "    # resetting stats to baseline first as below is necessary for stability\n",
    "    for m in model.modules():\n",
    "        if type(m) == nn.BatchNorm2d:\n",
    "            m.momentum = None # use simple average\n",
    "            m.reset_running_stats()\n",
    "    # run a single train epoch with augmentations to recalc stats\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        with torch.no_grad(), autocast():\n",
    "            for images, _ in loader:\n",
    "                output = model(images.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a379cc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-reset:\n",
      "0.4194\n"
     ]
    }
   ],
   "source": [
    "reset_bn_stats(avg_model)\n",
    "print('Post-reset:')\n",
    "print(\n",
    "    evaluate(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575128d",
   "metadata": {},
   "source": [
    "# Combine models via permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ccdaa9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perm_map(corr_mtx):\n",
    "    # sort the (i, j) channel pairs by correlation\n",
    "    nchan = corr_mtx.shape[0]\n",
    "    triples = [(i, j, corr_mtx[i, j].item()) for i in range(nchan) for j in range(nchan)]\n",
    "    triples = sorted(triples, key=lambda p: -p[2])\n",
    "    # greedily find a matching\n",
    "    perm_d = {}\n",
    "    for i, j, c in triples:\n",
    "        if not (i in perm_d.keys() or j in perm_d.values()):\n",
    "            perm_d[i] = j\n",
    "    perm_map = torch.tensor([perm_d[i] for i in range(nchan)])\n",
    "\n",
    "    # qual_map will be a permutation of the indices in the order\n",
    "    # of the quality / degree of correlation between the neurons found in the permutation.\n",
    "    # this just for visualization purposes.\n",
    "    qual_l = [corr_mtx[i, perm_map[i]].item() for i in range(nchan)]\n",
    "    qual_map = torch.tensor(sorted(range(nchan), key=lambda i: -qual_l[i]))\n",
    "\n",
    "    return perm_map, qual_map\n",
    "\n",
    "def get_layer_perm1(corr_mtx, method='max_weight', vizz=False, prune_threshold=-torch.inf):\n",
    "    if method == 'greedy':\n",
    "        perm_map, qual_map = compute_perm_map(corr_mtx)\n",
    "        if vizz:\n",
    "            corr_mtx_viz = (corr_mtx[qual_map].T[perm_map[qual_map]]).T\n",
    "            viz(corr_mtx_viz)\n",
    "    elif method == 'max_weight':\n",
    "        corr_mtx_a = corr_mtx.cpu().numpy()\n",
    "        row_ind, col_ind = scipy.optimize.linear_sum_assignment(corr_mtx_a, maximize=True)\n",
    "        assert (row_ind == np.arange(len(corr_mtx_a))).all()\n",
    "        perm_map = torch.tensor(col_ind).long()\n",
    "        perm_map = torch.eye(corr_mtx.shape[0], device=corr_mtx.device)[perm_map]\n",
    "    else:\n",
    "        raise Exception('Unknown method: %s' % method)\n",
    "    \n",
    "#     pdb.set_trace()\n",
    "    pruned_elements = torch.from_numpy(\n",
    "        corr_mtx_a[row_ind, col_ind] >= prune_threshold\n",
    "    ).to(perm_map.device).to(torch.float32)\n",
    "    return perm_map, pruned_elements\n",
    "\n",
    "# returns the channel-permutation to make layer1's activations most closely\n",
    "# match layer0's.\n",
    "def get_layer_perm(net0, net1, method='max_weight', vizz=False, prune_threshold=-torch.inf):\n",
    "    corr_mtx = run_corr_matrix(net0, net1)\n",
    "    return get_layer_perm1(corr_mtx, method=method, vizz=vizz, prune_threshold=prune_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "3633cd5c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9558\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15185/1760931642.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_vecs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremap_class_idxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_vecs2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremap_class_idxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_15185/3650053867.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, loader, class_vectors, remap_class_idxs)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mnormed_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencodings\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mencodings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model0 = resnet20(w=4).to(DEVICE)\n",
    "model1 = resnet20(w=4).to(DEVICE)\n",
    "load_model(model0, f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}')\n",
    "load_model(model1, f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}')\n",
    "\n",
    "print(evaluate(model0, test_loader1, class_vecs1, remap_class_idxs=class_idxs))\n",
    "print(evaluate(model1, test_loader2, class_vecs2, remap_class_idxs=class_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "941a6624",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_threshold = -torch.inf\n",
    "from collections import defaultdict\n",
    "module2io = defaultdict(lambda: dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b23f393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:06<00:00, 15.35it/s]\n",
      "100%|| 100/100 [00:08<00:00, 12.19it/s]\n",
      "100%|| 100/100 [00:09<00:00, 10.16it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.59it/s]\n",
      "100%|| 100/100 [00:04<00:00, 20.28it/s]\n",
      "100%|| 100/100 [00:06<00:00, 16.42it/s]\n",
      "100%|| 100/100 [00:06<00:00, 15.06it/s]\n",
      "100%|| 100/100 [00:07<00:00, 13.30it/s]\n",
      "100%|| 100/100 [00:08<00:00, 12.45it/s]\n",
      "100%|| 100/100 [00:08<00:00, 11.73it/s]\n",
      "100%|| 100/100 [00:09<00:00, 11.08it/s]\n",
      "100%|| 100/100 [00:09<00:00, 10.54it/s]\n"
     ]
    }
   ],
   "source": [
    "model_to_alter, module2io = transform_model(\n",
    "    model0, \n",
    "    model1, \n",
    "    model_to_alter=model1, \n",
    "    transform_fn=get_layer_perm, \n",
    "    prune_threshold=-torch.inf, \n",
    "    module2io=module2io\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f3f5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model1, f'resnet20x4_CIFAR5_perm1_{prune_threshold}threshold_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c61fa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Post-reset:\n",
      "0.5406\n"
     ]
    }
   ],
   "source": [
    "avg_model = resnet20(w=4).to(DEVICE)\n",
    "\n",
    "mix_weights(\n",
    "    avg_model, \n",
    "    .5, \n",
    "    f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}',\n",
    "    f'resnet20x4_CIFAR5_perm1_{prune_threshold}threshold_new'\n",
    ")\n",
    "\n",
    "print(\n",
    "    evaluate(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ")\n",
    "reset_bn_stats(avg_model)\n",
    "print('Post-reset:')\n",
    "print(\n",
    "    evaluate(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915a7269",
   "metadata": {},
   "source": [
    "# Combine Models via Bipartite Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ed86e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bipartite_perm(corr, prune_threshold=-torch.inf):\n",
    "    scores, idx = corr.max(0)\n",
    "    valid_elements = scores >= prune_threshold\n",
    "    idx = torch.where(valid_elements, idx, corr.shape[0])\n",
    "    location_lookup = torch.eye(corr.shape[0]+1, corr.shape[0], device=corr.device)\n",
    "    matches = location_lookup[idx]\n",
    "    totals = matches.sum(0, keepdim=True)\n",
    "    matches = matches / (totals + 1)\n",
    "    return matches.t(), totals\n",
    "\n",
    "def get_layer_bipartite_transform(net0, net1, prune_threshold=-torch.inf):\n",
    "    corr_mtx = run_corr_matrix(net0, net1)\n",
    "    return get_bipartite_perm(corr_mtx, prune_threshold=prune_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "deff07b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9558\n",
      "0.9726\n",
      "0.9726\n"
     ]
    }
   ],
   "source": [
    "model0 = resnet20(w=4).to(DEVICE)\n",
    "model1 = resnet20(w=4).to(DEVICE)\n",
    "model_to_alter = resnet20(w=4).to(DEVICE)\n",
    "\n",
    "load_model(model0, f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}')\n",
    "load_model(model1, f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}')\n",
    "load_model(model_to_alter, f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}')\n",
    "\n",
    "print(evaluate(model0, test_loader1, class_vecs1, remap_class_idxs=class_idxs))\n",
    "print(evaluate(model1, test_loader2, class_vecs2, remap_class_idxs=class_idxs))\n",
    "print(evaluate(model_to_alter, test_loader2, class_vecs2, remap_class_idxs=class_idxs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78c9232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_threshold = -torch.inf\n",
    "from collections import defaultdict\n",
    "module2io = defaultdict(lambda: dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ccbfde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:06<00:00, 15.19it/s]\n",
      "100%|| 100/100 [00:08<00:00, 11.85it/s]\n",
      "100%|| 100/100 [00:09<00:00, 10.01it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.07it/s]\n",
      "100%|| 100/100 [00:05<00:00, 19.75it/s]\n",
      "100%|| 100/100 [00:06<00:00, 16.51it/s]\n",
      "100%|| 100/100 [00:06<00:00, 14.94it/s]\n",
      "100%|| 100/100 [00:07<00:00, 13.24it/s]\n",
      "100%|| 100/100 [00:08<00:00, 12.47it/s]\n",
      "100%|| 100/100 [00:08<00:00, 11.55it/s]\n",
      "100%|| 100/100 [00:09<00:00, 10.87it/s]\n",
      "100%|| 100/100 [00:09<00:00, 10.34it/s]\n"
     ]
    }
   ],
   "source": [
    "model_to_alter, module2io = transform_model(\n",
    "    model0, \n",
    "    model1, \n",
    "    model_to_alter=model_to_alter, \n",
    "    transform_fn=get_layer_bipartite_transform, \n",
    "    prune_threshold=-torch.inf, \n",
    "    module2io=module2io\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7491c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model_to_alter, f'resnet20x4_CIFAR5_bipartite_{prune_threshold}threshold_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b978cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Post-reset:\n",
      "0.4777\n"
     ]
    }
   ],
   "source": [
    "avg_model = resnet20(w=4).to(DEVICE)\n",
    "\n",
    "mix_weights(\n",
    "    avg_model, \n",
    "    .5, \n",
    "    f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}',\n",
    "    f'resnet20x4_CIFAR5_bipartite_{prune_threshold}threshold_new'\n",
    ")\n",
    "\n",
    "print(\n",
    "    evaluate(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ")\n",
    "reset_bn_stats(avg_model)\n",
    "print('Post-reset:')\n",
    "print(\n",
    "    evaluate(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905ffd7b",
   "metadata": {},
   "source": [
    "# Combine Via Procrustes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "5d7d7c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_procrustes(corr_mtx):\n",
    "    U, _, Vh = torch.linalg.svd(corr_mtx)\n",
    "    return U @ Vh\n",
    "\n",
    "# returns the channel-permutation to make layer1's activations most closely\n",
    "# match layer0's.\n",
    "def get_layer_procrustes(net0, net1, prune_threshold=None):\n",
    "    corr_mtx = run_corr_matrix(net0, net1)\n",
    "    try:\n",
    "        return get_procrustes(corr_mtx), torch.ones(corr_mtx.shape[0], device=corr_mtx.device)\n",
    "    except:\n",
    "        print('Applying Permutation')\n",
    "        pdb.set_trace()\n",
    "        return get_layer_perm1(corr_mtx, 'max_weight', vizz=False, prune_threshold=prune_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "93505eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9558\n",
      "0.9726\n",
      "0.9726\n"
     ]
    }
   ],
   "source": [
    "model0 = resnet20(w=4).to(DEVICE)\n",
    "model1 = resnet20(w=4).to(DEVICE)\n",
    "model_to_alter = resnet20(w=4).to(DEVICE)\n",
    "\n",
    "load_model(model0, f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}')\n",
    "load_model(model1, f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}')\n",
    "load_model(model_to_alter, f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}')\n",
    "\n",
    "print(evaluate(model0, test_loader1, class_vecs1, remap_class_idxs=class_idxs))\n",
    "print(evaluate(model1, test_loader2, class_vecs2, remap_class_idxs=class_idxs))\n",
    "print(evaluate(model_to_alter, test_loader2, class_vecs2, remap_class_idxs=class_idxs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "c096ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_threshold = -torch.inf\n",
    "from collections import defaultdict\n",
    "module2io = defaultdict(lambda: dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "0211cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given two networks net0, net1 which each output a feature map of shape NxCxWxH\n",
    "# this will reshape both outputs to (N*W*H)xC\n",
    "# and then compute a CxC correlation matrix between the outputs of the two networks\n",
    "def run_corr_matrix(net0, net1, epochs=1, norm=True, loader=train_aug_loader):\n",
    "    n = epochs*len(loader)\n",
    "    mean0 = mean1 = std0 = std1 = None\n",
    "    with torch.no_grad():\n",
    "        net0.eval()\n",
    "        net1.eval()\n",
    "        for _ in range(epochs):\n",
    "            for i, (images, _) in enumerate(tqdm(loader)):\n",
    "                img_t = images.float().to(DEVICE)\n",
    "                out0 = net0(img_t)\n",
    "                out0 = out0.reshape(out0.shape[0], out0.shape[1], -1).permute(0, 2, 1)\n",
    "                out0 = out0.reshape(-1, out0.shape[2]).double()\n",
    "\n",
    "                out1 = net1(img_t)\n",
    "                out1 = out1.reshape(out1.shape[0], out1.shape[1], -1).permute(0, 2, 1)\n",
    "                out1 = out1.reshape(-1, out1.shape[2]).double()\n",
    "\n",
    "                mean0_b = out0.mean(dim=0)\n",
    "                mean1_b = out1.mean(dim=0)\n",
    "                std0_b = out0.std(dim=0)\n",
    "                std1_b = out1.std(dim=0)\n",
    "                outer_b = (out0.T @ out1) / out0.shape[0]\n",
    "\n",
    "                if i == 0:\n",
    "                    mean0 = torch.zeros_like(mean0_b)\n",
    "                    mean1 = torch.zeros_like(mean1_b)\n",
    "                    std0 = torch.zeros_like(std0_b)\n",
    "                    std1 = torch.zeros_like(std1_b)\n",
    "                    outer = torch.zeros_like(outer_b)\n",
    "                mean0 += mean0_b / n\n",
    "                mean1 += mean1_b / n\n",
    "                std0 += std0_b / n\n",
    "                std1 += std1_b / n\n",
    "                outer += outer_b / n\n",
    "                if outer.isnan().sum() > 0: pdb.set_trace()\n",
    "                \n",
    "    cov = outer - torch.outer(mean0, mean1)\n",
    "    if cov.isnan().sum() > 0: pdb.set_trace()\n",
    "    if norm:\n",
    "        corr = cov / (torch.outer(std0, std1) + 1e-4)\n",
    "        return corr.to(torch.float32)\n",
    "    else:\n",
    "        return cov.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "d3ea55f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:06<00:00, 14.57it/s]\n"
     ]
    }
   ],
   "source": [
    "class Subnet(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        self = self.model\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        return x\n",
    "# corr = run_corr_matrix(Subnet(model0), Subnet(model1))\n",
    "# perm_map1 = get_layer_perm1(corr)\n",
    "perm_map, collapse_totals = get_layer_procrustes(Subnet(model0), Subnet(model1))\n",
    "permute_output(perm_map, model_to_alter.conv1, model_to_alter.bn1)\n",
    "permute_output(perm_map, model_to_alter.layer1[0].conv2, model_to_alter.layer1[0].bn2)\n",
    "permute_output(perm_map, model_to_alter.layer1[1].conv2, model_to_alter.layer1[1].bn2)\n",
    "permute_output(perm_map, model_to_alter.layer1[2].conv2, model_to_alter.layer1[2].bn2)\n",
    "permute_input(perm_map, [model_to_alter.layer1[0].conv1, model_to_alter.layer1[1].conv1, model_to_alter.layer1[2].conv1])\n",
    "permute_input(perm_map, [model_to_alter.layer2[0].conv1, model_to_alter.layer2[0].shortcut[0]])\n",
    "\n",
    "module2io['conv1']['output'] = collapse_totals\n",
    "module2io['bn1']['output'] = collapse_totals\n",
    "module2io['layer1.0.conv2']['output'] = collapse_totals\n",
    "module2io['layer1.0.bn2']['output'] = collapse_totals\n",
    "module2io['layer1.1.conv2']['output'] = collapse_totals\n",
    "module2io['layer1.1.bn2']['output'] = collapse_totals\n",
    "module2io['layer1.2.conv2']['output'] = collapse_totals\n",
    "module2io['layer1.2.bn2']['output'] = collapse_totals\n",
    "\n",
    "module2io['layer1.0.conv1']['input'] = collapse_totals\n",
    "module2io['layer1.1.conv1']['input'] = collapse_totals\n",
    "module2io['layer1.2.conv1']['input'] = collapse_totals\n",
    "module2io['layer2.0.conv1']['input'] = collapse_totals\n",
    "module2io['layer2.0.shortcut.0']['input'] = collapse_totals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "24775f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subnet(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        self = self.model\n",
    "        x = self.conv1(x)\n",
    "#         x = F.relu(self.bn1(self.conv1(x)))\n",
    "#         x = self.layer1(x)\n",
    "#         x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "f5fa1306",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_alter.eval()\n",
    "for (images, _) in train_aug_loader:\n",
    "    if model_to_alter.bn1(Subnet(model_to_alter)(images.to(DEVICE))).isnan().sum() > 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "b0c67a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.eval()\n",
    "model_to_alter.eval()\n",
    "x = Subnet(model_to_alter)(images.to(DEVICE))\n",
    "y = Subnet(model1)(images.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "92126b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a83462ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0047, -0.2131, -0.2379,  ..., -0.4124, -0.6936, -0.7678],\n",
       "        [ 0.1949,  0.0194,  0.1038,  ..., -0.2479, -0.6081, -0.9205],\n",
       "        [ 0.1955,  0.0537,  0.1642,  ..., -0.2278, -0.6081, -0.9205],\n",
       "        ...,\n",
       "        [ 0.3429,  0.5502,  0.5937,  ..., -0.4127, -0.6081, -0.9205],\n",
       "        [ 0.3528,  0.5601,  0.6413,  ..., -0.4254, -0.6081, -0.9205],\n",
       "        [ 0.2916,  0.5425,  0.6184,  ..., -0.7634, -0.9897, -1.2217]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1487a3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[ 0.2029,  0.3060,  0.2887,  ...,  0.2293,  0.5042,  0.5268],\n",
      "        [ 0.0252,  0.0989,  0.1011,  ..., -0.0957,  0.1328,  0.2677],\n",
      "        [-0.0422,  0.0133,  0.0426,  ..., -0.0927,  0.1328,  0.2677],\n",
      "        ...,\n",
      "        [ 0.1896,  0.2273,  0.1936,  ...,  0.0416,  0.1328,  0.2677],\n",
      "        [ 0.2037,  0.2602,  0.2511,  ...,  0.0430,  0.1328,  0.2677],\n",
      "        [ 0.1875,  0.3116,  0.4022,  ..., -0.4774, -0.4942, -0.2350]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model_to_alter.bn1(x)[0, 2])\n",
    "print(model1.bn1(y)[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5882cff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.2404,  0.1396, -0.0716,  0.0786, -0.0161, -0.0274, -0.0696,  0.1303,\n",
       "         0.0332, -0.0910, -0.1487,  0.0779, -0.0313,  0.1654,  0.0041,  0.0915,\n",
       "         0.0815,  0.2537,  0.2602,  0.0523,  0.0832,  0.0276,  0.0186,  0.0259,\n",
       "         0.0361,  0.1434,  0.1514,  0.1169,  0.1514,  0.1451,  0.0742,  0.2794,\n",
       "         0.0354,  0.0278,  0.1422,  0.1603,  0.0654, -0.0599,  0.1679,  0.0952,\n",
       "         0.0704,  0.0535,  0.1706, -0.0352,  0.0277,  0.1155,  0.0524,  0.1103,\n",
       "         0.0493,  0.1667,  0.0365,  0.1371,  0.1578,  0.1853, -0.0271,  0.0426,\n",
       "         0.3463,  0.0887, -0.0385,  0.4119,  0.1525,  0.2235,  0.0598,  0.2431],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_alter.bn1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a25eddee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 1.4097e-03,  1.2869e-04,  2.3129e-01,  1.9476e-01,  1.4690e-01,\n",
       "         2.1003e-01,  7.3980e-03,  1.3881e-01,  1.4591e-01,  4.1396e-03,\n",
       "         9.8003e-03,  6.2927e-02,  4.5149e-02,  3.7162e-02,  1.6157e-01,\n",
       "         2.6507e-03,  4.1655e-03,  7.1932e-02,  2.6579e-01,  3.8272e-03,\n",
       "         1.9317e-01,  2.4836e-02,  1.4905e-01,  1.5718e-01,  4.1719e-02,\n",
       "         7.0815e-03,  1.7597e-01,  7.3099e-03,  1.9581e-01,  8.1096e-03,\n",
       "         1.4232e-01,  2.0811e-01,  2.4732e-01,  2.0034e-01,  1.4372e-01,\n",
       "         1.7139e-01,  2.1959e-03,  3.4310e-02,  1.0486e-03,  2.0663e-01,\n",
       "        -1.3367e-03,  1.7193e-01,  8.8805e-02,  6.6579e-03,  1.3809e-01,\n",
       "         2.7566e-01,  1.6680e-01,  2.8706e-01,  1.0999e-01,  6.9599e-03,\n",
       "         3.4698e-05,  2.1785e-01,  1.8298e-01,  3.4205e-02,  8.3630e-02,\n",
       "         1.6947e-01,  3.7090e-03,  2.4517e-01,  1.0076e-03,  1.4919e-01,\n",
       "         1.0005e-03,  1.1864e-03,  2.2749e-01,  1.2409e-02], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.bn1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7c8e31c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.8395e-01,  2.5076e-01,  1.9080e-01,  ...,  4.3645e-01,\n",
       "            2.2975e-01,  8.8654e-02],\n",
       "          [ 3.7421e-01,  1.2216e-01,  6.8440e-02,  ...,  3.8697e-01,\n",
       "            6.8679e-02, -5.3376e-02],\n",
       "          [ 3.8322e-01,  1.2404e-01,  1.1459e-01,  ...,  4.0046e-01,\n",
       "            6.8679e-02, -5.3376e-02],\n",
       "          ...,\n",
       "          [ 1.6105e-01,  5.0846e-02,  7.1986e-02,  ...,  2.1359e-01,\n",
       "            6.8679e-02, -5.3376e-02],\n",
       "          [ 1.8690e-01,  6.0473e-02,  6.9189e-02,  ...,  2.0503e-01,\n",
       "            6.8679e-02, -5.3376e-02],\n",
       "          [ 1.2470e-01,  4.2930e-02,  5.8450e-02,  ...,  2.2539e-01,\n",
       "            1.1935e-01, -5.6858e-02]],\n",
       "\n",
       "         [[-1.4520e-01, -1.8773e-01, -1.8586e-01,  ..., -9.9788e-02,\n",
       "           -2.0183e-01, -1.3094e-01],\n",
       "          [-1.1241e-01, -1.5141e-01, -1.4925e-01,  ..., -4.3954e-02,\n",
       "           -1.0142e-01, -9.7098e-02],\n",
       "          [-1.1434e-01, -1.4998e-01, -1.4259e-01,  ..., -4.8374e-02,\n",
       "           -1.0142e-01, -9.7098e-02],\n",
       "          ...,\n",
       "          [-1.4449e-01, -1.7118e-01, -1.4144e-01,  ..., -8.9093e-02,\n",
       "           -1.0142e-01, -9.7098e-02],\n",
       "          [-1.5044e-01, -1.8717e-01, -1.6175e-01,  ..., -8.8484e-02,\n",
       "           -1.0142e-01, -9.7098e-02],\n",
       "          [-1.2233e-01, -1.6415e-01, -1.7996e-01,  ...,  7.4987e-02,\n",
       "            1.1209e-01,  7.7919e-02]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.3149e-04,  3.5941e-02,  4.7137e-02,  ..., -6.6848e-02,\n",
       "            1.1622e-01,  1.0185e-01],\n",
       "          [-1.0794e-01, -6.5017e-02, -1.6062e-02,  ..., -2.6027e-01,\n",
       "           -3.3710e-02, -1.8476e-02],\n",
       "          [-1.5599e-01, -1.1410e-01, -5.9602e-02,  ..., -2.6862e-01,\n",
       "           -3.3710e-02, -1.8476e-02],\n",
       "          ...,\n",
       "          [ 2.2512e-02,  6.8926e-02,  5.9912e-02,  ..., -1.4436e-01,\n",
       "           -3.3710e-02, -1.8476e-02],\n",
       "          [ 1.6303e-02,  6.3998e-02,  8.0520e-02,  ..., -1.4091e-01,\n",
       "           -3.3710e-02, -1.8476e-02],\n",
       "          [-9.9825e-03,  8.2421e-02,  1.3078e-01,  ..., -4.1288e-01,\n",
       "           -3.5674e-01, -2.9240e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[-1.7134e-01, -8.4358e-02, -6.7908e-02,  ..., -1.2564e-01,\n",
       "           -5.6946e-02,  1.4187e-01],\n",
       "          [-5.7747e-02,  6.2348e-02,  1.8379e-02,  ...,  8.1010e-04,\n",
       "            4.1855e-02,  2.4536e-01],\n",
       "          [-1.5680e-02,  8.5298e-02,  2.0978e-02,  ...,  1.0538e-02,\n",
       "            4.1855e-02,  2.4536e-01],\n",
       "          ...,\n",
       "          [ 5.7478e-03, -6.5638e-03, -3.5082e-02,  ...,  3.5852e-02,\n",
       "            4.1855e-02,  2.4536e-01],\n",
       "          [ 9.2037e-03,  1.2028e-02, -3.6724e-02,  ...,  3.9793e-02,\n",
       "            4.1855e-02,  2.4536e-01],\n",
       "          [ 8.9742e-02,  7.1449e-02,  8.8468e-03,  ...,  2.1400e-01,\n",
       "            2.1294e-01,  3.8821e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.5662e-01,  2.7485e-01,  3.0612e-01,  ...,  2.2975e-01,\n",
       "            2.2975e-01,  8.8654e-02],\n",
       "          [-1.3493e-01, -3.7773e-01, -2.9131e-01,  ...,  6.8679e-02,\n",
       "            6.8679e-02, -5.3376e-02],\n",
       "          [-2.8500e-02, -1.3246e-01,  1.5943e-03,  ...,  6.8679e-02,\n",
       "            6.8679e-02, -5.3376e-02],\n",
       "          ...,\n",
       "          [ 2.0588e-01,  1.1460e-01,  1.5362e-01,  ...,  6.8679e-02,\n",
       "            6.8679e-02, -5.3376e-02],\n",
       "          [ 3.0539e-01,  1.1940e-01,  1.1460e-01,  ...,  6.8679e-02,\n",
       "            6.8679e-02, -5.3376e-02],\n",
       "          [ 2.6742e-01,  1.1507e-01,  1.1039e-01,  ...,  1.1935e-01,\n",
       "            1.1935e-01, -5.6858e-02]],\n",
       "\n",
       "         [[ 3.7694e-02,  1.2475e-01,  2.1304e-01,  ..., -2.0183e-01,\n",
       "           -2.0183e-01, -1.3094e-01],\n",
       "          [ 3.7812e-02,  7.8624e-02,  1.4399e-01,  ..., -1.0142e-01,\n",
       "           -1.0142e-01, -9.7098e-02],\n",
       "          [-4.8262e-02, -2.9799e-02, -4.0580e-02,  ..., -1.0142e-01,\n",
       "           -1.0142e-01, -9.7098e-02],\n",
       "          ...,\n",
       "          [-6.6671e-02, -1.2604e-01, -1.0039e-01,  ..., -1.0142e-01,\n",
       "           -1.0142e-01, -9.7098e-02],\n",
       "          [-5.4030e-02, -8.0664e-02, -8.9258e-02,  ..., -1.0142e-01,\n",
       "           -1.0142e-01, -9.7098e-02],\n",
       "          [ 1.1990e-02,  5.3505e-02,  5.7067e-02,  ...,  1.1209e-01,\n",
       "            1.1209e-01,  7.7919e-02]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.4929e-01, -4.3094e-01, -5.3045e-01,  ...,  1.1622e-01,\n",
       "            1.1622e-01,  1.0185e-01],\n",
       "          [-1.2003e-01, -8.3442e-02, -2.0058e-01,  ..., -3.3710e-02,\n",
       "           -3.3710e-02, -1.8476e-02],\n",
       "          [-3.2802e-03,  1.2584e-01,  1.1269e-01,  ..., -3.3710e-02,\n",
       "           -3.3710e-02, -1.8476e-02],\n",
       "          ...,\n",
       "          [-5.7487e-03,  8.2665e-02, -3.4887e-02,  ..., -3.3710e-02,\n",
       "           -3.3710e-02, -1.8476e-02],\n",
       "          [-1.0921e-01,  9.8317e-03, -2.9230e-02,  ..., -3.3710e-02,\n",
       "           -3.3710e-02, -1.8476e-02],\n",
       "          [-2.7337e-01, -2.3069e-01, -2.3478e-01,  ..., -3.5674e-01,\n",
       "           -3.5674e-01, -2.9240e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[ 8.3820e-02,  2.7023e-01,  3.1549e-01,  ..., -5.6946e-02,\n",
       "           -5.6946e-02,  1.4187e-01],\n",
       "          [ 1.8321e-01,  1.4087e-01,  1.0013e-01,  ...,  4.1855e-02,\n",
       "            4.1855e-02,  2.4536e-01],\n",
       "          [ 1.1195e-01,  2.1415e-02, -1.1417e-01,  ...,  4.1855e-02,\n",
       "            4.1855e-02,  2.4536e-01],\n",
       "          ...,\n",
       "          [-8.2331e-02, -1.3080e-01, -3.1952e-02,  ...,  4.1855e-02,\n",
       "            4.1855e-02,  2.4536e-01],\n",
       "          [-5.4667e-02, -3.0598e-02,  2.3832e-03,  ...,  4.1855e-02,\n",
       "            4.1855e-02,  2.4536e-01],\n",
       "          [ 5.2962e-02,  1.0482e-01,  1.1425e-01,  ...,  2.1294e-01,\n",
       "            2.1294e-01,  3.8821e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.5924e-01,  2.2975e-01, -6.1357e-02,  ..., -7.1093e-02,\n",
       "           -7.0446e-02,  7.0822e-02],\n",
       "          [ 4.0637e-01,  6.8679e-02, -1.8954e-01,  ...,  6.1060e-02,\n",
       "            6.0604e-02,  1.8591e-01],\n",
       "          [ 4.0637e-01,  6.8679e-02, -2.0889e-01,  ...,  6.4625e-02,\n",
       "            6.4370e-02,  1.8943e-01],\n",
       "          ...,\n",
       "          [ 4.0637e-01,  6.8679e-02,  7.7057e-02,  ...,  1.6903e-01,\n",
       "            1.7480e-01,  2.6237e-02],\n",
       "          [ 4.0637e-01,  6.8679e-02,  6.8679e-02,  ...,  6.8679e-02,\n",
       "            6.8679e-02, -5.3376e-02],\n",
       "          [ 3.8231e-01,  1.1935e-01,  1.1935e-01,  ...,  1.1935e-01,\n",
       "            1.1935e-01, -5.6858e-02]],\n",
       "\n",
       "         [[-9.6822e-02, -2.0183e-01, -5.1563e-02,  ...,  9.3853e-02,\n",
       "            9.3700e-02,  1.5485e-02],\n",
       "          [-3.4490e-02, -1.0142e-01, -7.6930e-02,  ...,  3.2076e-02,\n",
       "            3.2504e-02,  2.5036e-03],\n",
       "          [-3.4490e-02, -1.0142e-01, -1.1418e-01,  ...,  2.7342e-02,\n",
       "            2.7713e-02,  3.6539e-04],\n",
       "          ...,\n",
       "          [-3.4490e-02, -1.0142e-01, -1.2725e-01,  ..., -1.4907e-01,\n",
       "           -1.5583e-01, -1.0887e-01],\n",
       "          [-3.4490e-02, -1.0142e-01, -1.0142e-01,  ..., -1.0142e-01,\n",
       "           -1.0142e-01, -9.7098e-02],\n",
       "          [ 5.4080e-02,  1.1209e-01,  1.1209e-01,  ...,  1.1209e-01,\n",
       "            1.1209e-01,  7.7919e-02]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.3855e-02,  1.1622e-01,  7.3885e-02,  ..., -6.4446e-02,\n",
       "           -6.3323e-02, -3.3013e-02],\n",
       "          [-2.1759e-01, -3.3710e-02, -2.6589e-02,  ...,  3.6598e-02,\n",
       "            3.4647e-02,  5.4860e-02],\n",
       "          [-2.1759e-01, -3.3710e-02,  1.1630e-02,  ...,  3.7111e-02,\n",
       "            3.3636e-02,  5.0933e-02],\n",
       "          ...,\n",
       "          [-2.1759e-01, -3.3710e-02, -2.9752e-02,  ...,  5.9503e-02,\n",
       "            3.6023e-02,  5.0001e-02],\n",
       "          [-2.1759e-01, -3.3710e-02, -3.3710e-02,  ..., -3.3710e-02,\n",
       "           -3.3710e-02, -1.8476e-02],\n",
       "          [-4.4329e-01, -3.5674e-01, -3.5674e-01,  ..., -3.5674e-01,\n",
       "           -3.5674e-01, -2.9240e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[-1.2467e-01, -5.6946e-02,  3.3903e-01,  ...,  3.0752e-02,\n",
       "            3.0955e-02, -1.4712e-01],\n",
       "          [-1.9197e-02,  4.1855e-02,  4.2950e-01,  ..., -1.2360e-01,\n",
       "           -1.2075e-01, -2.8229e-01],\n",
       "          [-1.9197e-02,  4.1855e-02,  3.8756e-01,  ..., -1.2285e-01,\n",
       "           -1.2000e-01, -2.8321e-01],\n",
       "          ...,\n",
       "          [-1.9197e-02,  4.1855e-02,  3.0658e-02,  ..., -5.7955e-02,\n",
       "           -4.1499e-02,  1.6238e-01],\n",
       "          [-1.9197e-02,  4.1855e-02,  4.1855e-02,  ...,  4.1855e-02,\n",
       "            4.1855e-02,  2.4536e-01],\n",
       "          [ 1.3089e-01,  2.1294e-01,  2.1294e-01,  ...,  2.1294e-01,\n",
       "            2.1294e-01,  3.8821e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 4.5924e-01,  2.2975e-01,  2.2975e-01,  ...,  2.2975e-01,\n",
       "            2.2975e-01,  8.8654e-02],\n",
       "          [ 4.0637e-01,  6.8679e-02,  6.8679e-02,  ...,  9.0273e-02,\n",
       "            8.3499e-02, -4.9357e-02],\n",
       "          [ 4.0637e-01,  6.8679e-02,  6.8679e-02,  ..., -1.7453e-03,\n",
       "            1.1383e-02, -3.0948e-02],\n",
       "          ...,\n",
       "          [ 4.0637e-01,  6.8679e-02,  6.8679e-02,  ...,  1.2354e-01,\n",
       "            1.2006e-01,  1.7378e-01],\n",
       "          [ 4.0637e-01,  6.8679e-02,  6.8679e-02,  ...,  3.6033e-02,\n",
       "            1.1314e-01,  2.0494e-01],\n",
       "          [ 3.8231e-01,  1.1935e-01,  1.1935e-01,  ...,  9.8628e-02,\n",
       "            1.4553e-01,  1.7282e-01]],\n",
       "\n",
       "         [[-9.6822e-02, -2.0183e-01, -2.0183e-01,  ..., -2.0183e-01,\n",
       "           -2.0183e-01, -1.3094e-01],\n",
       "          [-3.4490e-02, -1.0142e-01, -1.0142e-01,  ...,  2.0444e-02,\n",
       "            1.0141e-02, -1.2105e-02],\n",
       "          [-3.4490e-02, -1.0142e-01, -1.0142e-01,  ..., -1.4736e-02,\n",
       "           -2.2307e-02, -5.1017e-02],\n",
       "          ...,\n",
       "          [-3.4490e-02, -1.0142e-01, -1.0142e-01,  ..., -1.3295e-01,\n",
       "           -1.2306e-01, -1.1234e-01],\n",
       "          [-3.4490e-02, -1.0142e-01, -1.0142e-01,  ..., -1.5244e-01,\n",
       "           -1.6020e-01, -1.1638e-01],\n",
       "          [ 5.4080e-02,  1.1209e-01,  1.1209e-01,  ..., -1.4491e-01,\n",
       "           -1.2674e-01, -1.0416e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.3855e-02,  1.1622e-01,  1.1622e-01,  ...,  1.1622e-01,\n",
       "            1.1622e-01,  1.0185e-01],\n",
       "          [-2.1759e-01, -3.3710e-02, -3.3710e-02,  ..., -2.2061e-01,\n",
       "           -2.0684e-01, -1.4617e-01],\n",
       "          [-2.1759e-01, -3.3710e-02, -3.3710e-02,  ..., -1.1912e-01,\n",
       "           -1.1511e-01, -8.8127e-02],\n",
       "          ...,\n",
       "          [-2.1759e-01, -3.3710e-02, -3.3710e-02,  ..., -1.2545e-02,\n",
       "           -3.6499e-02, -2.7315e-02],\n",
       "          [-2.1759e-01, -3.3710e-02, -3.3710e-02,  ...,  6.3923e-02,\n",
       "            7.3763e-02,  6.8104e-03],\n",
       "          [-4.4329e-01, -3.5674e-01, -3.5674e-01,  ...,  1.0108e-01,\n",
       "            8.9825e-02,  1.9578e-02]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[-1.2467e-01, -5.6946e-02, -5.6946e-02,  ..., -5.6946e-02,\n",
       "           -5.6946e-02,  1.4187e-01],\n",
       "          [-1.9197e-02,  4.1855e-02,  4.1855e-02,  ...,  1.5814e-01,\n",
       "            1.5244e-01,  3.2276e-01],\n",
       "          [-1.9197e-02,  4.1855e-02,  4.1855e-02,  ...,  7.2852e-02,\n",
       "            6.0835e-02,  1.8614e-01],\n",
       "          ...,\n",
       "          [-1.9197e-02,  4.1855e-02,  4.1855e-02,  ...,  1.4770e-02,\n",
       "            3.6732e-02, -7.3431e-02],\n",
       "          [-1.9197e-02,  4.1855e-02,  4.1855e-02,  ...,  4.9606e-02,\n",
       "           -3.1955e-02, -5.5934e-02],\n",
       "          [ 1.3089e-01,  2.1294e-01,  2.1294e-01,  ..., -1.8710e-02,\n",
       "           -6.9574e-02, -5.5444e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.2670e-01, -1.2354e-01,  1.3161e-01,  ...,  1.0332e-01,\n",
       "            8.9461e-02,  9.2929e-02],\n",
       "          [ 2.9079e-01, -2.3172e-01,  1.1722e-01,  ...,  1.3890e-01,\n",
       "            1.1625e-01,  1.3420e-01],\n",
       "          [ 3.1139e-01, -2.1807e-01,  1.0413e-01,  ...,  1.2566e-01,\n",
       "            1.3182e-01,  1.4721e-01],\n",
       "          ...,\n",
       "          [ 4.0637e-01,  6.8679e-02,  6.8679e-02,  ...,  6.8679e-02,\n",
       "            6.8679e-02, -5.3376e-02],\n",
       "          [ 4.0637e-01,  6.8679e-02,  6.8679e-02,  ...,  6.8679e-02,\n",
       "            6.8679e-02, -5.3376e-02],\n",
       "          [ 3.8231e-01,  1.1935e-01,  1.1935e-01,  ...,  1.1935e-01,\n",
       "            1.1935e-01, -5.6858e-02]],\n",
       "\n",
       "         [[-3.3544e-02, -1.9938e-01, -9.4408e-02,  ..., -8.3503e-02,\n",
       "           -7.3151e-02, -7.8326e-02],\n",
       "          [-4.7724e-02, -1.7610e-01, -1.1681e-01,  ..., -1.1892e-01,\n",
       "           -1.2228e-01, -1.0727e-01],\n",
       "          [-4.7302e-02, -1.6662e-01, -1.0080e-01,  ..., -1.2632e-01,\n",
       "           -1.4173e-01, -1.2934e-01],\n",
       "          ...,\n",
       "          [-3.4490e-02, -1.0142e-01, -1.0142e-01,  ..., -1.0142e-01,\n",
       "           -1.0142e-01, -9.7098e-02],\n",
       "          [-3.4490e-02, -1.0142e-01, -1.0142e-01,  ..., -1.0142e-01,\n",
       "           -1.0142e-01, -9.7098e-02],\n",
       "          [ 5.4080e-02,  1.1209e-01,  1.1209e-01,  ...,  1.1209e-01,\n",
       "            1.1209e-01,  7.7919e-02]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.7784e-02,  1.7298e-01, -2.5086e-02,  ..., -1.4988e-02,\n",
       "           -3.0119e-02, -2.2970e-02],\n",
       "          [-1.9298e-01,  2.2966e-01,  6.2079e-03,  ...,  1.8491e-02,\n",
       "            2.3465e-02,  3.1800e-02],\n",
       "          [-1.9959e-01,  1.9332e-01, -8.7564e-04,  ...,  2.8203e-02,\n",
       "            6.0460e-02,  6.6110e-02],\n",
       "          ...,\n",
       "          [-2.1759e-01, -3.3710e-02, -3.3710e-02,  ..., -3.3710e-02,\n",
       "           -3.3710e-02, -1.8476e-02],\n",
       "          [-2.1759e-01, -3.3710e-02, -3.3710e-02,  ..., -3.3710e-02,\n",
       "           -3.3710e-02, -1.8476e-02],\n",
       "          [-4.4329e-01, -3.5674e-01, -3.5674e-01,  ..., -3.5674e-01,\n",
       "           -3.5674e-01, -2.9240e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[ 8.1642e-02,  1.2252e-02, -6.6707e-02,  ..., -8.1770e-02,\n",
       "           -5.0596e-02, -1.0742e-01],\n",
       "          [ 2.0200e-01,  2.2540e-02, -3.2259e-02,  ..., -3.5518e-02,\n",
       "           -2.4972e-02, -1.1842e-01],\n",
       "          [ 1.9135e-01,  4.7626e-02, -7.5638e-03,  ..., -3.7599e-02,\n",
       "           -5.7393e-02, -1.1874e-01],\n",
       "          ...,\n",
       "          [-1.9197e-02,  4.1855e-02,  4.1855e-02,  ...,  4.1855e-02,\n",
       "            4.1855e-02,  2.4536e-01],\n",
       "          [-1.9197e-02,  4.1855e-02,  4.1855e-02,  ...,  4.1855e-02,\n",
       "            4.1855e-02,  2.4536e-01],\n",
       "          [ 1.3089e-01,  2.1294e-01,  2.1294e-01,  ...,  2.1294e-01,\n",
       "            2.1294e-01,  3.8821e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.5924e-01,  2.2975e-01,  2.2975e-01,  ...,  2.2975e-01,\n",
       "            2.2975e-01,  8.8654e-02],\n",
       "          [ 4.0637e-01,  6.8679e-02,  6.8679e-02,  ...,  6.8679e-02,\n",
       "            6.8679e-02, -5.3376e-02],\n",
       "          [ 4.0637e-01,  6.8679e-02,  6.8679e-02,  ...,  6.8679e-02,\n",
       "            6.8679e-02, -5.3376e-02],\n",
       "          ...,\n",
       "          [ 1.9982e-01, -4.3593e-01,  1.4082e-01,  ...,  4.2491e-02,\n",
       "            3.5805e-02,  1.2454e-01],\n",
       "          [ 2.0824e-01, -4.2414e-01,  1.2564e-01,  ...,  3.8676e-02,\n",
       "            3.7121e-02,  1.1199e-01],\n",
       "          [ 1.1117e-01, -3.3865e-01,  6.6603e-02,  ...,  6.3476e-02,\n",
       "            6.1968e-02,  1.2295e-01]],\n",
       "\n",
       "         [[-9.6822e-02, -2.0183e-01, -2.0183e-01,  ..., -2.0183e-01,\n",
       "           -2.0183e-01, -1.3094e-01],\n",
       "          [-3.4490e-02, -1.0142e-01, -1.0142e-01,  ..., -1.0142e-01,\n",
       "           -1.0142e-01, -9.7098e-02],\n",
       "          [-3.4490e-02, -1.0142e-01, -1.0142e-01,  ..., -1.0142e-01,\n",
       "           -1.0142e-01, -9.7098e-02],\n",
       "          ...,\n",
       "          [-2.7262e-02, -1.5055e-01, -4.8233e-02,  ...,  1.3097e-02,\n",
       "            2.0083e-02, -1.3138e-02],\n",
       "          [-2.5034e-02, -1.3701e-01, -2.8805e-02,  ...,  3.5123e-02,\n",
       "            4.4175e-02,  1.3869e-02],\n",
       "          [ 5.6643e-03, -5.8445e-02, -1.4208e-01,  ..., -2.6845e-03,\n",
       "           -1.2607e-02, -3.3644e-02]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.3855e-02,  1.1622e-01,  1.1622e-01,  ...,  1.1622e-01,\n",
       "            1.1622e-01,  1.0185e-01],\n",
       "          [-2.1759e-01, -3.3710e-02, -3.3710e-02,  ..., -3.3710e-02,\n",
       "           -3.3710e-02, -1.8476e-02],\n",
       "          [-2.1759e-01, -3.3710e-02, -3.3710e-02,  ..., -3.3710e-02,\n",
       "           -3.3710e-02, -1.8476e-02],\n",
       "          ...,\n",
       "          [-1.9892e-01,  3.5132e-01,  4.8479e-02,  ...,  1.7039e-02,\n",
       "            1.7296e-02,  6.1227e-02],\n",
       "          [-2.0116e-01,  3.2541e-01,  1.5972e-02,  ..., -1.6738e-03,\n",
       "           -2.2999e-02,  2.8936e-02],\n",
       "          [-3.5194e-01,  3.3949e-01,  2.1140e-01,  ...,  4.3640e-02,\n",
       "            4.9608e-02,  7.5508e-02]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[-1.2467e-01, -5.6946e-02, -5.6946e-02,  ..., -5.6946e-02,\n",
       "           -5.6946e-02,  1.4187e-01],\n",
       "          [-1.9197e-02,  4.1855e-02,  4.1855e-02,  ...,  4.1855e-02,\n",
       "            4.1855e-02,  2.4536e-01],\n",
       "          [-1.9197e-02,  4.1855e-02,  4.1855e-02,  ...,  4.1855e-02,\n",
       "            4.1855e-02,  2.4536e-01],\n",
       "          ...,\n",
       "          [ 3.0988e-01, -2.5743e-02, -1.3355e-01,  ..., -4.2512e-02,\n",
       "           -5.0386e-02, -1.3454e-01],\n",
       "          [ 2.9948e-01, -7.7072e-03, -1.0128e-01,  ..., -4.3463e-02,\n",
       "           -3.4265e-02, -1.0067e-01],\n",
       "          [ 3.9293e-01, -6.6138e-02, -2.1337e-01,  ..., -2.0138e-01,\n",
       "           -2.1264e-01, -2.2577e-01]]]], device='cuda:0',\n",
       "       grad_fn=<CudnnBatchNormBackward0>)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_alter.bn1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinit_bn(bn):\n",
    "    bn_copy = torch.nn.BatchNorm2d(\n",
    "        num_features=bn.num_features,\n",
    "        eps=\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "e5221326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_copy = torch.nn.BatchNorm2d(64, affine=False)\n",
    "bn_copy.running_mean = model_to_alter.bn1.running_mean\n",
    "bn_copy.running_var = model_to_alter.bn1.running_var\n",
    "bn_copy.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f56c1585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 8.9498e-01,  2.5174e-01,  3.1861e-01,  ..., -4.5012e-01,\n",
       "            6.8267e-01,  1.0177e+00],\n",
       "          [ 6.4966e-01, -1.0747e-01, -5.4608e-02,  ..., -3.3555e-01,\n",
       "            6.2257e-01,  9.4255e-01],\n",
       "          [ 5.6776e-01, -1.9791e-01, -3.3246e-01,  ..., -4.6928e-01,\n",
       "            4.6046e-01,  1.0594e+00],\n",
       "          ...,\n",
       "          [ 6.7263e-01, -9.8307e-02, -8.2092e-02,  ..., -1.0027e-01,\n",
       "            2.2852e-01, -1.8406e-01],\n",
       "          [ 1.4178e+00,  2.5572e-01,  2.7387e-01,  ...,  1.8409e-01,\n",
       "            1.6184e-01, -4.3754e-01],\n",
       "          [ 1.1984e+00,  1.0435e-01,  1.0435e-01,  ...,  1.0435e-01,\n",
       "            1.0435e-01, -6.2748e-01]],\n",
       "\n",
       "         [[-1.1181e-02, -4.5649e-01, -4.3789e-01,  ...,  2.1656e-01,\n",
       "           -2.4214e-01,  4.0661e-01],\n",
       "          [ 3.4579e-01,  1.4526e-01,  2.8036e-01,  ...,  2.3088e-01,\n",
       "            2.3999e-01,  4.6710e-01],\n",
       "          [ 1.9874e-01,  4.8089e-02,  1.5994e-01,  ...,  3.2368e-01,\n",
       "            3.3562e-01,  5.9756e-01],\n",
       "          ...,\n",
       "          [-3.6983e-02, -7.2090e-01, -7.1546e-01,  ..., -7.3085e-01,\n",
       "           -6.2872e-01, -3.3114e-01],\n",
       "          [ 8.1013e-02, -5.2065e-01, -5.3386e-01,  ..., -4.8345e-01,\n",
       "           -3.2140e-01, -2.8969e-01],\n",
       "          [ 9.0006e-01,  1.3143e+00,  1.3143e+00,  ...,  1.3143e+00,\n",
       "            1.3143e+00,  1.0735e+00]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.4640e-02,  4.4715e-01,  5.1029e-01,  ...,  2.7011e-01,\n",
       "            1.0198e-01, -2.4038e-01],\n",
       "          [-6.0644e-01, -2.5006e-02, -1.8364e-01,  ...,  3.7520e-01,\n",
       "           -3.8202e-02, -9.1293e-01],\n",
       "          [-3.9130e-01,  6.1236e-02, -1.2334e-03,  ...,  1.8472e-01,\n",
       "           -1.0113e-01, -1.0239e+00],\n",
       "          ...,\n",
       "          [ 4.0235e-02,  7.5569e-01,  7.4263e-01,  ...,  6.8230e-01,\n",
       "            4.1406e-01, -2.0549e-01],\n",
       "          [-6.4441e-01,  1.5806e-01,  1.4040e-01,  ...,  1.7140e-01,\n",
       "            7.5712e-02, -1.0820e-01],\n",
       "          [-1.9811e+00, -1.5905e+00, -1.5905e+00,  ..., -1.5905e+00,\n",
       "           -1.5905e+00, -1.3036e+00]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[-3.0761e-01, -1.5829e-01, -2.2314e-01,  ..., -9.1573e-02,\n",
       "           -9.3667e-01,  4.2148e-01],\n",
       "          [ 2.8125e-02, -5.2630e-03,  1.4998e-01,  ..., -2.8881e-01,\n",
       "           -1.0156e+00,  8.2268e-01],\n",
       "          [-1.0482e-01, -2.7072e-03,  2.0905e-01,  ..., -8.3581e-03,\n",
       "           -1.0112e+00,  7.9753e-01],\n",
       "          ...,\n",
       "          [-5.3162e-01, -6.1023e-01, -6.0707e-01,  ..., -3.9649e-01,\n",
       "           -5.3408e-01,  9.5700e-01],\n",
       "          [-2.9183e-01, -1.1231e-01, -1.1179e-01,  ...,  1.6273e-02,\n",
       "            7.1193e-02,  1.1183e+00],\n",
       "          [ 6.6195e-01,  1.0009e+00,  1.0009e+00,  ...,  1.0009e+00,\n",
       "            1.0009e+00,  1.7207e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7332e-01,  5.4982e-02,  5.5644e-02,  ...,  1.4765e+00,\n",
       "            5.6652e-01, -2.2754e-02],\n",
       "          [ 1.6550e-01, -4.7605e-02, -2.1789e-02,  ...,  1.2040e+00,\n",
       "           -1.0722e-01, -6.1671e-01],\n",
       "          [ 2.0895e-01, -5.1449e-02, -2.3446e-02,  ...,  1.1563e+00,\n",
       "           -1.0722e-01, -6.1671e-01],\n",
       "          ...,\n",
       "          [-4.8106e-01, -3.1177e-01, -2.8168e-02,  ...,  3.7029e-01,\n",
       "           -1.0722e-01, -6.1671e-01],\n",
       "          [ 5.2742e-01,  4.3839e-01,  5.2214e-01,  ...,  3.8686e-01,\n",
       "           -1.0722e-01, -6.1671e-01],\n",
       "          [ 7.4399e-01,  1.7531e-01,  1.5238e-01,  ...,  4.9822e-01,\n",
       "            1.0435e-01, -6.2748e-01]],\n",
       "\n",
       "         [[-1.0924e-01, -1.6678e-01, -1.5349e-01,  ..., -2.0396e-01,\n",
       "           -9.4479e-01, -4.2860e-01],\n",
       "          [-1.0791e-01, -1.9034e-01, -1.7574e-01,  ...,  2.1289e-01,\n",
       "           -2.2509e-01, -1.8798e-01],\n",
       "          [-1.1428e-01, -2.1066e-01, -2.1427e-01,  ...,  1.8535e-01,\n",
       "           -2.2509e-01, -1.8798e-01],\n",
       "          ...,\n",
       "          [-3.5694e-01, -7.7638e-01, -1.0460e+00,  ...,  7.2381e-03,\n",
       "           -2.2509e-01, -1.8798e-01],\n",
       "          [-3.6555e-01, -8.8606e-01, -6.5863e-01,  ...,  8.8282e-03,\n",
       "           -2.2509e-01, -1.8798e-01],\n",
       "          [ 5.2670e-01,  7.7119e-01,  8.4475e-01,  ...,  1.1862e+00,\n",
       "            1.3143e+00,  1.0735e+00]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.2470e-01,  2.8187e-01,  2.7103e-01,  ..., -1.6361e-01,\n",
       "            5.3185e-01,  4.6706e-01],\n",
       "          [ 2.6281e-01,  3.7563e-01,  3.5032e-01,  ..., -9.1694e-01,\n",
       "           -1.4348e-01, -7.4469e-02],\n",
       "          [ 2.3235e-01,  3.9791e-01,  3.8835e-01,  ..., -8.8520e-01,\n",
       "           -1.4348e-01, -7.4469e-02],\n",
       "          ...,\n",
       "          [ 1.0015e+00,  1.1673e+00,  1.3205e+00,  ..., -3.7831e-01,\n",
       "           -1.4348e-01, -7.4469e-02],\n",
       "          [ 7.4599e-01,  9.4743e-01,  7.3958e-01,  ..., -3.8644e-01,\n",
       "           -1.4348e-01, -7.4469e-02],\n",
       "          [-8.5185e-01, -6.6605e-01, -8.0586e-01,  ..., -1.6923e+00,\n",
       "           -1.5905e+00, -1.3036e+00]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[-3.0990e-01, -3.2708e-01, -3.2600e-01,  ..., -4.4961e-01,\n",
       "           -1.2038e-01,  6.9831e-01],\n",
       "          [-2.5866e-01, -2.5335e-01, -2.5910e-01,  ...,  2.3578e-02,\n",
       "            2.8585e-01,  1.1250e+00],\n",
       "          [-2.5167e-01, -2.5054e-01, -2.6577e-01,  ...,  2.9028e-02,\n",
       "            2.8585e-01,  1.1250e+00],\n",
       "          ...,\n",
       "          [-5.0292e-01, -7.3586e-01, -9.5844e-01,  ...,  1.5196e-01,\n",
       "            2.8585e-01,  1.1250e+00],\n",
       "          [-6.8074e-01, -6.3490e-01, -4.7752e-01,  ...,  1.4409e-01,\n",
       "            2.8585e-01,  1.1250e+00],\n",
       "          [ 1.5940e-01,  3.4384e-01,  4.1750e-01,  ...,  8.3541e-01,\n",
       "            1.0009e+00,  1.7207e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5234e+00,  5.6652e-01, -5.7413e-01,  ..., -6.2476e-01,\n",
       "           -7.4309e-01, -1.4332e-01],\n",
       "          [ 1.3006e+00, -1.0722e-01, -1.2004e+00,  ..., -1.7569e-01,\n",
       "           -2.5467e-01,  3.3795e-01],\n",
       "          [ 1.3006e+00, -1.0722e-01, -1.1258e+00,  ..., -1.4774e-01,\n",
       "           -1.7714e-01,  3.3480e-01],\n",
       "          ...,\n",
       "          [ 1.3006e+00, -1.0722e-01, -6.8634e-01,  ..., -4.7531e-02,\n",
       "           -1.5795e-01, -2.5231e-01],\n",
       "          [ 1.3006e+00, -1.0722e-01, -6.5112e-01,  ..., -1.2464e-01,\n",
       "           -1.8290e-01, -1.9711e-01],\n",
       "          [ 1.1984e+00,  1.0435e-01,  1.7114e-01,  ...,  6.0563e-01,\n",
       "            5.8795e-01, -1.9998e-01]],\n",
       "\n",
       "         [[-1.8471e-01, -9.4479e-01,  9.4285e-02,  ...,  9.9222e-01,\n",
       "            9.7553e-01,  4.5451e-01],\n",
       "          [ 2.6012e-01, -2.2509e-01, -3.2485e-02,  ...,  5.8714e-01,\n",
       "            5.1570e-01,  3.3451e-01],\n",
       "          [ 2.6012e-01, -2.2509e-01, -7.6993e-02,  ...,  6.4468e-01,\n",
       "            6.3556e-01,  4.5623e-01],\n",
       "          ...,\n",
       "          [ 2.6012e-01, -2.2509e-01, -7.2205e-02,  ...,  2.9507e-01,\n",
       "            3.1423e-01,  1.7034e-01],\n",
       "          [ 2.6012e-01, -2.2509e-01, -3.6486e-01,  ..., -7.3418e-01,\n",
       "           -7.4699e-01, -6.3313e-01],\n",
       "          [ 9.0006e-01,  1.3143e+00,  9.8068e-01,  ...,  9.2819e-01,\n",
       "            9.3704e-01,  9.8971e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.9442e-01,  5.3185e-01,  3.5160e-01,  ..., -2.5011e-01,\n",
       "           -2.0497e-01, -8.0425e-02],\n",
       "          [-9.7450e-01, -1.4348e-01, -8.9682e-02,  ...,  1.8371e-01,\n",
       "            3.0529e-01,  4.1076e-01],\n",
       "          [-9.7450e-01, -1.4348e-01, -1.0294e-01,  ...,  1.6030e-01,\n",
       "            2.2059e-01,  3.0741e-01],\n",
       "          ...,\n",
       "          [-9.7450e-01, -1.4348e-01, -2.2923e-01,  ..., -2.1783e-01,\n",
       "           -2.1207e-01,  2.2685e-02],\n",
       "          [-9.7450e-01, -1.4348e-01, -4.2840e-02,  ...,  7.2116e-01,\n",
       "            7.4245e-01,  7.8149e-01],\n",
       "          [-1.9811e+00, -1.5905e+00, -1.5552e+00,  ..., -1.2653e+00,\n",
       "           -1.2535e+00, -9.8822e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[-3.9775e-01, -1.2038e-01,  1.4432e+00,  ...,  2.7450e-01,\n",
       "            2.9020e-01, -5.3256e-01],\n",
       "          [ 3.5713e-02,  2.8585e-01,  1.8917e+00,  ..., -1.9907e-01,\n",
       "           -2.4310e-01, -1.0026e+00],\n",
       "          [ 3.5713e-02,  2.8585e-01,  1.7966e+00,  ..., -2.5012e-01,\n",
       "           -2.7793e-01, -8.8504e-01],\n",
       "          ...,\n",
       "          [ 3.5713e-02,  2.8585e-01,  1.0510e+00,  ...,  1.2204e-01,\n",
       "            2.0438e-01,  3.6331e-01],\n",
       "          [ 3.5713e-02,  2.8585e-01,  7.5811e-01,  ..., -6.1430e-01,\n",
       "           -5.9221e-01, -2.0448e-01],\n",
       "          [ 6.6195e-01,  1.0009e+00,  9.5659e-01,  ...,  5.1559e-01,\n",
       "            5.1204e-01,  1.2769e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 1.5234e+00,  5.6652e-01,  5.6652e-01,  ...,  5.6652e-01,\n",
       "            5.6652e-01, -2.2754e-02],\n",
       "          [ 1.3006e+00, -1.0722e-01, -1.0722e-01,  ...,  2.7050e-01,\n",
       "            2.7689e-01, -6.5844e-01],\n",
       "          [ 1.3006e+00, -1.0722e-01, -1.0722e-01,  ..., -1.4510e+00,\n",
       "           -1.4356e+00, -6.3088e-01],\n",
       "          ...,\n",
       "          [ 1.3006e+00, -1.0722e-01, -1.0722e-01,  ..., -1.4811e-01,\n",
       "            1.1745e+00,  4.9839e-01],\n",
       "          [ 1.3006e+00, -1.0722e-01, -1.0722e-01,  ...,  2.2628e-02,\n",
       "            1.1557e+00,  3.6864e-01],\n",
       "          [ 1.1984e+00,  1.0435e-01,  1.0435e-01,  ..., -2.9759e-01,\n",
       "           -2.2360e-01,  1.5756e-01]],\n",
       "\n",
       "         [[-1.8471e-01, -9.4479e-01, -9.4479e-01,  ..., -9.4479e-01,\n",
       "           -9.4479e-01, -4.2860e-01],\n",
       "          [ 2.6012e-01, -2.2509e-01, -2.2509e-01,  ...,  3.0394e+00,\n",
       "            3.0465e+00,  2.4757e+00],\n",
       "          [ 2.6012e-01, -2.2509e-01, -2.2509e-01,  ...,  1.9103e+00,\n",
       "            1.9254e+00,  7.9572e-01],\n",
       "          ...,\n",
       "          [ 2.6012e-01, -2.2509e-01, -2.2509e-01,  ...,  5.1524e-01,\n",
       "            7.5907e-01,  5.8985e-01],\n",
       "          [ 2.6012e-01, -2.2509e-01, -2.2509e-01,  ...,  9.8063e-01,\n",
       "            1.2684e+00,  1.4200e+00],\n",
       "          [ 9.0006e-01,  1.3143e+00,  1.3143e+00,  ..., -6.8803e-01,\n",
       "           -4.4697e-01, -6.9016e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.9442e-01,  5.3185e-01,  5.3185e-01,  ...,  5.3185e-01,\n",
       "            5.3185e-01,  4.6706e-01],\n",
       "          [-9.7450e-01, -1.4348e-01, -1.4348e-01,  ..., -3.2040e+00,\n",
       "           -3.2201e+00, -2.6763e+00],\n",
       "          [-9.7450e-01, -1.4348e-01, -1.4348e-01,  ..., -1.1337e+00,\n",
       "           -1.1269e+00, -8.5857e-01],\n",
       "          ...,\n",
       "          [-9.7450e-01, -1.4348e-01, -1.4348e-01,  ..., -3.2289e-01,\n",
       "           -1.1760e+00, -9.7639e-01],\n",
       "          [-9.7450e-01, -1.4348e-01, -1.4348e-01,  ..., -2.3893e-01,\n",
       "           -1.6318e+00, -2.1213e+00],\n",
       "          [-1.9811e+00, -1.5905e+00, -1.5905e+00,  ...,  1.4264e+00,\n",
       "            8.9007e-01,  3.5034e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[-3.9775e-01, -1.2038e-01, -1.2038e-01,  ..., -1.2038e-01,\n",
       "           -1.2038e-01,  6.9831e-01],\n",
       "          [ 3.5713e-02,  2.8585e-01,  2.8585e-01,  ...,  1.9494e+00,\n",
       "            1.9493e+00,  2.4791e+00],\n",
       "          [ 3.5713e-02,  2.8585e-01,  2.8585e-01,  ...,  5.3233e-01,\n",
       "            5.2553e-01, -4.3846e-01],\n",
       "          ...,\n",
       "          [ 3.5713e-02,  2.8585e-01,  2.8585e-01,  ..., -2.6771e-01,\n",
       "           -3.3166e-01,  8.9202e-01],\n",
       "          [ 3.5713e-02,  2.8585e-01,  2.8585e-01,  ..., -4.1649e-01,\n",
       "           -9.7650e-02,  1.2527e+00],\n",
       "          [ 6.6195e-01,  1.0009e+00,  1.0009e+00,  ..., -1.1727e+00,\n",
       "           -9.4083e-01, -1.0316e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5234e+00,  5.6652e-01,  5.6652e-01,  ...,  5.6652e-01,\n",
       "            5.6652e-01, -2.2754e-02],\n",
       "          [ 1.3006e+00, -1.0722e-01, -1.0722e-01,  ...,  1.1818e-01,\n",
       "            1.8309e-01, -5.0954e-01],\n",
       "          [ 1.3006e+00, -1.0722e-01, -1.0722e-01,  ..., -1.2974e+00,\n",
       "           -7.4591e-01, -3.1230e-01],\n",
       "          ...,\n",
       "          [ 1.3006e+00, -1.0722e-01, -1.0722e-01,  ..., -1.2080e-01,\n",
       "           -5.1825e-02, -1.6951e-02],\n",
       "          [ 1.3006e+00, -1.0722e-01, -1.0722e-01,  ..., -3.6435e-02,\n",
       "           -6.4142e-02, -3.9787e-02],\n",
       "          [ 1.1984e+00,  1.0435e-01,  1.0435e-01,  ...,  9.8438e-02,\n",
       "            1.9278e-01, -2.7462e-02]],\n",
       "\n",
       "         [[-1.8471e-01, -9.4479e-01, -9.4479e-01,  ..., -9.4479e-01,\n",
       "           -9.4479e-01, -4.2860e-01],\n",
       "          [ 2.6012e-01, -2.2509e-01, -2.2509e-01,  ...,  2.2873e+00,\n",
       "            2.2569e+00,  1.7045e+00],\n",
       "          [ 2.6012e-01, -2.2509e-01, -2.2509e-01,  ...,  1.0949e+00,\n",
       "            9.1289e-01,  3.3046e-01],\n",
       "          ...,\n",
       "          [ 2.6012e-01, -2.2509e-01, -2.2509e-01,  ..., -1.7863e-02,\n",
       "           -6.5231e-04, -2.6979e-02],\n",
       "          [ 2.6012e-01, -2.2509e-01, -2.2509e-01,  ...,  8.9192e-02,\n",
       "           -2.4916e-02, -1.0936e-01],\n",
       "          [ 9.0006e-01,  1.3143e+00,  1.3143e+00,  ...,  2.9096e-01,\n",
       "            3.0404e-01,  3.7792e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.9442e-01,  5.3185e-01,  5.3185e-01,  ...,  5.3185e-01,\n",
       "            5.3185e-01,  4.6706e-01],\n",
       "          [-9.7450e-01, -1.4348e-01, -1.4348e-01,  ..., -2.5692e+00,\n",
       "           -2.4786e+00, -1.8044e+00],\n",
       "          [-9.7450e-01, -1.4348e-01, -1.4348e-01,  ..., -5.0398e-01,\n",
       "           -5.9823e-01, -6.3482e-01],\n",
       "          ...,\n",
       "          [-9.7450e-01, -1.4348e-01, -1.4348e-01,  ...,  2.6002e-01,\n",
       "            2.4175e-01,  1.9509e-01],\n",
       "          [-9.7450e-01, -1.4348e-01, -1.4348e-01,  ...,  6.8690e-02,\n",
       "            1.8561e-01,  3.4737e-01],\n",
       "          [-1.9811e+00, -1.5905e+00, -1.5905e+00,  ..., -2.4360e-01,\n",
       "           -3.0925e-01, -2.7597e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[-3.9775e-01, -1.2038e-01, -1.2038e-01,  ..., -1.2038e-01,\n",
       "           -1.2038e-01,  6.9831e-01],\n",
       "          [ 3.5713e-02,  2.8585e-01,  2.8585e-01,  ...,  1.6747e+00,\n",
       "            1.5320e+00,  1.9639e+00],\n",
       "          [ 3.5713e-02,  2.8585e-01,  2.8585e-01,  ...,  2.7033e-01,\n",
       "           -4.7863e-02,  1.6151e-02],\n",
       "          ...,\n",
       "          [ 3.5713e-02,  2.8585e-01,  2.8585e-01,  ..., -1.8497e-01,\n",
       "           -2.1177e-01, -1.2868e-01],\n",
       "          [ 3.5713e-02,  2.8585e-01,  2.8585e-01,  ..., -5.9107e-02,\n",
       "           -9.6385e-02, -1.1561e-01],\n",
       "          [ 6.6195e-01,  1.0009e+00,  1.0009e+00,  ..., -6.9112e-02,\n",
       "           -5.5781e-02,  3.0126e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5234e+00,  5.6652e-01,  8.8394e-01,  ...,  6.9887e-01,\n",
       "            6.9318e-01, -8.2728e-02],\n",
       "          [ 1.3006e+00, -1.0722e-01, -1.1542e+00,  ..., -1.1081e+00,\n",
       "           -1.1752e+00, -7.3005e-01],\n",
       "          [ 1.3006e+00, -1.0722e-01, -1.0058e+00,  ..., -4.6499e-01,\n",
       "           -3.4779e-01, -4.6104e-02],\n",
       "          ...,\n",
       "          [ 1.3006e+00, -1.0722e-01, -8.9646e-01,  ...,  1.8648e-01,\n",
       "            1.7359e-01, -1.3928e-01],\n",
       "          [ 1.3006e+00, -1.0722e-01, -9.1823e-01,  ...,  2.0705e-01,\n",
       "            2.2882e-01, -1.2330e-01],\n",
       "          [ 1.1984e+00,  1.0435e-01, -8.2250e-01,  ...,  6.0869e-02,\n",
       "            1.7745e-01, -1.7145e-01]],\n",
       "\n",
       "         [[-1.8471e-01, -9.4479e-01, -4.5832e-01,  ...,  3.9738e-01,\n",
       "            7.0239e-01,  1.1174e+00],\n",
       "          [ 2.6012e-01, -2.2509e-01,  6.8093e-01,  ...,  7.3165e-01,\n",
       "            7.9735e-01,  2.5403e-01],\n",
       "          [ 2.6012e-01, -2.2509e-01, -1.5983e-01,  ..., -4.7846e-02,\n",
       "           -8.3877e-03,  2.7265e-02],\n",
       "          ...,\n",
       "          [ 2.6012e-01, -2.2509e-01, -1.1993e-01,  ..., -4.9956e-01,\n",
       "           -4.4666e-01, -2.5484e-01],\n",
       "          [ 2.6012e-01, -2.2509e-01, -1.3668e-01,  ..., -5.1214e-01,\n",
       "           -3.8524e-01, -2.2666e-01],\n",
       "          [ 9.0006e-01,  1.3143e+00,  1.0349e+00,  ..., -8.3120e-02,\n",
       "            2.5919e-02,  1.7620e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.9442e-01,  5.3185e-01,  1.6842e-01,  ..., -7.0431e-01,\n",
       "           -1.0376e+00, -1.0165e+00],\n",
       "          [-9.7450e-01, -1.4348e-01, -2.5760e-01,  ..., -2.9303e-01,\n",
       "           -2.7541e-01, -2.9930e-01],\n",
       "          [-9.7450e-01, -1.4348e-01, -1.4997e-02,  ...,  4.3760e-01,\n",
       "            5.1662e-01,  3.7295e-01],\n",
       "          ...,\n",
       "          [-9.7450e-01, -1.4348e-01, -4.1172e-02,  ...,  2.7332e-04,\n",
       "            9.7661e-03, -2.9094e-02],\n",
       "          [-9.7450e-01, -1.4348e-01, -3.0506e-02,  ..., -2.8333e-02,\n",
       "           -9.7296e-02, -8.1300e-02],\n",
       "          [-1.9811e+00, -1.5905e+00, -1.2456e+00,  ..., -2.3771e-01,\n",
       "           -4.3324e-01, -5.0200e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[-3.9775e-01, -1.2038e-01,  1.2250e-01,  ...,  5.8732e-01,\n",
       "            7.7129e-01,  1.4821e+00],\n",
       "          [ 3.5713e-02,  2.8585e-01,  1.6605e+00,  ...,  5.5650e-01,\n",
       "            3.8300e-01,  8.3382e-02],\n",
       "          [ 3.5713e-02,  2.8585e-01,  1.5646e+00,  ..., -3.9097e-02,\n",
       "           -2.1566e-01, -4.2431e-01],\n",
       "          ...,\n",
       "          [ 3.5713e-02,  2.8585e-01,  1.4656e+00,  ..., -1.1778e-02,\n",
       "           -7.6594e-02,  3.1024e-01],\n",
       "          [ 3.5713e-02,  2.8585e-01,  1.4492e+00,  ..., -2.6186e-02,\n",
       "           -1.7360e-02,  3.7120e-01],\n",
       "          [ 6.6195e-01,  1.0009e+00,  1.8375e+00,  ...,  4.1670e-01,\n",
       "            4.0956e-01,  7.4759e-01]]]], device='cuda:0',\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_copy(x)# * model_to_alter.bn1.weight.view(1, -1, 1, 1) + model_to_alter.bn1.bias.view(1, -1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "99d0815d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_copy(x)[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "17b40756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 8.9499e-01,  2.5175e-01,  3.1861e-01,  ..., -4.5013e-01,\n",
       "            6.8268e-01,  1.0177e+00],\n",
       "          [ 6.4967e-01, -1.0747e-01, -5.4609e-02,  ..., -3.3555e-01,\n",
       "            6.2257e-01,  9.4255e-01],\n",
       "          [ 5.6777e-01, -1.9791e-01, -3.3246e-01,  ..., -4.6929e-01,\n",
       "            4.6046e-01,  1.0594e+00],\n",
       "          ...,\n",
       "          [ 6.7263e-01, -9.8308e-02, -8.2093e-02,  ..., -1.0027e-01,\n",
       "            2.2853e-01, -1.8406e-01],\n",
       "          [ 1.4178e+00,  2.5572e-01,  2.7388e-01,  ...,  1.8409e-01,\n",
       "            1.6184e-01, -4.3754e-01],\n",
       "          [ 1.1984e+00,  1.0435e-01,  1.0435e-01,  ...,  1.0435e-01,\n",
       "            1.0435e-01, -6.2749e-01]],\n",
       "\n",
       "         [[-1.1181e-02, -4.5649e-01, -4.3789e-01,  ...,  2.1657e-01,\n",
       "           -2.4214e-01,  4.0662e-01],\n",
       "          [ 3.4580e-01,  1.4527e-01,  2.8037e-01,  ...,  2.3089e-01,\n",
       "            2.3999e-01,  4.6711e-01],\n",
       "          [ 1.9875e-01,  4.8090e-02,  1.5994e-01,  ...,  3.2368e-01,\n",
       "            3.3563e-01,  5.9757e-01],\n",
       "          ...,\n",
       "          [-3.6983e-02, -7.2091e-01, -7.1547e-01,  ..., -7.3086e-01,\n",
       "           -6.2873e-01, -3.3114e-01],\n",
       "          [ 8.1014e-02, -5.2065e-01, -5.3387e-01,  ..., -4.8346e-01,\n",
       "           -3.2141e-01, -2.8970e-01],\n",
       "          [ 9.0007e-01,  1.3144e+00,  1.3144e+00,  ...,  1.3144e+00,\n",
       "            1.3144e+00,  1.0735e+00]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.4641e-02,  4.4716e-01,  5.1029e-01,  ...,  2.7011e-01,\n",
       "            1.0198e-01, -2.4038e-01],\n",
       "          [-6.0645e-01, -2.5007e-02, -1.8364e-01,  ...,  3.7521e-01,\n",
       "           -3.8202e-02, -9.1294e-01],\n",
       "          [-3.9131e-01,  6.1237e-02, -1.2334e-03,  ...,  1.8472e-01,\n",
       "           -1.0113e-01, -1.0239e+00],\n",
       "          ...,\n",
       "          [ 4.0235e-02,  7.5570e-01,  7.4264e-01,  ...,  6.8231e-01,\n",
       "            4.1407e-01, -2.0549e-01],\n",
       "          [-6.4442e-01,  1.5807e-01,  1.4041e-01,  ...,  1.7140e-01,\n",
       "            7.5713e-02, -1.0821e-01],\n",
       "          [-1.9812e+00, -1.5905e+00, -1.5905e+00,  ..., -1.5905e+00,\n",
       "           -1.5905e+00, -1.3037e+00]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[-3.0761e-01, -1.5830e-01, -2.2315e-01,  ..., -9.1574e-02,\n",
       "           -9.3668e-01,  4.2148e-01],\n",
       "          [ 2.8125e-02, -5.2631e-03,  1.4998e-01,  ..., -2.8881e-01,\n",
       "           -1.0156e+00,  8.2268e-01],\n",
       "          [-1.0482e-01, -2.7072e-03,  2.0905e-01,  ..., -8.3581e-03,\n",
       "           -1.0112e+00,  7.9754e-01],\n",
       "          ...,\n",
       "          [-5.3162e-01, -6.1024e-01, -6.0708e-01,  ..., -3.9649e-01,\n",
       "           -5.3408e-01,  9.5700e-01],\n",
       "          [-2.9183e-01, -1.1231e-01, -1.1179e-01,  ...,  1.6273e-02,\n",
       "            7.1193e-02,  1.1183e+00],\n",
       "          [ 6.6196e-01,  1.0009e+00,  1.0009e+00,  ...,  1.0009e+00,\n",
       "            1.0009e+00,  1.7207e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7332e-01,  5.4983e-02,  5.5644e-02,  ...,  1.4765e+00,\n",
       "            5.6652e-01, -2.2754e-02],\n",
       "          [ 1.6550e-01, -4.7605e-02, -2.1789e-02,  ...,  1.2040e+00,\n",
       "           -1.0723e-01, -6.1672e-01],\n",
       "          [ 2.0895e-01, -5.1450e-02, -2.3446e-02,  ...,  1.1563e+00,\n",
       "           -1.0723e-01, -6.1672e-01],\n",
       "          ...,\n",
       "          [-4.8106e-01, -3.1177e-01, -2.8168e-02,  ...,  3.7029e-01,\n",
       "           -1.0723e-01, -6.1672e-01],\n",
       "          [ 5.2743e-01,  4.3840e-01,  5.2214e-01,  ...,  3.8686e-01,\n",
       "           -1.0723e-01, -6.1672e-01],\n",
       "          [ 7.4399e-01,  1.7532e-01,  1.5238e-01,  ...,  4.9823e-01,\n",
       "            1.0435e-01, -6.2749e-01]],\n",
       "\n",
       "         [[-1.0924e-01, -1.6678e-01, -1.5350e-01,  ..., -2.0396e-01,\n",
       "           -9.4481e-01, -4.2861e-01],\n",
       "          [-1.0791e-01, -1.9034e-01, -1.7575e-01,  ...,  2.1289e-01,\n",
       "           -2.2509e-01, -1.8798e-01],\n",
       "          [-1.1428e-01, -2.1066e-01, -2.1427e-01,  ...,  1.8535e-01,\n",
       "           -2.2509e-01, -1.8798e-01],\n",
       "          ...,\n",
       "          [-3.5695e-01, -7.7639e-01, -1.0460e+00,  ...,  7.2382e-03,\n",
       "           -2.2509e-01, -1.8798e-01],\n",
       "          [-3.6555e-01, -8.8608e-01, -6.5864e-01,  ...,  8.8283e-03,\n",
       "           -2.2509e-01, -1.8798e-01],\n",
       "          [ 5.2671e-01,  7.7120e-01,  8.4476e-01,  ...,  1.1863e+00,\n",
       "            1.3144e+00,  1.0735e+00]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.2471e-01,  2.8187e-01,  2.7103e-01,  ..., -1.6361e-01,\n",
       "            5.3185e-01,  4.6707e-01],\n",
       "          [ 2.6281e-01,  3.7564e-01,  3.5032e-01,  ..., -9.1695e-01,\n",
       "           -1.4349e-01, -7.4471e-02],\n",
       "          [ 2.3235e-01,  3.9792e-01,  3.8836e-01,  ..., -8.8521e-01,\n",
       "           -1.4349e-01, -7.4471e-02],\n",
       "          ...,\n",
       "          [ 1.0015e+00,  1.1673e+00,  1.3205e+00,  ..., -3.7831e-01,\n",
       "           -1.4349e-01, -7.4471e-02],\n",
       "          [ 7.4600e-01,  9.4744e-01,  7.3959e-01,  ..., -3.8645e-01,\n",
       "           -1.4349e-01, -7.4471e-02],\n",
       "          [-8.5186e-01, -6.6606e-01, -8.0588e-01,  ..., -1.6924e+00,\n",
       "           -1.5905e+00, -1.3037e+00]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[-3.0990e-01, -3.2709e-01, -3.2600e-01,  ..., -4.4962e-01,\n",
       "           -1.2038e-01,  6.9832e-01],\n",
       "          [-2.5866e-01, -2.5335e-01, -2.5911e-01,  ...,  2.3579e-02,\n",
       "            2.8585e-01,  1.1250e+00],\n",
       "          [-2.5167e-01, -2.5054e-01, -2.6577e-01,  ...,  2.9028e-02,\n",
       "            2.8585e-01,  1.1250e+00],\n",
       "          ...,\n",
       "          [-5.0293e-01, -7.3587e-01, -9.5845e-01,  ...,  1.5196e-01,\n",
       "            2.8585e-01,  1.1250e+00],\n",
       "          [-6.8074e-01, -6.3490e-01, -4.7752e-01,  ...,  1.4409e-01,\n",
       "            2.8585e-01,  1.1250e+00],\n",
       "          [ 1.5940e-01,  3.4384e-01,  4.1751e-01,  ...,  8.3541e-01,\n",
       "            1.0009e+00,  1.7207e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5234e+00,  5.6652e-01, -5.7414e-01,  ..., -6.2477e-01,\n",
       "           -7.4310e-01, -1.4332e-01],\n",
       "          [ 1.3006e+00, -1.0723e-01, -1.2004e+00,  ..., -1.7569e-01,\n",
       "           -2.5467e-01,  3.3795e-01],\n",
       "          [ 1.3006e+00, -1.0723e-01, -1.1258e+00,  ..., -1.4774e-01,\n",
       "           -1.7714e-01,  3.3480e-01],\n",
       "          ...,\n",
       "          [ 1.3006e+00, -1.0723e-01, -6.8635e-01,  ..., -4.7532e-02,\n",
       "           -1.5796e-01, -2.5231e-01],\n",
       "          [ 1.3006e+00, -1.0723e-01, -6.5112e-01,  ..., -1.2464e-01,\n",
       "           -1.8290e-01, -1.9711e-01],\n",
       "          [ 1.1984e+00,  1.0435e-01,  1.7114e-01,  ...,  6.0563e-01,\n",
       "            5.8795e-01, -1.9998e-01]],\n",
       "\n",
       "         [[-1.8471e-01, -9.4481e-01,  9.4286e-02,  ...,  9.9223e-01,\n",
       "            9.7555e-01,  4.5452e-01],\n",
       "          [ 2.6012e-01, -2.2509e-01, -3.2486e-02,  ...,  5.8715e-01,\n",
       "            5.1571e-01,  3.3451e-01],\n",
       "          [ 2.6012e-01, -2.2509e-01, -7.6995e-02,  ...,  6.4469e-01,\n",
       "            6.3557e-01,  4.5624e-01],\n",
       "          ...,\n",
       "          [ 2.6012e-01, -2.2509e-01, -7.2206e-02,  ...,  2.9508e-01,\n",
       "            3.1423e-01,  1.7034e-01],\n",
       "          [ 2.6012e-01, -2.2509e-01, -3.6487e-01,  ..., -7.3419e-01,\n",
       "           -7.4700e-01, -6.3314e-01],\n",
       "          [ 9.0007e-01,  1.3144e+00,  9.8070e-01,  ...,  9.2820e-01,\n",
       "            9.3705e-01,  9.8972e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.9442e-01,  5.3185e-01,  3.5160e-01,  ..., -2.5012e-01,\n",
       "           -2.0497e-01, -8.0426e-02],\n",
       "          [-9.7451e-01, -1.4349e-01, -8.9684e-02,  ...,  1.8371e-01,\n",
       "            3.0529e-01,  4.1076e-01],\n",
       "          [-9.7451e-01, -1.4349e-01, -1.0294e-01,  ...,  1.6030e-01,\n",
       "            2.2059e-01,  3.0742e-01],\n",
       "          ...,\n",
       "          [-9.7451e-01, -1.4349e-01, -2.2923e-01,  ..., -2.1783e-01,\n",
       "           -2.1207e-01,  2.2686e-02],\n",
       "          [-9.7451e-01, -1.4349e-01, -4.2841e-02,  ...,  7.2118e-01,\n",
       "            7.4246e-01,  7.8150e-01],\n",
       "          [-1.9812e+00, -1.5905e+00, -1.5552e+00,  ..., -1.2653e+00,\n",
       "           -1.2536e+00, -9.8823e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[-3.9775e-01, -1.2038e-01,  1.4432e+00,  ...,  2.7450e-01,\n",
       "            2.9020e-01, -5.3257e-01],\n",
       "          [ 3.5713e-02,  2.8585e-01,  1.8917e+00,  ..., -1.9907e-01,\n",
       "           -2.4310e-01, -1.0026e+00],\n",
       "          [ 3.5713e-02,  2.8585e-01,  1.7966e+00,  ..., -2.5012e-01,\n",
       "           -2.7794e-01, -8.8505e-01],\n",
       "          ...,\n",
       "          [ 3.5713e-02,  2.8585e-01,  1.0510e+00,  ...,  1.2204e-01,\n",
       "            2.0438e-01,  3.6331e-01],\n",
       "          [ 3.5713e-02,  2.8585e-01,  7.5811e-01,  ..., -6.1430e-01,\n",
       "           -5.9222e-01, -2.0448e-01],\n",
       "          [ 6.6196e-01,  1.0009e+00,  9.5659e-01,  ...,  5.1560e-01,\n",
       "            5.1204e-01,  1.2769e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 1.5234e+00,  5.6652e-01,  5.6652e-01,  ...,  5.6652e-01,\n",
       "            5.6652e-01, -2.2754e-02],\n",
       "          [ 1.3006e+00, -1.0723e-01, -1.0723e-01,  ...,  2.7050e-01,\n",
       "            2.7689e-01, -6.5845e-01],\n",
       "          [ 1.3006e+00, -1.0723e-01, -1.0723e-01,  ..., -1.4510e+00,\n",
       "           -1.4356e+00, -6.3088e-01],\n",
       "          ...,\n",
       "          [ 1.3006e+00, -1.0723e-01, -1.0723e-01,  ..., -1.4811e-01,\n",
       "            1.1745e+00,  4.9839e-01],\n",
       "          [ 1.3006e+00, -1.0723e-01, -1.0723e-01,  ...,  2.2628e-02,\n",
       "            1.1558e+00,  3.6864e-01],\n",
       "          [ 1.1984e+00,  1.0435e-01,  1.0435e-01,  ..., -2.9759e-01,\n",
       "           -2.2360e-01,  1.5756e-01]],\n",
       "\n",
       "         [[-1.8471e-01, -9.4481e-01, -9.4481e-01,  ..., -9.4481e-01,\n",
       "           -9.4481e-01, -4.2861e-01],\n",
       "          [ 2.6012e-01, -2.2509e-01, -2.2509e-01,  ...,  3.0394e+00,\n",
       "            3.0465e+00,  2.4758e+00],\n",
       "          [ 2.6012e-01, -2.2509e-01, -2.2509e-01,  ...,  1.9104e+00,\n",
       "            1.9254e+00,  7.9573e-01],\n",
       "          ...,\n",
       "          [ 2.6012e-01, -2.2509e-01, -2.2509e-01,  ...,  5.1525e-01,\n",
       "            7.5908e-01,  5.8986e-01],\n",
       "          [ 2.6012e-01, -2.2509e-01, -2.2509e-01,  ...,  9.8064e-01,\n",
       "            1.2684e+00,  1.4200e+00],\n",
       "          [ 9.0007e-01,  1.3144e+00,  1.3144e+00,  ..., -6.8804e-01,\n",
       "           -4.4698e-01, -6.9017e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.9442e-01,  5.3185e-01,  5.3185e-01,  ...,  5.3185e-01,\n",
       "            5.3185e-01,  4.6707e-01],\n",
       "          [-9.7451e-01, -1.4349e-01, -1.4349e-01,  ..., -3.2040e+00,\n",
       "           -3.2201e+00, -2.6764e+00],\n",
       "          [-9.7451e-01, -1.4349e-01, -1.4349e-01,  ..., -1.1337e+00,\n",
       "           -1.1269e+00, -8.5858e-01],\n",
       "          ...,\n",
       "          [-9.7451e-01, -1.4349e-01, -1.4349e-01,  ..., -3.2290e-01,\n",
       "           -1.1761e+00, -9.7641e-01],\n",
       "          [-9.7451e-01, -1.4349e-01, -1.4349e-01,  ..., -2.3893e-01,\n",
       "           -1.6319e+00, -2.1213e+00],\n",
       "          [-1.9812e+00, -1.5905e+00, -1.5905e+00,  ...,  1.4264e+00,\n",
       "            8.9009e-01,  3.5035e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[-3.9775e-01, -1.2038e-01, -1.2038e-01,  ..., -1.2038e-01,\n",
       "           -1.2038e-01,  6.9832e-01],\n",
       "          [ 3.5713e-02,  2.8585e-01,  2.8585e-01,  ...,  1.9494e+00,\n",
       "            1.9493e+00,  2.4791e+00],\n",
       "          [ 3.5713e-02,  2.8585e-01,  2.8585e-01,  ...,  5.3233e-01,\n",
       "            5.2553e-01, -4.3846e-01],\n",
       "          ...,\n",
       "          [ 3.5713e-02,  2.8585e-01,  2.8585e-01,  ..., -2.6771e-01,\n",
       "           -3.3166e-01,  8.9202e-01],\n",
       "          [ 3.5713e-02,  2.8585e-01,  2.8585e-01,  ..., -4.1649e-01,\n",
       "           -9.7650e-02,  1.2527e+00],\n",
       "          [ 6.6196e-01,  1.0009e+00,  1.0009e+00,  ..., -1.1727e+00,\n",
       "           -9.4083e-01, -1.0316e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5234e+00,  5.6652e-01,  5.6652e-01,  ...,  5.6652e-01,\n",
       "            5.6652e-01, -2.2754e-02],\n",
       "          [ 1.3006e+00, -1.0723e-01, -1.0723e-01,  ...,  1.1818e-01,\n",
       "            1.8309e-01, -5.0955e-01],\n",
       "          [ 1.3006e+00, -1.0723e-01, -1.0723e-01,  ..., -1.2974e+00,\n",
       "           -7.4591e-01, -3.1230e-01],\n",
       "          ...,\n",
       "          [ 1.3006e+00, -1.0723e-01, -1.0723e-01,  ..., -1.2080e-01,\n",
       "           -5.1826e-02, -1.6951e-02],\n",
       "          [ 1.3006e+00, -1.0723e-01, -1.0723e-01,  ..., -3.6435e-02,\n",
       "           -6.4143e-02, -3.9787e-02],\n",
       "          [ 1.1984e+00,  1.0435e-01,  1.0435e-01,  ...,  9.8439e-02,\n",
       "            1.9279e-01, -2.7462e-02]],\n",
       "\n",
       "         [[-1.8471e-01, -9.4481e-01, -9.4481e-01,  ..., -9.4481e-01,\n",
       "           -9.4481e-01, -4.2861e-01],\n",
       "          [ 2.6012e-01, -2.2509e-01, -2.2509e-01,  ...,  2.2874e+00,\n",
       "            2.2570e+00,  1.7045e+00],\n",
       "          [ 2.6012e-01, -2.2509e-01, -2.2509e-01,  ...,  1.0950e+00,\n",
       "            9.1291e-01,  3.3046e-01],\n",
       "          ...,\n",
       "          [ 2.6012e-01, -2.2509e-01, -2.2509e-01,  ..., -1.7864e-02,\n",
       "           -6.5232e-04, -2.6979e-02],\n",
       "          [ 2.6012e-01, -2.2509e-01, -2.2509e-01,  ...,  8.9193e-02,\n",
       "           -2.4916e-02, -1.0937e-01],\n",
       "          [ 9.0007e-01,  1.3144e+00,  1.3144e+00,  ...,  2.9097e-01,\n",
       "            3.0405e-01,  3.7793e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.9442e-01,  5.3185e-01,  5.3185e-01,  ...,  5.3185e-01,\n",
       "            5.3185e-01,  4.6707e-01],\n",
       "          [-9.7451e-01, -1.4349e-01, -1.4349e-01,  ..., -2.5692e+00,\n",
       "           -2.4786e+00, -1.8045e+00],\n",
       "          [-9.7451e-01, -1.4349e-01, -1.4349e-01,  ..., -5.0399e-01,\n",
       "           -5.9824e-01, -6.3483e-01],\n",
       "          ...,\n",
       "          [-9.7451e-01, -1.4349e-01, -1.4349e-01,  ...,  2.6003e-01,\n",
       "            2.4175e-01,  1.9509e-01],\n",
       "          [-9.7451e-01, -1.4349e-01, -1.4349e-01,  ...,  6.8691e-02,\n",
       "            1.8562e-01,  3.4738e-01],\n",
       "          [-1.9812e+00, -1.5905e+00, -1.5905e+00,  ..., -2.4360e-01,\n",
       "           -3.0926e-01, -2.7597e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[-3.9775e-01, -1.2038e-01, -1.2038e-01,  ..., -1.2038e-01,\n",
       "           -1.2038e-01,  6.9832e-01],\n",
       "          [ 3.5713e-02,  2.8585e-01,  2.8585e-01,  ...,  1.6747e+00,\n",
       "            1.5320e+00,  1.9639e+00],\n",
       "          [ 3.5713e-02,  2.8585e-01,  2.8585e-01,  ...,  2.7033e-01,\n",
       "           -4.7863e-02,  1.6151e-02],\n",
       "          ...,\n",
       "          [ 3.5713e-02,  2.8585e-01,  2.8585e-01,  ..., -1.8497e-01,\n",
       "           -2.1177e-01, -1.2868e-01],\n",
       "          [ 3.5713e-02,  2.8585e-01,  2.8585e-01,  ..., -5.9107e-02,\n",
       "           -9.6386e-02, -1.1561e-01],\n",
       "          [ 6.6196e-01,  1.0009e+00,  1.0009e+00,  ..., -6.9112e-02,\n",
       "           -5.5781e-02,  3.0126e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5234e+00,  5.6652e-01,  8.8394e-01,  ...,  6.9888e-01,\n",
       "            6.9319e-01, -8.2729e-02],\n",
       "          [ 1.3006e+00, -1.0723e-01, -1.1542e+00,  ..., -1.1081e+00,\n",
       "           -1.1752e+00, -7.3006e-01],\n",
       "          [ 1.3006e+00, -1.0723e-01, -1.0058e+00,  ..., -4.6499e-01,\n",
       "           -3.4780e-01, -4.6104e-02],\n",
       "          ...,\n",
       "          [ 1.3006e+00, -1.0723e-01, -8.9647e-01,  ...,  1.8648e-01,\n",
       "            1.7359e-01, -1.3928e-01],\n",
       "          [ 1.3006e+00, -1.0723e-01, -9.1824e-01,  ...,  2.0705e-01,\n",
       "            2.2882e-01, -1.2330e-01],\n",
       "          [ 1.1984e+00,  1.0435e-01, -8.2251e-01,  ...,  6.0870e-02,\n",
       "            1.7746e-01, -1.7145e-01]],\n",
       "\n",
       "         [[-1.8471e-01, -9.4481e-01, -4.5832e-01,  ...,  3.9739e-01,\n",
       "            7.0240e-01,  1.1174e+00],\n",
       "          [ 2.6012e-01, -2.2509e-01,  6.8094e-01,  ...,  7.3166e-01,\n",
       "            7.9736e-01,  2.5403e-01],\n",
       "          [ 2.6012e-01, -2.2509e-01, -1.5984e-01,  ..., -4.7847e-02,\n",
       "           -8.3878e-03,  2.7265e-02],\n",
       "          ...,\n",
       "          [ 2.6012e-01, -2.2509e-01, -1.1994e-01,  ..., -4.9957e-01,\n",
       "           -4.4667e-01, -2.5484e-01],\n",
       "          [ 2.6012e-01, -2.2509e-01, -1.3668e-01,  ..., -5.1215e-01,\n",
       "           -3.8525e-01, -2.2666e-01],\n",
       "          [ 9.0007e-01,  1.3144e+00,  1.0349e+00,  ..., -8.3121e-02,\n",
       "            2.5919e-02,  1.7621e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.9442e-01,  5.3185e-01,  1.6842e-01,  ..., -7.0432e-01,\n",
       "           -1.0376e+00, -1.0165e+00],\n",
       "          [-9.7451e-01, -1.4349e-01, -2.5760e-01,  ..., -2.9304e-01,\n",
       "           -2.7541e-01, -2.9931e-01],\n",
       "          [-9.7451e-01, -1.4349e-01, -1.4997e-02,  ...,  4.3760e-01,\n",
       "            5.1663e-01,  3.7296e-01],\n",
       "          ...,\n",
       "          [-9.7451e-01, -1.4349e-01, -4.1172e-02,  ...,  2.7333e-04,\n",
       "            9.7662e-03, -2.9095e-02],\n",
       "          [-9.7451e-01, -1.4349e-01, -3.0507e-02,  ..., -2.8334e-02,\n",
       "           -9.7298e-02, -8.1301e-02],\n",
       "          [-1.9812e+00, -1.5905e+00, -1.2456e+00,  ..., -2.3771e-01,\n",
       "           -4.3325e-01, -5.0201e-01]],\n",
       "\n",
       "         [[        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          ...,\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan],\n",
       "          [        nan,         nan,         nan,  ...,         nan,\n",
       "                   nan,         nan]],\n",
       "\n",
       "         [[-3.9775e-01, -1.2038e-01,  1.2250e-01,  ...,  5.8732e-01,\n",
       "            7.7129e-01,  1.4821e+00],\n",
       "          [ 3.5713e-02,  2.8585e-01,  1.6605e+00,  ...,  5.5651e-01,\n",
       "            3.8300e-01,  8.3383e-02],\n",
       "          [ 3.5713e-02,  2.8585e-01,  1.5646e+00,  ..., -3.9097e-02,\n",
       "           -2.1566e-01, -4.2431e-01],\n",
       "          ...,\n",
       "          [ 3.5713e-02,  2.8585e-01,  1.4656e+00,  ..., -1.1778e-02,\n",
       "           -7.6595e-02,  3.1024e-01],\n",
       "          [ 3.5713e-02,  2.8585e-01,  1.4492e+00,  ..., -2.6186e-02,\n",
       "           -1.7360e-02,  3.7120e-01],\n",
       "          [ 6.6196e-01,  1.0009e+00,  1.8375e+00,  ...,  4.1671e-01,\n",
       "            4.0956e-01,  7.4759e-01]]]], device='cuda:0',\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x - model_to_alter.bn1.running_mean.view(1, -1, 1, 1)) / torch.sqrt(model_to_alter.bn1.running_var.view(1, -1, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d578b121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7878, 0.5915,    nan, 0.5153, 0.2243, 0.5003,    nan, 0.6875, 0.2514,\n",
       "           nan,    nan, 0.2534, 0.2961, 0.5223,    nan, 0.3742, 0.6260, 0.7184,\n",
       "        0.8876, 0.4244, 0.2122, 0.6230, 0.5964, 0.3609,    nan, 0.8267, 0.6419,\n",
       "        0.5706, 0.7102, 0.8992, 0.9648, 0.6793, 0.4761,    nan, 0.6731,    nan,\n",
       "        0.0813,    nan, 0.6199, 0.4215, 0.8196, 0.6250, 0.5971, 0.1250, 0.6889,\n",
       "        0.4163,    nan, 0.4448,    nan, 0.5916,    nan,    nan, 1.0331, 0.8994,\n",
       "           nan,    nan, 0.9964, 0.7899,    nan, 1.3990, 0.4436, 0.5711,    nan,\n",
       "        0.9437], device='cuda:0')"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(model_to_alter.bn1.running_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "8d3a95e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0607, device='cuda:0')"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_alter.bn1.running_var[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "63c22315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6596, device='cuda:0')"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.bn1.running_var[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2044b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca4240a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000341c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d011ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9565195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0859b2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:06<00:00, 14.47it/s]\n",
      "100%|| 100/100 [00:08<00:00, 11.30it/s]\n",
      "100%|| 100/100 [00:10<00:00,  9.69it/s]\n",
      "100%|| 100/100 [00:04<00:00, 23.38it/s]\n",
      "100%|| 100/100 [00:05<00:00, 18.30it/s]\n",
      "100%|| 100/100 [00:06<00:00, 15.55it/s]\n",
      "100%|| 100/100 [00:07<00:00, 14.16it/s]\n",
      "100%|| 100/100 [00:07<00:00, 12.78it/s]\n",
      "100%|| 100/100 [00:08<00:00, 11.86it/s]\n",
      "100%|| 100/100 [00:08<00:00, 11.33it/s]\n",
      "100%|| 100/100 [00:09<00:00, 10.36it/s]\n",
      "100%|| 100/100 [00:10<00:00, 10.00it/s]\n"
     ]
    }
   ],
   "source": [
    "model_to_alter, module2io = transform_model(\n",
    "    model0, \n",
    "    model1, \n",
    "    model_to_alter, \n",
    "    transform_fn=get_layer_procrustes, \n",
    "    prune_threshold=-torch.inf, \n",
    "    module2io=module2io\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "dfe4a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model_to_alter, f'resnet20x4_CIFAR5_procrustes_{prune_threshold}threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "40475731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-reset:\n",
      "0.1\n",
      "Post-reset:\n",
      "0.3749\n"
     ]
    }
   ],
   "source": [
    "avg_model = resnet20(w=4).to(DEVICE)\n",
    "\n",
    "mix_weights(\n",
    "    avg_model, \n",
    "    .5, \n",
    "    f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}',\n",
    "    f'resnet20x4_CIFAR5_procrustes_{prune_threshold}threshold'\n",
    ")\n",
    "\n",
    "print('Pre-reset:')\n",
    "print(\n",
    "    evaluate(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ")\n",
    "reset_bn_stats(avg_model)\n",
    "print('Post-reset:')\n",
    "print(\n",
    "    evaluate(\n",
    "        avg_model, \n",
    "        test_loader, \n",
    "        class_vectors=text_features\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4182c8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
