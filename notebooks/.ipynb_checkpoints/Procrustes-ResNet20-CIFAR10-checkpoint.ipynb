{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0337890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "from sys import platform\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam, lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "if platform == 'darwin':\n",
    "    DEVICE = 'mps'\n",
    "else:\n",
    "    DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52314adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CIFAR_MEAN = [125.307, 122.961, 113.8575]\n",
    "CIFAR_STD = [51.5865, 50.847, 51.255]\n",
    "normalize = T.Normalize(np.array(CIFAR_MEAN)/255, np.array(CIFAR_STD)/255)\n",
    "denormalize = T.Normalize(-np.array(CIFAR_MEAN)/np.array(CIFAR_STD), 255/np.array(CIFAR_STD))\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "train_dset = torchvision.datasets.CIFAR10(root='/tmp', train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "test_dset = torchvision.datasets.CIFAR10(root='/tmp', train=False,\n",
    "                                        download=True, transform=test_transform)\n",
    "\n",
    "train_aug_loader = torch.utils.data.DataLoader(train_dset, batch_size=500, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=500, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9403e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates accuracy\n",
    "def evaluate(model, loader=test_loader, on_mac=False):\n",
    "    device = 'mps' if on_mac else 'cuda'\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs.to(device))\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            correct += (labels.to(device) == pred).sum().item()\n",
    "    return correct\n",
    "\n",
    "# evaluates loss\n",
    "def evaluate1(model, loader=test_loader, on_mac=False):\n",
    "    device = 'mps' if on_mac else 'cuda'\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs.to(device))\n",
    "            loss = F.cross_entropy(outputs, labels.to(device))\n",
    "            losses.append(loss.item())\n",
    "    return np.array(losses).mean()\n",
    "\n",
    "def train(save_key, on_mac=False):\n",
    "    device = 'mps' if on_mac else 'cuda'\n",
    "    model = resnet20(w=4).to(device)\n",
    "    optimizer = SGD(model.parameters(), lr=0.4, momentum=0.9, weight_decay=5e-4)\n",
    "    # optimizer = Adam(model.parameters(), lr=0.05)\n",
    "    \n",
    "    # Adam seems to perform worse than SGD for training ResNets on CIFAR-10.\n",
    "    # To make Adam work, we find that we need a very high learning rate: 0.05 (50x the default)\n",
    "    # At this LR, Adam gives 1.0-1.5% worse accuracy than SGD.\n",
    "    \n",
    "    # It is not yet clear whether the increased interpolation barrier for Adam-trained networks\n",
    "    # is simply due to the increased test loss of said networks relative to those trained with SGD.\n",
    "    # We include the option of using Adam in this notebook to explore this question.\n",
    "\n",
    "    EPOCHS = 100\n",
    "    ne_iters = len(train_aug_loader)\n",
    "    lr_schedule = np.interp(np.arange(1+EPOCHS*ne_iters), [0, 5*ne_iters, EPOCHS*ne_iters], [0, 1, 0])\n",
    "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_schedule.__getitem__)\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    \n",
    "    losses = []\n",
    "    for _ in tqdm(range(EPOCHS)):\n",
    "        for i, (inputs, labels) in enumerate(train_aug_loader):\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with autocast():\n",
    "                outputs = model(inputs.to(device))\n",
    "                loss = loss_fn(outputs, labels.to(device))\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            losses.append(loss.item())\n",
    "    print(evaluate(model))\n",
    "    save_model(model, save_key)\n",
    "    \n",
    "# given two networks net0, net1 which each output a feature map of shape NxCxWxH\n",
    "# this will reshape both outputs to (N*W*H)xC\n",
    "# and then compute a CxC correlation matrix between the outputs of the two networks\n",
    "def run_corr_matrix(net0, net1, epochs=1, norm=True, loader=train_aug_loader, on_mac=False):\n",
    "    device = 'mps' if on_mac else 'cuda'\n",
    "    n = epochs*len(loader)\n",
    "    mean0 = mean1 = std0 = std1 = None\n",
    "    with torch.no_grad():\n",
    "        net0.eval()\n",
    "        net1.eval()\n",
    "        for _ in range(epochs):\n",
    "            for i, (images, _) in enumerate(tqdm(loader)):\n",
    "                img_t = images.float().to(device)\n",
    "                out0 = net0(img_t)\n",
    "                out0 = out0.reshape(out0.shape[0], out0.shape[1], -1).permute(0, 2, 1)\n",
    "                out0 = out0.reshape(-1, out0.shape[2])#.double()\n",
    "\n",
    "                out1 = net1(img_t)\n",
    "                out1 = out1.reshape(out1.shape[0], out1.shape[1], -1).permute(0, 2, 1)\n",
    "                out1 = out1.reshape(-1, out1.shape[2])#.double()\n",
    "\n",
    "                mean0_b = out0.mean(dim=0)\n",
    "                mean1_b = out1.mean(dim=0)\n",
    "                std0_b = out0.std(dim=0)\n",
    "                std1_b = out1.std(dim=0)\n",
    "                outer_b = (out0.T @ out1) / out0.shape[0]\n",
    "\n",
    "                if i == 0:\n",
    "                    mean0 = torch.zeros_like(mean0_b)\n",
    "                    mean1 = torch.zeros_like(mean1_b)\n",
    "                    std0 = torch.zeros_like(std0_b)\n",
    "                    std1 = torch.zeros_like(std1_b)\n",
    "                    outer = torch.zeros_like(outer_b)\n",
    "                mean0 += mean0_b / n\n",
    "                mean1 += mean1_b / n\n",
    "                std0 += std0_b / n\n",
    "                std1 += std1_b / n\n",
    "                outer += outer_b / n\n",
    "\n",
    "    cov = outer - torch.outer(mean0, mean1)\n",
    "    if norm:\n",
    "        corr = cov / (torch.outer(std0, std1) + 1e-4)\n",
    "        return corr\n",
    "    else:\n",
    "        return cov\n",
    "\n",
    "def compute_perm_map(corr_mtx):\n",
    "    # sort the (i, j) channel pairs by correlation\n",
    "    nchan = corr_mtx.shape[0]\n",
    "    triples = [(i, j, corr_mtx[i, j].item()) for i in range(nchan) for j in range(nchan)]\n",
    "    triples = sorted(triples, key=lambda p: -p[2])\n",
    "    # greedily find a matching\n",
    "    perm_d = {}\n",
    "    for i, j, c in triples:\n",
    "        if not (i in perm_d.keys() or j in perm_d.values()):\n",
    "            perm_d[i] = j\n",
    "    perm_map = torch.tensor([perm_d[i] for i in range(nchan)])\n",
    "\n",
    "    # qual_map will be a permutation of the indices in the order\n",
    "    # of the quality / degree of correlation between the neurons found in the permutation.\n",
    "    # this just for visualization purposes.\n",
    "    qual_l = [corr_mtx[i, perm_map[i]].item() for i in range(nchan)]\n",
    "    qual_map = torch.tensor(sorted(range(nchan), key=lambda i: -qual_l[i]))\n",
    "\n",
    "    return perm_map, qual_map\n",
    "\n",
    "def get_layer_perm1(corr_mtx, method='max_weight', vizz=False, prune_threshold=-torch.inf):\n",
    "    if method == 'greedy':\n",
    "        perm_map, qual_map = compute_perm_map(corr_mtx)\n",
    "        if vizz:\n",
    "            corr_mtx_viz = (corr_mtx[qual_map].T[perm_map[qual_map]]).T\n",
    "            viz(corr_mtx_viz)\n",
    "    elif method == 'max_weight':\n",
    "        corr_mtx_a = corr_mtx.cpu().numpy()\n",
    "        row_ind, col_ind = scipy.optimize.linear_sum_assignment(corr_mtx_a, maximize=True)\n",
    "        assert (row_ind == np.arange(len(corr_mtx_a))).all()\n",
    "        perm_map = torch.tensor(col_ind).long()\n",
    "        perm_map = torch.eye(corr_mtx.shape[0], device=corr_mtx.device)[perm_map]\n",
    "    else:\n",
    "        raise Exception('Unknown method: %s' % method)\n",
    "    \n",
    "#     pdb.set_trace()\n",
    "    pruned_elements = torch.from_numpy(\n",
    "        corr_mtx_a[row_ind, col_ind] >= prune_threshold\n",
    "    ).to(perm_map.device).to(torch.float32)\n",
    "    return perm_map, pruned_elements\n",
    "\n",
    "# returns the channel-permutation to make layer1's activations most closely\n",
    "# match layer0's.\n",
    "def get_layer_perm(net0, net1, method='max_weight', vizz=False, prune_threshold=-torch.inf):\n",
    "    corr_mtx = run_corr_matrix(net0, net1)\n",
    "    return get_layer_perm1(corr_mtx, method, vizz, prune_threshold)\n",
    "\n",
    "# modifies the weight matrices of a convolution and batchnorm\n",
    "# layer given a permutation of the output channels\n",
    "def permute_output(perm_map, conv, bn):\n",
    "    pre_weights = [\n",
    "        conv.weight,\n",
    "        bn.weight,\n",
    "        bn.bias,\n",
    "        bn.running_mean,\n",
    "        bn.running_var,\n",
    "    ]\n",
    "    for w in pre_weights:\n",
    "        if len(w.shape) == 4:\n",
    "            transform = torch.einsum('ab,bcde->acde', perm_map, w)\n",
    "        elif len(w.shape) == 2:\n",
    "            transform = perm_map @ w\n",
    "        else:\n",
    "            transform = w @ perm_map.t()\n",
    "#         assert torch.allclose(w[perm_map.argmax(-1)], transform)\n",
    "        w.data = transform\n",
    "#         w.data = w[perm_map]\n",
    "\n",
    "# modifies the weight matrix of a convolution layer for a given\n",
    "# permutation of the input channels\n",
    "def permute_input(perm_map, after_convs):\n",
    "    if not isinstance(after_convs, list):\n",
    "        after_convs = [after_convs]\n",
    "    post_weights = [c.weight for c in after_convs]\n",
    "    for w in post_weights:\n",
    "        if len(w.shape) == 4:\n",
    "            transform = torch.einsum('abcd,be->aecd', w, perm_map.t())\n",
    "        elif len(w.shape) == 2:\n",
    "            transform = w @ perm_map.t()\n",
    "    #     assert torch.allclose(w[:, perm_map.argmax(-1)], transform)\n",
    "        w.data = transform\n",
    "#         w.data = w[:, perm_map, :, :]\n",
    "\n",
    "def permute_cls_output(perm_map, linear):\n",
    "    for w in [linear.weight, linear.bias]:\n",
    "        w.data = perm_map @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81113cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, i):\n",
    "    sd = model.state_dict()\n",
    "    path = os.path.join(\n",
    "        # '/Users/georgestoica/Downloads',\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def load_model(model, i):\n",
    "    path = os.path.join(\n",
    "        # '/Users/georgestoica/Downloads',\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    map_location = torch.device('mps') if on_mac else torch.device('cuda')\n",
    "    sd = torch.load(path, map_location=map_location)\n",
    "    model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd8c3f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "#             self.shortcut = LambdaLayer(lambda x:\n",
    "#                                         F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, w=1, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = w*16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, w*16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(w*16)\n",
    "        self.layer1 = self._make_layer(block, w*16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, w*32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, w*64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(w*64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def resnet20(w=1):\n",
    "    return ResNet(BasicBlock, [3, 3, 3], w=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11f26804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2867b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def specify_device():\n",
    "    if platform != 'darwin':\n",
    "        return 'cuda'\n",
    "    else:\n",
    "        return 'mps'\n",
    "\n",
    "# use the train loader with data augmentation as this gives better results\n",
    "def reset_bn_stats(model, epochs=1, loader=train_aug_loader):\n",
    "    # resetting stats to baseline first as below is necessary for stability\n",
    "    for m in model.modules():\n",
    "        if type(m) == nn.BatchNorm2d:\n",
    "            m.momentum = None # use simple average\n",
    "            m.reset_running_stats()\n",
    "    # run a single train epoch with augmentations to recalc stats\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        with torch.no_grad(), autocast():\n",
    "            for images, _ in loader:\n",
    "                output = model(images.to(DEVICE))\n",
    "\n",
    "def strip_param_suffix(name):\n",
    "    return name.replace('.weight', '').replace('.bias', '')\n",
    "\n",
    "def combine_io_masks(io, param):\n",
    "    mask = torch.zeros_like(param, device=param.device)\n",
    "    try:\n",
    "        if 'output' in io:\n",
    "            mask[io['output'].view(-1) == 0] = 1.\n",
    "        if 'input' in io and len(mask.shape) > 1:\n",
    "            mask[:, io['input'].view(-1) == 0] = 1.\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "    return mask\n",
    "\n",
    "def mix_weights(model, alpha, model0, model1, whitelisted_params=None):\n",
    "    sd0 = model0.state_dict()\n",
    "    sd1 = model1.state_dict()\n",
    "    sd_alpha = {}\n",
    "    for k in sd0.keys():\n",
    "        param0 = sd0[k].to(DEVICE)\n",
    "        param1 = sd1[k].to(DEVICE)\n",
    "        \n",
    "        if whitelisted_params is not None and strip_param_suffix(k) not in whitelisted_params:\n",
    "            sd_alpha[k] = param0\n",
    "            continue\n",
    "        print(k)\n",
    "        sd_alpha[k] = (1 - alpha) * param0 + alpha * param1\n",
    "        \n",
    "    model.load_state_dict(sd_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9d99f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_procrustes(corr_mtx):\n",
    "    U, _, Vh = torch.linalg.svd(corr_mtx)\n",
    "    return U @ Vh\n",
    "\n",
    "# returns the channel-permutation to make layer1's activations most closely\n",
    "# match layer0's.\n",
    "def get_layer_procrustes(pairs):\n",
    "    objective = None\n",
    "    for pair in pairs:\n",
    "#         pdb.set_trace()\n",
    "        pair_obj = pair[0] @ pair[1].t()\n",
    "        objective = objective + pair_obj if objective is not None else pair_obj\n",
    "    return get_procrustes(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "102fa563",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_input_conv = lambda conv: conv.weight.permute(1, 0, 2, 3).flatten(1)\n",
    "prep_output_conv = lambda conv: conv.weight.flatten(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "48b16cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = resnet20(w=4).to(device)\n",
    "model1 = resnet20(w=4).to(device)\n",
    "load_model(model0, 'resnet20x4_v5')\n",
    "load_model(model1, 'resnet20x4_v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4336656d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95.38, 95.31)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model0)/100, evaluate(model1)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75031415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12a532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f43a2548",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_procrustes = get_layer_procrustes(\n",
    "    [\n",
    "        # Affected Outputs\n",
    "        (\n",
    "            prep_output_conv(model0.conv1), \n",
    "            prep_output_conv(model1.conv1)\n",
    "        ),\n",
    "        (\n",
    "            prep_output_conv(model0.layer1[0].conv2),\n",
    "            prep_output_conv(model1.layer1[0].conv2),\n",
    "        ),\n",
    "        (\n",
    "            prep_output_conv(model0.layer1[1].conv2),\n",
    "            prep_output_conv(model1.layer1[1].conv2),\n",
    "        ),\n",
    "        (\n",
    "            prep_output_conv(model0.layer1[2].conv2),\n",
    "            prep_output_conv(model1.layer1[2].conv2),\n",
    "        ),\n",
    "        # Affected Inputs\n",
    "        (\n",
    "            prep_input_conv(model0.layer1[0].conv1), \n",
    "            prep_input_conv(model1.layer1[0].conv1)\n",
    "        ),\n",
    "        (\n",
    "            prep_input_conv(model0.layer1[1].conv1), \n",
    "            prep_input_conv(model1.layer1[1].conv1)\n",
    "        ),\n",
    "        (\n",
    "            prep_input_conv(model0.layer2[0].conv1), \n",
    "            prep_input_conv(model1.layer2[0].conv1)\n",
    "        ),\n",
    "        (\n",
    "            prep_input_conv(model0.layer2[0].shortcut[0]), \n",
    "            prep_input_conv(model1.layer2[0].shortcut[0])\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f2a4e4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.6174e-01, -1.9765e-03,  2.5963e-05,  5.7304e-02, -3.6224e-03,\n",
       "        -8.9071e-03,  2.1652e-01,  1.6306e-04,  5.0346e-03,  5.2636e-03,\n",
       "        -2.2815e-02, -4.4389e-02, -2.7383e-03,  9.9388e-03,  9.3380e-02,\n",
       "         3.8725e-03,  9.8015e-02, -1.9425e-01,  1.6853e-04,  2.9632e-03,\n",
       "        -8.8523e-04,  3.5012e-03, -2.7835e-02,  3.1955e-03,  3.5616e-02,\n",
       "        -2.2257e-02, -4.1228e-03, -3.0342e-02, -5.7705e-03, -1.5230e-01,\n",
       "        -5.0918e-02, -3.3739e-02,  1.2735e-02, -9.4574e-02, -1.1087e-02,\n",
       "         1.5460e-04,  5.5336e-03, -1.9358e-02, -1.8505e-01, -4.8186e-02,\n",
       "         2.1734e-02, -8.1023e-03,  8.4788e-01,  9.0214e-03,  1.1792e-02,\n",
       "        -6.9269e-03,  1.0127e-02,  2.8304e-03,  1.1876e-01,  1.0427e-01,\n",
       "         3.3406e-03, -2.0387e-02,  1.1719e-02,  3.4824e-03, -3.6582e-03,\n",
       "        -2.6726e-04, -3.2073e-04, -5.9925e-03,  6.5378e-03, -1.0761e-02,\n",
       "         1.3576e-02,  5.6282e-03,  5.6817e-03,  5.4326e-03], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_procrustes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "fd2dd5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "permute_output(conv1_procrustes, model1.conv1, model1.bn1)\n",
    "permute_output(conv1_procrustes, model1.layer1[0].conv2, model1.layer1[0].bn2)\n",
    "permute_output(conv1_procrustes, model1.layer1[1].conv2, model1.layer1[1].bn2)\n",
    "permute_output(conv1_procrustes, model1.layer1[2].conv2, model1.layer1[2].bn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "16fbc1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "permute_input(conv1_procrustes, [model1.layer1[0].conv1, model1.layer1[1].conv1, model1.layer1[2].conv1])\n",
    "permute_input(conv1_procrustes, [model1.layer2[0].conv1, model1.layer2[0].shortcut[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3e545cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_conv1_procrustes = get_layer_procrustes(\n",
    "    [\n",
    "        (\n",
    "            prep_output_conv(model0.layer1[0].conv1), \n",
    "            prep_output_conv(model1.layer1[0].conv1)\n",
    "        ),\n",
    "        (\n",
    "            prep_input_conv(model0.layer1[0].conv2),\n",
    "            prep_input_conv(model0.layer1[0].conv2)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "permute_output(layer1_conv1_procrustes, model1.layer1[0].conv1, model1.layer1[0].bn1)\n",
    "permute_input(layer1_conv1_procrustes, [model1.layer1[0].conv2, model1.layer1[0].bn2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d9d4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16d3311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76d3fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cab1dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef9066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "93bcdd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.conv2.weight\n",
      "Pre-reset:\n",
      "Accuracy=89.36%, Loss=0.408\n",
      "Post-reset:\n",
      "Accuracy=94.69%, Loss=0.192\n"
     ]
    }
   ],
   "source": [
    "model_a = resnet20(w=4).to(device) # W_alpha\n",
    "mix_weights(\n",
    "    model_a, \n",
    "    0.5, \n",
    "    model0,\n",
    "    model1,\n",
    "    whitelisted_params=['conv1', 'layer1.0.conv1', 'layer1.0.conv2']\n",
    ")\n",
    "\n",
    "print('Pre-reset:')\n",
    "print('Accuracy=%.2f%%, Loss=%.3f' % (evaluate(model_a)/100, evaluate1(model_a)))\n",
    "reset_bn_stats(model_a)\n",
    "print('Post-reset:')\n",
    "print('Accuracy=%.2f%%, Loss=%.3f' % (evaluate(model_a)/100, evaluate1(model_a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c957e1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb5062",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2288c72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.allclose(model1.conv1.weight, model0.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70acdd40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
