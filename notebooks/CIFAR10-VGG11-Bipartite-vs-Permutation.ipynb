{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import os\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e467503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, i):\n",
    "    sd = model.state_dict()\n",
    "    torch.save(model.state_dict(), os.path.join(\n",
    "        os.getcwd(),\n",
    "#         '/srv/share4/gstoica3/checkpoints/REPAIR/', \n",
    "        '%s.pt' % i))\n",
    "\n",
    "def load_model(model, i):\n",
    "    sd = torch.load(os.path.join(\n",
    "        os.getcwd(),\n",
    "#         '/srv/share4/gstoica3/checkpoints/REPAIR', \n",
    "        '%s.pt' % i))\n",
    "    model.load_state_dict(sd)\n",
    "    \n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs.cuda())\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            correct += (labels.cuda() == pred).sum().item()\n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "# Given two networks net0, net1 which each output a feature map of shape NxCxWxH,\n",
    "# this will reshape both outputs to (N*W*H)xC\n",
    "# and then compute a CxC correlation matrix between the two\n",
    "def run_corr_matrix(net0, net1):\n",
    "    n = len(train_aug_loader)\n",
    "    with torch.no_grad():\n",
    "        net0.eval()\n",
    "        net1.eval()\n",
    "        for i, (images, _) in enumerate(tqdm(train_aug_loader)):\n",
    "            \n",
    "            img_t = images.float().cuda()\n",
    "            out0 = net0(img_t).double()\n",
    "            out0 = out0.permute(0, 2, 3, 1).reshape(-1, out0.shape[1])\n",
    "            out1 = net1(img_t).double()\n",
    "            out1 = out1.permute(0, 2, 3, 1).reshape(-1, out1.shape[1])\n",
    "\n",
    "            # save batchwise first+second moments and outer product\n",
    "            mean0_b = out0.mean(dim=0)\n",
    "            mean1_b = out1.mean(dim=0)\n",
    "            sqmean0_b = out0.square().mean(dim=0)\n",
    "            sqmean1_b = out1.square().mean(dim=0)\n",
    "            outer_b = (out0.T @ out1) / out0.shape[0]\n",
    "            if i == 0:\n",
    "                mean0 = torch.zeros_like(mean0_b)\n",
    "                mean1 = torch.zeros_like(mean1_b)\n",
    "                sqmean0 = torch.zeros_like(sqmean0_b)\n",
    "                sqmean1 = torch.zeros_like(sqmean1_b)\n",
    "                outer = torch.zeros_like(outer_b)\n",
    "            mean0 += mean0_b / n\n",
    "            mean1 += mean1_b / n\n",
    "            sqmean0 += sqmean0_b / n\n",
    "            sqmean1 += sqmean1_b / n\n",
    "            outer += outer_b / n\n",
    "\n",
    "    cov = outer - torch.outer(mean0, mean1)\n",
    "    std0 = (sqmean0 - mean0**2).sqrt()\n",
    "    std1 = (sqmean1 - mean1**2).sqrt()\n",
    "    outer = (torch.outer(std0, std1) + 1e-4)\n",
    "    outer[outer.isnan()] = 1e-4\n",
    "    corr = cov / outer\n",
    "    assert corr.isnan().sum() == 0, 'corr has nans...'\n",
    "    return corr\n",
    "\n",
    "def get_layer_perm1(corr_mtx):\n",
    "    corr_mtx_a = corr_mtx.cpu().numpy()\n",
    "    row_ind, col_ind = scipy.optimize.linear_sum_assignment(corr_mtx_a, maximize=True)\n",
    "    assert (row_ind == np.arange(len(corr_mtx_a))).all()\n",
    "    perm_map = torch.tensor(col_ind).long()\n",
    "    perm_map = torch.eye(corr_mtx.shape[0], device=corr_mtx.device)[perm_map]\n",
    "    return perm_map\n",
    "\n",
    "def get_bipartite_perm(corr, threshold=-torch.inf):\n",
    "    scores, idx = corr.max(0)\n",
    "    valid_elements = scores >= threshold\n",
    "    idx = torch.where(valid_elements, idx, corr.shape[0])\n",
    "    location_lookup = torch.eye(corr.shape[0]+1, corr.shape[0], device=corr.device)\n",
    "    matches = location_lookup[idx]\n",
    "    totals = matches.sum(0, keepdim=True)\n",
    "    matches = matches / (totals + 1)\n",
    "    return matches.t(), totals\n",
    "\n",
    "# returns the channel-permutation to make layer1's activations most closely\n",
    "# match layer0's.\n",
    "def get_layer_perm(net0, net1):\n",
    "    corr_mtx = run_corr_matrix(net0, net1)\n",
    "    return get_layer_perm1(corr_mtx)\n",
    "\n",
    "def get_layer_bipartite_transform(net0, net1, threshold=-torch.inf):\n",
    "    corr_mtx = run_corr_matrix(net0, net1)\n",
    "    return get_bipartite_perm(corr_mtx, threshold=threshold)\n",
    "\n",
    "# modifies the weight matrices of a convolution and batchnorm\n",
    "# layer given a permutation of the output channels\n",
    "def permute_output(perm_map, layer):\n",
    "    pre_weights = [layer.weight,\n",
    "                   layer.bias]\n",
    "    for w in pre_weights:\n",
    "        if len(w.shape) == 4:\n",
    "            transform = torch.einsum('ab,bcde->acde', perm_map, w)\n",
    "        elif len(w.shape) == 2:\n",
    "            transform = perm_map @ w\n",
    "        else:\n",
    "            transform = w @ perm_map.t()\n",
    "#         assert torch.allclose(w[perm_map.argmax(-1)], transform)\n",
    "        w.data = transform\n",
    "\n",
    "# modifies the weight matrix of a layer for a given permutation of the input channels\n",
    "# works for both conv2d and linear\n",
    "def permute_input(perm_map, layer):\n",
    "    w = layer.weight\n",
    "    if len(w.shape) == 4:\n",
    "        transform = torch.einsum('abcd,be->aecd', w, perm_map.t())\n",
    "    elif len(w.shape) == 2:\n",
    "        transform = w @ perm_map.t()\n",
    "#     assert torch.allclose(w[:, perm_map.argmax(-1)], transform)\n",
    "    w.data = transform\n",
    "\n",
    "def subnet(model, n_layers):\n",
    "    return model.features[:n_layers]\n",
    "\n",
    "def permute_model(source, target):\n",
    "    source_feats = source.features\n",
    "    target_feats = target.features\n",
    "    n = len(source_feats)\n",
    "    for i in range(n):\n",
    "        if not isinstance(target_feats[i], nn.Conv2d): continue\n",
    "        assert isinstance(target_feats[i+1], nn.ReLU)\n",
    "        perm_map = get_layer_perm(\n",
    "            subnet(source, i+2), subnet(target, i+2)\n",
    "        )\n",
    "        permute_output(perm_map, target_feats[i])\n",
    "        \n",
    "        next_layer = None\n",
    "        for j in range(i+1, n):\n",
    "            if isinstance(target_feats[j], nn.Conv2d):\n",
    "                next_layer = target_feats[j]\n",
    "                break\n",
    "        if next_layer is None:\n",
    "            next_layer = target.classifier\n",
    "        permute_input(perm_map, next_layer)\n",
    "\n",
    "def strip_param_suffix(name):\n",
    "    return name.replace('.weight', '').replace('.bias', '')\n",
    "\n",
    "def get_empty_module_dict(net):\n",
    "    module2Dict = dict()\n",
    "    module_list = []\n",
    "    for key in net.state_dict().keys():\n",
    "        base_name = strip_param_suffix(key)\n",
    "        module2Dict[base_name] = dict()\n",
    "        if base_name not in module_list:\n",
    "            module_list += [base_name]\n",
    "    return module2Dict, module_list\n",
    "\n",
    "def apply_bipartite_transform(source, target, threshold=-torch.inf):\n",
    "    source_feats = source.features\n",
    "    target_feats = target.features\n",
    "    module2Dict, module_list = get_empty_module_dict(target)\n",
    "    k = 0\n",
    "    n = len(source_feats)\n",
    "    for i in range(n):\n",
    "        if not isinstance(target_feats[i], nn.Conv2d): continue\n",
    "        assert isinstance(target_feats[i+1], nn.ReLU)\n",
    "        bipartite_map, layer_totals = get_layer_bipartite_transform(\n",
    "            subnet(source, i+2), subnet(target, i+2), threshold=threshold\n",
    "        )\n",
    "        permute_output(bipartite_map, target_feats[i])\n",
    "        module2Dict[module_list[k]]['output'] = layer_totals\n",
    "#         pdb.set_trace()\n",
    "        next_layer = None\n",
    "        for j in range(i+1, n):\n",
    "            if isinstance(target_feats[j], nn.Conv2d):\n",
    "                next_layer = target_feats[j]\n",
    "                break\n",
    "        if next_layer is None:\n",
    "            next_layer = target.classifier\n",
    "        permute_input(bipartite_map, next_layer)\n",
    "        module2Dict[module_list[k+1]]['input'] = layer_totals\n",
    "        k += 1\n",
    "    return module2Dict\n",
    "\n",
    "def combine_io_masks(io, param):\n",
    "    mask = torch.zeros_like(param, device=param.device)\n",
    "    try:\n",
    "        if 'output' in io:\n",
    "            mask[io['output'].view(-1) == 0] = 1.\n",
    "        if 'input' in io and len(mask.shape) > 1:\n",
    "            mask[:, io['input'].view(-1) == 0] = 1.\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "    return mask\n",
    "\n",
    "def mix_weights(net, alpha, key0, key1, module2io=None):\n",
    "    sd0 = torch.load(\n",
    "        os.path.join(\n",
    "            os.getcwd(),\n",
    "#             '/srv/share4/gstoica3/checkpoints/REPAIR', \n",
    "            '%s.pt' % key0\n",
    "        )\n",
    "    )\n",
    "    sd1 = torch.load(\n",
    "        os.path.join(\n",
    "            os.getcwd(),\n",
    "#             '/srv/share4/gstoica3/checkpoints/REPAIR', \n",
    "            '%s.pt' % key1\n",
    "        )\n",
    "    )\n",
    "    sd_alpha = {}\n",
    "    for k in sd0.keys():\n",
    "        param0 = sd0[k].cuda()\n",
    "        param1 = sd1[k].cuda()\n",
    "        sd_alpha[k] = (1 - alpha) * param0 + alpha * param1\n",
    "        if module2io is not None:\n",
    "            param_base = strip_param_suffix(k)\n",
    "            mask = combine_io_masks(module2io[param_base], param1)\n",
    "            sd_alpha[k][mask == 1] = param0[mask == 1]\n",
    "#     sd_alpha = {k: (1 - alpha) * sd0[k].cuda() + alpha * sd1[k].cuda()\n",
    "#                 for k in sd0.keys()}\n",
    "    net.load_state_dict(sd_alpha)\n",
    "    \n",
    "def mix_weights_over_alphas(num_times, model_a, k0, k1, module2io=None):\n",
    "    step = 1. / num_times\n",
    "    alphas = np.arange(0., 1. + step, step)\n",
    "    accuracies = []\n",
    "    for alpha in tqdm(alphas):\n",
    "        mix_weights(model_a, alpha, k0, k1, module2io=module2io)\n",
    "        accuracies.append(evaluate(model_a))\n",
    "    return alphas, accuracies\n",
    "\n",
    "def mix_weights_and_repair_over_alphas(num_times, model_a, wrap0, wrap1, k0, k1, module2io=None):\n",
    "    step = 1. / num_times\n",
    "    alphas = np.arange(0., 1. + step, step)\n",
    "    accuracies = []\n",
    "    for alpha in tqdm(alphas):\n",
    "        mix_weights(model_a, alpha, k0, k1, module2io=module2io)\n",
    "        wrap_a = make_repaired_net(model_a)\n",
    "        fuse_computed_batchnorms(wrap0, wrap1, wrap_a)\n",
    "        reset_bn_stats(wrap_a)\n",
    "        model_b = fuse_tracked_net(wrap_a)\n",
    "        accuracies.append(evaluate(model_b))\n",
    "    return alphas, accuracies\n",
    "\n",
    "class TrackLayer(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super().__init__()\n",
    "        self.layer = layer\n",
    "        self.bn = nn.BatchNorm2d(layer.out_channels)\n",
    "        \n",
    "    def get_stats(self):\n",
    "        return (self.bn.running_mean, self.bn.running_var.sqrt())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.layer(x)\n",
    "        self.bn(x1)\n",
    "        return x1\n",
    "\n",
    "class ResetLayer(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super().__init__()\n",
    "        self.layer = layer\n",
    "        self.bn = nn.BatchNorm2d(layer.out_channels)\n",
    "        \n",
    "    def set_stats(self, goal_mean, goal_std):\n",
    "        self.bn.bias.data = goal_mean\n",
    "        self.bn.weight.data = goal_std\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.layer(x)\n",
    "        return self.bn(x1)\n",
    "\n",
    "# adds TrackLayers around every conv layer\n",
    "def make_tracked_net(net):\n",
    "    net1 = vgg11()\n",
    "    net1.load_state_dict(net.state_dict())\n",
    "    for i, layer in enumerate(net1.features):\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            net1.features[i] = TrackLayer(layer)\n",
    "    return net1.cuda().eval()\n",
    "\n",
    "# adds ResetLayers around every conv layer\n",
    "def make_repaired_net(net):\n",
    "    net1 = vgg11()\n",
    "    net1.load_state_dict(net.state_dict())\n",
    "    for i, layer in enumerate(net1.features):\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            net1.features[i] = ResetLayer(layer)\n",
    "    return net1.cuda().eval()\n",
    "\n",
    "# reset all tracked BN stats against training data\n",
    "def reset_bn_stats(model):\n",
    "    # resetting stats to baseline first as below is necessary for stability\n",
    "    for m in model.modules():\n",
    "        if type(m) == nn.BatchNorm2d:\n",
    "            m.momentum = None # use simple average\n",
    "            m.reset_running_stats()\n",
    "    model.train()\n",
    "    with torch.no_grad(), autocast():\n",
    "        for images, _ in train_aug_loader:\n",
    "            output = model(images.cuda())\n",
    "            \n",
    "def fuse_conv_bn(conv, bn):\n",
    "    fused_conv = torch.nn.Conv2d(conv.in_channels,\n",
    "                                 conv.out_channels,\n",
    "                                 kernel_size=conv.kernel_size,\n",
    "                                 stride=conv.stride,\n",
    "                                 padding=conv.padding,\n",
    "                                 bias=True)\n",
    "\n",
    "    # set weights\n",
    "    w_conv = conv.weight.clone()\n",
    "    bn_std = (bn.eps + bn.running_var).sqrt()\n",
    "    gamma = bn.weight / bn_std\n",
    "    fused_conv.weight.data = (w_conv * gamma.reshape(-1, 1, 1, 1))\n",
    "\n",
    "    # set bias\n",
    "    beta = bn.bias + gamma * (-bn.running_mean + conv.bias)\n",
    "    fused_conv.bias.data = beta\n",
    "    \n",
    "    return fused_conv\n",
    "\n",
    "def fuse_tracked_net(net):\n",
    "    net1 = vgg11()\n",
    "    for i, rlayer in enumerate(net.features):\n",
    "        if isinstance(rlayer, ResetLayer):\n",
    "            fused_conv = fuse_conv_bn(rlayer.layer, rlayer.bn)\n",
    "            net1.features[i].load_state_dict(fused_conv.state_dict())\n",
    "    net1.classifier.load_state_dict(net.classifier.state_dict())\n",
    "    return net1\n",
    "\n",
    "def fuse_computed_batchnorms(wrap0, wrap1, wrap_a, alpha=0.5, module2io=None):\n",
    "    # Iterate through corresponding triples of (TrackLayer, TrackLayer, ResetLayer)\n",
    "    # around conv layers in (model0, model1, model_a).\n",
    "    if module2io is not None:\n",
    "        modules = list(module2io.keys())\n",
    "        idx = 0\n",
    "    for track0, track1, reset_a in zip(wrap0.modules(), wrap1.modules(), wrap_a.modules()): \n",
    "        if not isinstance(track0, TrackLayer):\n",
    "            continue  \n",
    "        assert (isinstance(track0, TrackLayer)\n",
    "                and isinstance(track1, TrackLayer)\n",
    "                and isinstance(reset_a, ResetLayer))\n",
    "\n",
    "        # get neuronal statistics of original networks\n",
    "        mu0, std0 = track0.get_stats()\n",
    "        mu1, std1 = track1.get_stats()\n",
    "        # set the goal neuronal statistics for the merged network \n",
    "        goal_mean = (1 - alpha) * mu0 + alpha * mu1\n",
    "        goal_std = (1 - alpha) * std0 + alpha * std1\n",
    "        if module2io is not None:\n",
    "            io = module2io[modules[idx]]\n",
    "            mask = io['output'].view(-1) == 0.\n",
    "            goal_mean[mask == 1] = mu0[mask == 1]\n",
    "            goal_std[mask == 1] = std0[mask == 1]\n",
    "            idx += 1\n",
    "        reset_a.set_stats(goal_mean, goal_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CIFAR_MEAN = [125.307, 122.961, 113.8575]\n",
    "CIFAR_STD = [51.5865, 50.847, 51.255]\n",
    "normalize = T.Normalize(np.array(CIFAR_MEAN)/255, np.array(CIFAR_STD)/255)\n",
    "denormalize = T.Normalize(-np.array(CIFAR_MEAN)/np.array(CIFAR_STD), 255/np.array(CIFAR_STD))\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "train_dset = torchvision.datasets.CIFAR10(root='/tmp', train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "test_dset = torchvision.datasets.CIFAR10(root='/tmp', train=False,\n",
    "                                        download=True, transform=test_transform)\n",
    "\n",
    "train_aug_loader = torch.utils.data.DataLoader(train_dset, batch_size=500, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=500, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/kuangliu/pytorch-cifar/blob/master/models/vgg.py\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name, w=1):\n",
    "        super(VGG, self).__init__()\n",
    "        self.w = w\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(self.w*512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers.append(nn.Conv2d(in_channels if in_channels == 3 else self.w*in_channels,\n",
    "                                     self.w*x, kernel_size=3, padding=1))\n",
    "                layers.append(nn.ReLU(inplace=True))\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "def vgg11(w=1):\n",
    "    return VGG('VGG11', w).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maybe Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(w=1):\n",
    "    model = vgg11(w)\n",
    "    optimizer = SGD(model.parameters(), lr=0.08, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    EPOCHS = 100\n",
    "    ne_iters = len(train_aug_loader)\n",
    "    lr_schedule = np.interp(np.arange(1+EPOCHS*ne_iters), [0, 5*ne_iters, EPOCHS*ne_iters], [0, 1, 0])\n",
    "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_schedule.__getitem__)\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "\n",
    "    losses = []\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        model.train()\n",
    "        for i, (inputs, labels) in enumerate(train_aug_loader):\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with autocast():\n",
    "                outputs = model(inputs.cuda())\n",
    "                loss = loss_fn(outputs, labels.cuda())\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            losses.append(loss.item())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [09:18<00:00,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8924\n"
     ]
    }
   ],
   "source": [
    "# model = train_model()\n",
    "# print(evaluate(model))\n",
    "save_model(model, 'vgg11_v1')\n",
    "\n",
    "model = train_model()\n",
    "print(evaluate(model))\n",
    "save_model(model, 'vgg11_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan  2 13:33:14 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.142.00   Driver Version: 450.142.00   CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   42C    P0    41W / 300W |   5262MiB / 16160MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      9093      C   ...user/anaconda3/bin/python     2037MiB |\r\n",
      "|    0   N/A  N/A      9180      C   ...user/anaconda3/bin/python     3223MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = '1'\n",
    "m1 = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.897, 0.8924)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0 = vgg11()\n",
    "model1 = vgg11()\n",
    "load_model(model0, f'vgg11_v{m0}')\n",
    "load_model(model1, f'vgg11_v{m1}')\n",
    "\n",
    "evaluate(model0), evaluate(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = .897"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Permutation with REPAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 18.97it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 18.06it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 17.83it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 17.91it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 17.82it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 17.97it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 17.61it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 17.88it/s]\n"
     ]
    }
   ],
   "source": [
    "permute_model(model0, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8923\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(model1))\n",
    "save_model(model1, f'vgg11_v{m1}_perm1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Only Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(α=0): 89.7% \t\t<-- Model A\n",
      "(α=1): 89.2% \t\t<-- Model B\n",
      "(α=0.5): 61.8% \t\t<-- Merged model\n"
     ]
    }
   ],
   "source": [
    "k0 = f'vgg11_v{m0}'\n",
    "k1 = f'vgg11_v{m1}_perm1'\n",
    "model0 = vgg11()\n",
    "model1 = vgg11()\n",
    "model_a = vgg11()\n",
    "mix_weights(model0, 0.0, k0, k1)\n",
    "mix_weights(model1, 1.0, k0, k1)\n",
    "\n",
    "alpha = 0.5\n",
    "mix_weights(model_a, alpha, k0, k1)\n",
    "print('(α=0): %.1f%% \\t\\t<-- Model A' % (100*evaluate(model0)))\n",
    "print('(α=1): %.1f%% \\t\\t<-- Model B' % (100*evaluate(model1)))\n",
    "print('(α=0.5): %.1f%% \\t\\t<-- Merged model' % (100*evaluate(model_a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:12<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "alphas, permute_accuracies = mix_weights_over_alphas(10, model_a, k0, k1)\n",
    "alpha = 0.5\n",
    "mix_weights(model_a, alpha, k0, k1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Apply REPAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate all neuronal statistics in the endpoint networks\n",
    "wrap0 = make_tracked_net(model0)\n",
    "wrap1 = make_tracked_net(model1)\n",
    "reset_bn_stats(wrap0)\n",
    "reset_bn_stats(wrap1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap0 = make_tracked_net(model0)\n",
    "perm_wrap1 = make_tracked_net(model1)\n",
    "reset_bn_stats(wrap0)\n",
    "reset_bn_stats(perm_wrap1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [02:05<00:00, 11.42s/it]\n"
     ]
    }
   ],
   "source": [
    "alphas, permute_repairs = mix_weights_and_repair_over_alphas(10, model_a, wrap0, wrap1, k0, k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8823,\n",
       " 0.8838,\n",
       " 0.8757,\n",
       " 0.8659,\n",
       " 0.8501,\n",
       " 0.8448,\n",
       " 0.8531,\n",
       " 0.865,\n",
       " 0.8721,\n",
       " 0.8758,\n",
       " 0.8778]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permute_repairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Bipartite with REPAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.897, 0.8924)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0 = vgg11()\n",
    "model1 = vgg11()\n",
    "load_model(model0, f'vgg11_v{m0}')\n",
    "load_model(model1, f'vgg11_v{m1}')\n",
    "\n",
    "evaluate(model0), evaluate(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 11.06it/s]\n",
      "100%|██████████| 100/100 [00:08<00:00, 12.23it/s]\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.17it/s]\n",
      "100%|██████████| 100/100 [00:08<00:00, 12.02it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 16.67it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 17.94it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 18.20it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 18.03it/s]\n"
     ]
    }
   ],
   "source": [
    "module2io = apply_bipartite_transform(model0, model1, threshold=-torch.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(model1))\n",
    "save_model(model1, f'vgg11_v{m1}_bipartite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(α=0): 89.7% \t\t<-- Model A\n",
      "(α=1): 10.0% \t\t<-- Model B\n",
      "(α=0.5): 84.9% \t\t<-- Merged model\n"
     ]
    }
   ],
   "source": [
    "k0 = f'vgg11_v{m0}'\n",
    "k1 = f'vgg11_v{m1}_bipartite'\n",
    "model0 = vgg11()\n",
    "model1 = vgg11()\n",
    "model_a = vgg11()\n",
    "mix_weights(model0, 0.0, k0, k1)\n",
    "mix_weights(model1, 1.0, k0, k1)\n",
    "\n",
    "alpha = 0.5\n",
    "mix_weights(model_a, alpha, k0, k1, module2io=module2io)\n",
    "print('(α=0): %.1f%% \\t\\t<-- Model A' % (100*evaluate(model0)))\n",
    "print('(α=1): %.1f%% \\t\\t<-- Model B' % (100*evaluate(model1)))\n",
    "print('(α=0.5): %.1f%% \\t\\t<-- Merged model' % (100*evaluate(model_a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:11<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "alphas, bipartite_accuracies = mix_weights_over_alphas(10, model_a, k0, k1, module2io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate all neuronal statistics in the endpoint networks\n",
    "wrap0 = make_tracked_net(model0)\n",
    "wrap1 = make_tracked_net(model1)\n",
    "reset_bn_stats(wrap0)\n",
    "reset_bn_stats(wrap1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [01:21<00:00,  7.38s/it]\n"
     ]
    }
   ],
   "source": [
    "alphas, bipartite_repairs = mix_weights_and_repair_over_alphas(\n",
    "    10, model_a, wrap0, wrap1, k0, k1, module2io=module2io\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8937,\n",
       " 0.8938,\n",
       " 0.8928,\n",
       " 0.8927,\n",
       " 0.8923,\n",
       " 0.89,\n",
       " 0.8873,\n",
       " 0.8815,\n",
       " 0.8706,\n",
       " 0.8502,\n",
       " 0.8196]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bipartite_repairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "# plt.axhline(best_acc, label='Best Baseline Acc', color='grey')\n",
    "plt.plot(alphas, np.array(permute_accuracies) - best_acc, label='Permute')\n",
    "plt.plot(alphas, np.array(permute_repairs) - best_acc, label='Permute & REPAIR')\n",
    "plt.plot(alphas, np.array(bipartite_accuracies) - best_acc, label='Bipartite')\n",
    "plt.plot(alphas, np.array(bipartite_repairs) - best_acc, label='Bipartite & REPAIR')\n",
    "plt.legend()\n",
    "ax.set_ylim(-.4, 0.1)\n",
    "plt.title(f'CIFAR10 & VGG11: Aligning {m1} --> {m0}')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('Loss Barrier')\n",
    "plt.savefig(os.path.join(os.getcwd(), f'cifar10_vgg11_{m1}to{m0}'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.897"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8982"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(bipartite_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENAS-pytorch",
   "language": "python",
   "name": "enas-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
