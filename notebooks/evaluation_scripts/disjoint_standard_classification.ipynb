{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f48a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7fc0fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f3274739850>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam, lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sys import platform\n",
    "\n",
    "DEVICE = 'mps' if platform == 'darwin' else 'cuda'\n",
    "if DEVICE == 'mps':\n",
    "    DOWNLOAD_PATH = '/Users/georgestoica/Downloads' \n",
    "else:\n",
    "    DOWNLOAD_PATH = '/srv/share/gstoica3/checkpoints/REPAIR/'\n",
    "    \n",
    "torch.autograd.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af5a5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2edab3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, i):\n",
    "    sd = model.state_dict()\n",
    "    path = os.path.join(\n",
    "        # '/Users/georgestoica/Downloads',\n",
    "        DOWNLOAD_PATH,\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def load_model(model, i):\n",
    "    path = os.path.join(\n",
    "        # '/Users/georgestoica/Downloads',\n",
    "        DOWNLOAD_PATH,\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    sd = torch.load(path, map_location=torch.device(DEVICE))\n",
    "    model.load_state_dict(sd)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11765ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_info = {\n",
    "    'dir': '/nethome/gstoica3/research/pytorch-cifar100/data/cifar-100-python',\n",
    "    'classes1': np.arange(50),\n",
    "    'classes2': np.arange(50, 100),\n",
    "    'num_classes': 100,\n",
    "    'split_classes': 50\n",
    "}\n",
    "\n",
    "cifar10_info = {\n",
    "    'dir': '/tmp',\n",
    "    'classes1': np.array([3, 2, 0, 6, 4]),\n",
    "    'classes2': np.array([5, 7, 9, 8, 1]),\n",
    "    'num_classes': 10,\n",
    "    'split_classes': 5\n",
    "}\n",
    "\n",
    "ds_info = cifar100_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4622a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CIFAR_MEAN = [125.307, 122.961, 113.8575]\n",
    "CIFAR_STD = [51.5865, 50.847, 51.255]\n",
    "normalize = T.Normalize(np.array(CIFAR_MEAN)/255, np.array(CIFAR_STD)/255)\n",
    "denormalize = T.Normalize(-np.array(CIFAR_MEAN)/np.array(CIFAR_STD), 255/np.array(CIFAR_STD))\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "train_dset = torchvision.datasets.CIFAR100(root=ds_info['dir'], train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "test_dset = torchvision.datasets.CIFAR100(root=ds_info['dir'], train=False,\n",
    "                                        download=True, transform=test_transform)\n",
    "\n",
    "train_aug_loader = torch.utils.data.DataLoader(train_dset, batch_size=500, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=500, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e93ecf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:12, 3869.64it/s]\n",
      "50000it [00:12, 3866.69it/s]\n",
      "10000it [00:01, 5890.21it/s]\n",
      "10000it [00:01, 5932.15it/s]\n"
     ]
    }
   ],
   "source": [
    "train_aug_loader = torch.utils.data.DataLoader(train_dset, batch_size=500, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=500, shuffle=False, num_workers=8)\n",
    "\n",
    "model1_classes= ds_info['classes1']#np.array([3, 2, 0, 6, 4])\n",
    "model2_classes = ds_infoZ['classes2']\n",
    "\n",
    "valid_examples1 = [i for i, (_, label) in tqdm(enumerate(train_dset)) if label in model1_classes]\n",
    "valid_examples2 = [i for i, (_, label) in tqdm(enumerate(train_dset)) if label in model2_classes]\n",
    "\n",
    "assert len(set(valid_examples1).intersection(set(valid_examples2))) == 0, 'sets should be disjoint'\n",
    "\n",
    "train_aug_loader1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dset, valid_examples1), batch_size=500, shuffle=True, num_workers=8\n",
    ")\n",
    "train_aug_loader2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dset, valid_examples2), batch_size=500, shuffle=True, num_workers=8\n",
    ")\n",
    "\n",
    "test_valid_examples1 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model1_classes]\n",
    "test_valid_examples2 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model2_classes]\n",
    "\n",
    "test_loader1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dset, test_valid_examples1), batch_size=500, shuffle=False, num_workers=8\n",
    ")\n",
    "test_loader2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dset, test_valid_examples2), batch_size=500, shuffle=False, num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dfa46be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,  0,  1,  2,  3,\n",
      "         4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
      "        22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n",
      "        40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n"
     ]
    }
   ],
   "source": [
    "class_idxs = np.zeros(100, dtype=int)\n",
    "class_idxs[model1_classes] = np.arange(ds_info['split_classes'])\n",
    "class_idxs[model2_classes] = np.arange(ds_info['split_classes'])\n",
    "class_idxs = torch.from_numpy(class_idxs)\n",
    "print(class_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27223ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "789d93e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmeans_pytorch import kmeans, kmeans_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4e31c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac63643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnets import resnet20\n",
    "from matching_algs import *\n",
    "from model_matchings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e77f61e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/srv/share/gstoica3/checkpoints/REPAIR/resnet20x4_CIFAR50_clses[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]_onehot.pth.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_45275/951176962.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m modela = load_model(\n\u001b[1;32m      2\u001b[0m     \u001b[0mresnet20\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34mf'resnet20x4_CIFAR50_clses{model1_classes.tolist()}_onehot'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_45275/3161928138.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model, i)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;34m'%s.pth.tar'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     )\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/srv/share/gstoica3/checkpoints/REPAIR/resnet20x4_CIFAR50_clses[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]_onehot.pth.tar'"
     ]
    }
   ],
   "source": [
    "modela = load_model(\n",
    "    resnet20(w=4, num_classes=5).to(DEVICE),\n",
    "    f'resnet20x4_CIFAR50_clses{model1_classes.tolist()}_onehot'\n",
    ")\n",
    "\n",
    "modelb = load_model(\n",
    "    resnet20(w=4, num_classes=5).to(DEVICE),\n",
    "    f'resnet20x4_CIFAR50_clses{model2_classes.tolist()}_onehot'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f4e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates accuracy\n",
    "def evaluate(model, loader, num_classes, remap_class_idxs=None, return_confusion=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    totals = [0] * num_classes\n",
    "    corrects = [0] * num_classes\n",
    "    confusion = np.zeros((10, 10))\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            logits = model(inputs.to(DEVICE))\n",
    "            pred = logits.argmax(dim=1)\n",
    "            if remap_class_idxs is not None:\n",
    "                remaped_labels = remap_class_idxs[labels]\n",
    "            else:\n",
    "                remaped_labels = labels\n",
    "                \n",
    "            correct += (remaped_labels.to(DEVICE) == pred).sum().item()\n",
    "            \n",
    "            for gt, p in zip(remaped_labels, pred):\n",
    "                totals[gt] += 1\n",
    "                if gt == p:\n",
    "                    corrects[gt] += 1\n",
    "            \n",
    "            total += inputs.shape[0]\n",
    "    if return_confusion:\n",
    "        return correct / sum(totals), list(map(lambda a: a[0] / a[1], zip(corrects, totals)))\n",
    "    else:\n",
    "        return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871c1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    modela, test_loader1, num_classes=ds_info['num_classes'],  \n",
    "    remap_class_idxs=class_idxs, return_confusion=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96753bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    modelb, test_loader2, num_classes=ds_info['num_classes'], \n",
    "    remap_class_idxs=class_idxs, return_confusion=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187d8a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_class_idxs = deepcopy(class_idxs)\n",
    "concat_class_idxs[model2_classes] += 5\n",
    "concat_class_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e78cc21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def general_soft_matching(\n",
    "#     hull_tensor,\n",
    "#     interleave=False,\n",
    "#     random=False,\n",
    "#     r=.5\n",
    "# ):  \n",
    "#     hull_tensor = hull_tensor[0]\n",
    "#     hull_normed = hull_tensor / hull_tensor.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "#     bound = int(hull_tensor.shape[0] * (1-r))\n",
    "    \n",
    "#     sims = hull_normed @ hull_normed.transpose(-1, -2)\n",
    "#     uppertri_indices = torch.triu_indices(sims.shape[-2], sims.shape[-1], offset=0)\n",
    "#     sims[uppertri_indices[0], uppertri_indices[1]] = -torch.inf\n",
    "#     candidate_scores, candidate_indices = sims.max(-1)\n",
    "#     argsorted_scores = candidate_scores.argsort(descending=True)\n",
    "#     merge_indices = argsorted_scores[:bound]\n",
    "#     unmerge_indices = argsorted_scores[bound:]\n",
    "    \n",
    "#     roots = torch.arange(sims.shape[0], device=sims.device)\n",
    "#     for _ in range(bound-1):\n",
    "#         roots[merge_indices] = roots[candidate_indices[merge_indices]]\n",
    "    \n",
    "#     def merge(x, mode='mean'):\n",
    "#         x = x[0]\n",
    "#         merge_tensor = x.scatter_reduce(\n",
    "#             0, \n",
    "#             roots[merge_indices][:, None].expand(bound, x.shape[1]),\n",
    "#             x[merge_indices], \n",
    "#             reduce='mean'\n",
    "#         )\n",
    "#         unmerge_tensor = merge_tensor[unmerge_indices]\n",
    "#         return unmerge_tensor[None]\n",
    "    \n",
    "#     def unmerge(x):\n",
    "#         x = x[0]\n",
    "#         out = torch.zeros((hull_tensor.shape[0], x.shape[1]), device=x.device)\n",
    "#         out.scatter_(\n",
    "#             0,\n",
    "#             index=unmerge_indices[:, None].expand(*x.shape),\n",
    "#             src=x\n",
    "#         )\n",
    "#         out = out.scatter(\n",
    "#             0,\n",
    "#             index=merge_indices[:, None].expand(*x.shape),\n",
    "#             src=out[roots[merge_indices]]\n",
    "#         )\n",
    "#         return out[None]\n",
    "    \n",
    "#     return merge, unmerge\n",
    "\n",
    "    \n",
    "# def match_tensors_tome(\n",
    "#     hull_tensor, eps=1e-7, interleave=False, random_perm=False, \n",
    "#     backend_alg=general_soft_matching\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     hull_tensor: [2O,I]\n",
    "#     \"\"\"\n",
    "#     O, I = hull_tensor.shape\n",
    "#     O //= 2\n",
    "    \n",
    "#     big_eye = torch.eye(2*O, device=hull_tensor.device)\n",
    "#     small_eye = torch.eye(O, device=hull_tensor.device)\n",
    "    \n",
    "#     interleave_mat = big_eye\n",
    "#     if interleave:\n",
    "#         A1, A2, B1, B2 = interleave_mat.chunk(4, dim=0)\n",
    "#         interleave_mat = torch.cat([A1, B1, A2, B2], dim=0)\n",
    "    \n",
    "    \n",
    "#     hull_tensor = interleave_mat @ hull_tensor\n",
    "    \n",
    "#     merge, unmerge = backend_alg(hull_tensor[None], 0.5)\n",
    "    \n",
    "#     merge_mat = merge(big_eye[None])[0] @ interleave_mat\n",
    "#     unmerge_mat = interleave_mat.T @ unmerge(small_eye[None])[0]\n",
    "#     return merge_mat, unmerge_mat\n",
    "\n",
    "# def kmeans_matching(\n",
    "#     hull_tensor,\n",
    "#     interleave=False,\n",
    "#     random_perm=False,\n",
    "#     r=.5\n",
    "# ):\n",
    "#     hull_normed = hull_tensor / hull_tensor.norm(dim=-1, keepdim=True)\n",
    "#     O = hull_tensor.shape[0]\n",
    "#     k = int(O * (1-r))\n",
    "#     cluster_ids, cluster_centers = kmeans(\n",
    "#         X=hull_normed, num_clusters=k, \n",
    "#         distance='cosine', \n",
    "#         device=hull_tensor.device,\n",
    "#         tqdm_flag=False,\n",
    "#         seed=123\n",
    "#     )\n",
    "\n",
    "#     eye = torch.eye(k, device=hull_tensor.device)\n",
    "#     transform = eye[cluster_ids]\n",
    "\n",
    "#     unmerge = transform\n",
    "#     merge = (transform / transform.sum(dim=0, keepdim=True)).T\n",
    "#     return merge, unmerge\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610fb3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_transform_differences(old_transforms, current_transforms):\n",
    "    if len(old_transforms) == 0:\n",
    "        return {}\n",
    "    transform2norm = {}\n",
    "    for key, old_transform in old_transforms.items():\n",
    "        current_transform = current_transforms[key]\n",
    "        old_align = old_transform.output_align\n",
    "        new_align = current_transform.output_align\n",
    "        cost = old_align.T @ new_align\n",
    "        row_ind, col_idx = scipy.optimize.linear_sum_assignment(cost.detach().cpu().numpy())\n",
    "        permutation = torch.eye(new_align.shape[1], device=old_align.device)[col_idx]\n",
    "        aligned_new = new_align @ permutation\n",
    "#         pdb.set_trace()\n",
    "        norm = torch.norm(old_align - aligned_new).cpu().numpy()\n",
    "        transform2norm[key] = norm\n",
    "    return transform2norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d11b2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r = 0.5\n",
    "fn = match_tensors_exact_bipartite\n",
    "set_r(r)\n",
    "set_match_fn(fn)\n",
    "\n",
    "match_tensors = match_wrapper(fn, interleave=False, random_perm=False)\n",
    "layer_transform = lambda : LayerTransform(normalize_tensors=False, tensor_merge_type='concat')\n",
    "old_state_dict = {}\n",
    "state_dict = {}\n",
    "old_transforms = defaultdict(lambda: layer_transform())\n",
    "new_transforms = defaultdict(lambda: layer_transform())\n",
    "modelc = resnet20(w=4, text_head=True).to(DEVICE)\n",
    "accuracies = []\n",
    "steps = []\n",
    "distances = []\n",
    "best_info = {'acc': 0., 'dist': np.inf}\n",
    "step = 1\n",
    "is_converged = False\n",
    "prev_distance = np.inf\n",
    "same_window = 5\n",
    "same_span = 0\n",
    "while not is_converged:\n",
    "# for step in tqdm(range(1000)):\n",
    "    old_transforms = new_transforms\n",
    "    old_state_dict = deepcopy(state_dict)\n",
    "    new_transforms = merge_resnet20(\n",
    "        state_dict, \n",
    "        modela, \n",
    "        modelb, \n",
    "        transforms=deepcopy(old_transforms),\n",
    "        concat_head=True\n",
    "    )\n",
    "    if step == 0:\n",
    "        original_computation = deepcopy(new_transforms)\n",
    "\n",
    "    transform2dist = find_transform_differences(old_transforms, new_transforms)\n",
    "    avg_distance = np.mean(list(transform2dist.values()))\n",
    "    \n",
    "    if abs(avg_distance - prev_distance) <= 1e-5:\n",
    "        same_span += 1\n",
    "    else:\n",
    "        same_span = 0\n",
    "    if same_span >= same_window:\n",
    "        is_converged = True\n",
    "        \n",
    "    prev_distance = avg_distance\n",
    "\n",
    "    if is_converged or step >= 1000:\n",
    "        break\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb7f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa09c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp = resnet20(w=8 * (1-r), num_classes=ds_info['num_classes'], text_head=False).eval().to(DEVICE)\n",
    "model_comp.load_state_dict(state_dict)\n",
    "reset_bn_stats(model_comp, loader=train_aug_loader)\n",
    "acc, confusion = evaluate(\n",
    "    model_comp, test_loader, num_classes=ds_info['num_classes'], \n",
    "    remap_class_idxs=concat_class_idxs, return_confusion=True\n",
    ")\n",
    "print(step, acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca816935",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de632fc",
   "metadata": {},
   "source": [
    "### Model Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb5a27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates accuracy\n",
    "def evaluate_ensemble(\n",
    "    modela,\n",
    "    modelb,\n",
    "    loader, \n",
    "    num_classes, \n",
    "    remap_class_idxs=None, \n",
    "    return_confusion=False\n",
    "):\n",
    "    modela.eval()\n",
    "    modelb.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    totals = [0] * num_classes\n",
    "    corrects = [0] * num_classes\n",
    "    confusion = np.zeros((10, 10))\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            logitsa = modela(inputs.to(DEVICE))\n",
    "            logitsb = modelb(inputs.to(DEVICE))\n",
    "            \n",
    "            preda_score, preda_idx = logitsa.max(dim=1)\n",
    "            predb_score, predb_idx = logitsb.max(dim=1)\n",
    "            pred = preda_idx\n",
    "            pred[preda_score < predb_score] = predb_idx[preda_score < predb_score] + (num_classes // 2)\n",
    "            \n",
    "            if remap_class_idxs is not None:\n",
    "                remaped_labels = remap_class_idxs[labels]\n",
    "            else:\n",
    "                remaped_labels = labels\n",
    "                \n",
    "            correct += (remaped_labels.to(DEVICE) == pred).sum().item()\n",
    "            \n",
    "            for gt, p in zip(remaped_labels, pred):\n",
    "                totals[gt] += 1\n",
    "                if gt == p:\n",
    "                    corrects[gt] += 1\n",
    "            \n",
    "            total += inputs.shape[0]\n",
    "    if return_confusion:\n",
    "        return correct / sum(totals), list(map(lambda a: a[0] / a[1], zip(corrects, totals)))\n",
    "    else:\n",
    "        return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97be2262",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_acc, ensemble_confusion = evaluate_ensemble(\n",
    "    modela, modelb, test_loader, num_classes=ds_info['num_classes'],\n",
    "    remap_class_idxs=concat_class_idxs, return_confusion=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a5a01af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7853"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edff3c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.721, 0.768, 0.871, 0.835, 0.83, 0.714, 0.826, 0.797, 0.727, 0.764]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b79e19e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
