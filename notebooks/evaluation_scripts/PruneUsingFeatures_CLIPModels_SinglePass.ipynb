{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256b885f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam, lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sys import platform\n",
    "\n",
    "DEVICE = 'mps' if platform == 'darwin' else 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d7eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6c5d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a983d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, i):\n",
    "    sd = model.state_dict()\n",
    "    path = os.path.join(\n",
    "        # '/Users/georgestoica/Downloads',\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def load_model(model, i):\n",
    "    path = os.path.join(\n",
    "        # '/Users/georgestoica/Downloads',\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    sd = torch.load(path, map_location=torch.device(DEVICE))\n",
    "    model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1028485",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_info = {\n",
    "    'dir': '/nethome/gstoica3/research/pytorch-cifar100/data/cifar-100-python',\n",
    "    'classes1': np.arange(50),\n",
    "    'classes2': np.arange(50, 100),\n",
    "    'num_classes': 100,\n",
    "    'split_classes': 50,\n",
    "    'wrapper': torchvision.datasets.CIFAR100\n",
    "}\n",
    "\n",
    "cifar10_info = {\n",
    "    'dir': '/tmp',\n",
    "    'classes1': np.array([3, 2, 0, 6, 4]),\n",
    "    'classes2': np.array([5, 7, 9, 8, 1]),\n",
    "    'num_classes': 10,\n",
    "    'split_classes': 5,\n",
    "    'wrapper': torchvision.datasets.CIFAR10\n",
    "}\n",
    "\n",
    "ds_info = cifar10_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d3687c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "489caa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "\n",
    "\n",
    "class BalancedBatchSampler(BatchSampler):\n",
    "    \"\"\"\n",
    "    BatchSampler - from a MNIST-like dataset, samples n_classes and within these classes samples n_samples.\n",
    "    Returns batches of size n_classes * n_samples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, n_classes, n_samples):\n",
    "        loader = DataLoader(dataset)\n",
    "        self.labels_list = []\n",
    "        for _, label in loader:\n",
    "            self.labels_list.append(label)\n",
    "        self.labels = torch.LongTensor(self.labels_list)\n",
    "        self.labels_set = list(set(self.labels.numpy()))\n",
    "        self.label_to_indices = {label: np.where(self.labels.numpy() == label)[0]\n",
    "                                 for label in self.labels_set}\n",
    "        for l in self.labels_set:\n",
    "            np.random.shuffle(self.label_to_indices[l])\n",
    "        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n",
    "        self.count = 0\n",
    "        self.n_classes = n_classes\n",
    "        self.n_samples = n_samples\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = self.n_samples * self.n_classes\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.count = 0\n",
    "        while self.count + self.batch_size <= len(self.dataset):\n",
    "            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n",
    "            indices = []\n",
    "            for class_ in classes:\n",
    "                indices.extend(self.label_to_indices[class_][\n",
    "                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n",
    "                                                                         class_] + self.n_samples])\n",
    "                self.used_label_indices_count[class_] += self.n_samples\n",
    "                if self.used_label_indices_count[class_] + self.n_samples > len(self.label_to_indices[class_]):\n",
    "                    np.random.shuffle(self.label_to_indices[class_])\n",
    "                    self.used_label_indices_count[class_] = 0\n",
    "            yield indices\n",
    "            self.count += self.n_classes * self.n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9cd3aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CIFAR_MEAN = [125.307, 122.961, 113.8575]\n",
    "CIFAR_STD = [51.5865, 50.847, 51.255]\n",
    "normalize = T.Normalize(np.array(CIFAR_MEAN)/255, np.array(CIFAR_STD)/255)\n",
    "denormalize = T.Normalize(-np.array(CIFAR_MEAN)/np.array(CIFAR_STD), 255/np.array(CIFAR_STD))\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "train_dset = ds_info['wrapper'](root=ds_info['dir'], train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "test_dset = ds_info['wrapper'](root=ds_info['dir'], train=False,\n",
    "                                        download=True, transform=test_transform)\n",
    "\n",
    "train_aug_loader = torch.utils.data.DataLoader(train_dset, batch_size=500, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=500, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c1172d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:15, 3211.91it/s]\n",
      "50000it [00:15, 3196.55it/s]\n",
      "10000it [00:02, 4781.21it/s]\n",
      "10000it [00:02, 4821.14it/s]\n"
     ]
    }
   ],
   "source": [
    "model1_classes= ds_info['classes1']#np.array([3, 2, 0, 6, 4])\n",
    "model2_classes = ds_info['classes2']\n",
    "\n",
    "valid_examples1 = [i for i, (_, label) in tqdm(enumerate(train_dset)) if label in model1_classes]\n",
    "valid_examples2 = [i for i, (_, label) in tqdm(enumerate(train_dset)) if label in model2_classes]\n",
    "\n",
    "assert len(set(valid_examples1).intersection(set(valid_examples2))) == 0, 'sets should be disjoint'\n",
    "\n",
    "train_aug_loader1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dset, valid_examples1), batch_size=500, shuffle=False, num_workers=8\n",
    ")\n",
    "train_aug_loader2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dset, valid_examples2), batch_size=500, shuffle=False, num_workers=8\n",
    ")\n",
    "\n",
    "test_valid_examples1 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model1_classes]\n",
    "test_valid_examples2 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model2_classes]\n",
    "\n",
    "test_loader1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dset, test_valid_examples1), batch_size=500, shuffle=False, num_workers=8\n",
    ")\n",
    "test_loader2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dset, test_valid_examples2), batch_size=500, shuffle=False, num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38614cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_batched_sampler = BalancedBatchSampler(train_dset, n_classes=ds_info['num_classes'], n_samples=50)\n",
    "balanced_train_aug_loader = torch.utils.data.DataLoader(\n",
    "    train_dset, num_workers=8, batch_sampler=balanced_batched_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff760c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 1, 0, 4, 0, 3, 1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "class_idxs = np.zeros(ds_info['num_classes'], dtype=int)\n",
    "class_idxs[model1_classes] = np.arange(ds_info['split_classes'])\n",
    "class_idxs[model2_classes] = np.arange(ds_info['split_classes'])\n",
    "class_idxs = torch.from_numpy(class_idxs)\n",
    "print(class_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26093947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the train loader with data augmentation as this gives better results\n",
    "def reset_bn_stats(model, epochs=1, loader=train_aug_loader):\n",
    "    # resetting stats to baseline first as below is necessary for stability\n",
    "    for m in model.modules():\n",
    "        if type(m) == nn.BatchNorm2d:\n",
    "            m.momentum = None # use simple average\n",
    "            m.reset_running_stats()\n",
    "    # run a single train epoch with augmentations to recalc stats\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        with torch.no_grad(), autocast():\n",
    "            for images, _ in loader:\n",
    "                output = model(images.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6155682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates accuracy\n",
    "def evaluate_texthead(model, loader, class_vectors, remap_class_idxs=None, return_confusion=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    totals = [0] * class_vectors.shape[0]\n",
    "    corrects = [0] * class_vectors.shape[0]\n",
    "    \n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            encodings = model(inputs.to(DEVICE))\n",
    "            normed_encodings = encodings / encodings.norm(dim=-1, keepdim=True)\n",
    "            outputs = normed_encodings @ class_vectors.T\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            if remap_class_idxs is not None:\n",
    "                correct += (remap_class_idxs[labels].to(DEVICE) == pred).sum().item()\n",
    "            else:\n",
    "                for gt, p in zip(labels, pred):\n",
    "                    totals[gt] += 1\n",
    "                    \n",
    "                    if gt == p:\n",
    "                        correct += 1\n",
    "                        corrects[gt] += 1\n",
    "                \n",
    "            total += inputs.shape[0]\n",
    "    if return_confusion:\n",
    "        return correct / sum(totals), list(map(lambda a: a[0] / a[1], zip(corrects, totals)))\n",
    "    else:\n",
    "        return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d932fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in test_dset.classes]).to(DEVICE)\n",
    "model, preprocess = clip.load('ViT-B/32', DEVICE)\n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "class_vecs1 = text_features[model1_classes]\n",
    "class_vecs2 = text_features[model2_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4753f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnets import resnet20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2db1035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_tensors_by_minimums(\n",
    "    scores,\n",
    "    r=.5\n",
    "):\n",
    "    O = scores.shape[0]\n",
    "    total_to_prune = int(O * (1 - r))\n",
    "    permutation_matrix = torch.eye(O, O, device=scores.device)\n",
    "    search_space = scores.clone()\n",
    "    min_args = search_space.argsort()[:total_to_prune]\n",
    "    torch.diagonal(permutation_matrix)[min_args] = 0.\n",
    "    return permutation_matrix.T, permutation_matrix\n",
    "\n",
    "def prune_tensors_by_negatives(\n",
    "    scores,\n",
    "):\n",
    "    O = scores.shape[0]\n",
    "    permutation_matrix = torch.eye(O, O, device=scores.device)\n",
    "    search_space = scores.clone()\n",
    "    min_args = (search_space <= 0.).to(torch.float).nonzero().view(-1)\n",
    "    torch.diagonal(permutation_matrix)[min_args] = 0.\n",
    "    return permutation_matrix.T, permutation_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dbee49",
   "metadata": {},
   "source": [
    "## Single Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fa94de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoringBase(object):\n",
    "    def __init__(self):\n",
    "        super(ScoringBase, self).__init__()\n",
    "        self.layer2score = defaultdict(lambda: None)\n",
    "        self.output_pattern = lambda model, x: F.relu(model.bn1(model.conv1(x)))\n",
    "    \n",
    "    def get_layer_intermediates(self, batch, layer, label, n):\n",
    "        pass\n",
    "    \n",
    "    def get_intermediate_scores(self, model, dataloader, num_passes=1, num_steps=None):\n",
    "        pass\n",
    "    \n",
    "    def batch_update_scores(self, label, out, n):\n",
    "        pass\n",
    "    \n",
    "    def get_layer2score(self):\n",
    "        return self.layer2score\n",
    "\n",
    "class CovarianceScoring(ScoringBase):\n",
    "    def __init__(self):\n",
    "        super(CovarianceScoring, self).__init__()\n",
    "        ScoringBase.__init__(self)\n",
    "    \n",
    "    def get_layer_intermediates(self, batch, layer, label, n):\n",
    "        for i, inter in enumerate(list(layer)):\n",
    "            out = self.output_pattern(inter, batch)\n",
    "            self.batch_update_scores(label+f'.{i}', out=out, n=n)\n",
    "            batch = inter(batch)\n",
    "        self.batch_update_scores(label, out=batch, n=n)\n",
    "        return batch\n",
    "    \n",
    "    def batch_update_scores(self, label, out, n):\n",
    "        out = out.reshape(out.shape[0], out.shape[1], -1).permute(0, 2, 1)\n",
    "        out = out.reshape(-1, out.shape[2]).double()\n",
    "        mean_b = out.mean(dim=0).detach().cpu()\n",
    "        std_b = out.std(dim=0).detach().cpu()\n",
    "        outer_b = ((out.T @ out) / out.shape[0]).detach().cpu()\n",
    "\n",
    "        if self.layer2score[label] is None:\n",
    "            self.layer2score[label] = {}\n",
    "            self.layer2score[label]['mean'] = torch.zeros_like(mean_b)\n",
    "            self.layer2score[label]['std'] = torch.zeros_like(std_b)\n",
    "            self.layer2score[label]['outer'] = torch.zeros_like(outer_b)\n",
    "        \n",
    "        self.layer2score[label]['mean'] += mean_b / n\n",
    "        self.layer2score[label]['std'] += std_b / n\n",
    "        self.layer2score[label]['outer'] += outer_b / n\n",
    "\n",
    "    def get_intermediate_scores(self, model, dataloader, num_passes=1, num_steps=None):\n",
    "        n = len(dataloader) * num_passes\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "        \n",
    "        for _ in range(num_passes):\n",
    "            for i, (images, _) in enumerate(tqdm(dataloader)):\n",
    "                if num_steps is not None and i >= num_steps: break\n",
    "                inputs = images.float().to(DEVICE)\n",
    "                out = F.relu(model.bn1(model.conv1(inputs)))\n",
    "                out = self.get_layer_intermediates(out, model.layer1, 'layer1', n)\n",
    "                out = self.get_layer_intermediates(out, model.layer2, 'layer2', n)\n",
    "                out = self.get_layer_intermediates(out, model.layer3, 'layer3', n)\n",
    "        \n",
    "        for layer, cov in tqdm(self.layer2cov.items()):\n",
    "            mean = cov['mean']\n",
    "            std = cov['std']\n",
    "            outer = cov['outer']\n",
    "            cov = outer - torch.outer(mean, mean)\n",
    "            cov /= (torch.outer(std, std) + 1e-4)\n",
    "            torch.diagonal(cov)[:] = -torch.inf\n",
    "            self.layer2score[layer] = cov\n",
    "        \n",
    "\n",
    "class MagnitudeScoring(ScoringBase):\n",
    "    def __init__(self):\n",
    "        super(MagnitudeScoring, self).__init__()\n",
    "        ScoringBase.__init__(self)\n",
    "    \n",
    "    def batch_update_scores(self, label, out, n):\n",
    "        out = out.reshape(out.shape[0], out.shape[1], -1).permute(0, 2, 1)\n",
    "        out = out.reshape(-1, out.shape[2]).double()\n",
    "        mean = (out.mean(dim=0) / n).detach().cpu()\n",
    "        if self.layer2score[label] is None:\n",
    "            self.layer2score[label] = torch.zeros_like(mean)\n",
    "        self.layer2score[label] += mean\n",
    "    \n",
    "    def get_layer_intermediates(self, batch, layer, label, n):\n",
    "        for i, inter in enumerate(list(layer)):\n",
    "            out = self.output_pattern(inter, batch)\n",
    "            self.batch_update_scores(label+f'.{i}', out=out, n=n)\n",
    "            batch = inter(batch)\n",
    "        self.batch_update_scores(label, out=batch, n=n)\n",
    "        return batch\n",
    "    \n",
    "    def get_intermediate_scores(self, model, dataloader, num_passes=1, num_steps=None):\n",
    "        n = len(dataloader) * num_passes\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "        \n",
    "        for _ in range(num_passes):\n",
    "            for i, (images, _) in enumerate(tqdm(dataloader)):\n",
    "                if num_steps is not None and i >= num_steps: break\n",
    "                inputs = images.float().to(DEVICE)\n",
    "                out = F.relu(model.bn1(model.conv1(inputs)))\n",
    "                out = self.get_layer_intermediates(out, model.layer1, 'layer1', n)\n",
    "                out = self.get_layer_intermediates(out, model.layer2, 'layer2', n)\n",
    "                out = self.get_layer_intermediates(out, model.layer3, 'layer3', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a517092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinglePassResNet20(object):\n",
    "    def __init__(self, model):\n",
    "        super(SinglePassResNet20, self).__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    def prepare_model(self, layer2score, score2update_modules, transformer, precomputed_merges=None):\n",
    "        layer2merges = {}\n",
    "        for layer, score in layer2score.items():\n",
    "            if precomputed_merges is None:\n",
    "                merge, unmerge = transformer(score)\n",
    "                layer2merges[layer] = (merge.to(score.device), unmerge.to(score.device))\n",
    "            else:\n",
    "                layer2merges[layer] = precomputed_merges[layer]\n",
    "                merge, unmerge = precomputed_merges[layer]\n",
    "            output_modules = self.get_model_attributes(score2update_modules[layer]['output'])\n",
    "            input_modules = self.get_model_attributes(score2update_modules[layer]['input'])\n",
    "            self.transform_output_space(merge, output_modules)\n",
    "            self.transform_input_space(unmerge, input_modules)\n",
    "        \n",
    "        return layer2merges\n",
    "    \n",
    "    def get_model_attributes(self, components):\n",
    "        parameter_tuples = []\n",
    "        \n",
    "        for component in components['non_bn']:\n",
    "            edges = component.split('.')\n",
    "            node = getattr(self.model, edges[0])\n",
    "            for edge in edges[1:]:\n",
    "                node = getattr(node, edge)\n",
    "            parameter_tuples.append(node.weight)\n",
    "        \n",
    "        if 'bn' in components:\n",
    "            for component in components['bn']:\n",
    "                edges = component.split('.')\n",
    "                node = getattr(self.model, edges[0])\n",
    "                for edge in edges[1:]:\n",
    "                    node = getattr(node, edge)\n",
    "                parameter_tuples.append(node.weight)\n",
    "                parameter_tuples.append(node.bias)\n",
    "                parameter_tuples.append(node.running_mean)\n",
    "                parameter_tuples.append(node.running_var)\n",
    "        return parameter_tuples\n",
    "    \n",
    "    def transform_output_space(self, merge, list_of_modules):\n",
    "        for module in list_of_modules:\n",
    "            if len(module.shape) == 4:\n",
    "                transformed_module = torch.einsum('ab,bcde->acde', merge.to(module.device), module)\n",
    "            else:\n",
    "                transformed_module = merge.to(module.device) @ module\n",
    "            module.data = transformed_module\n",
    "\n",
    "    def transform_input_space(self, unmerge, list_of_modules):\n",
    "        for module in list_of_modules:\n",
    "            if len(module.shape) == 4:\n",
    "                module.data = torch.einsum('abcd,be->aecd', module, unmerge.to(module.device))\n",
    "            else:\n",
    "                module.data = (module @ unmerge.to(module.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc7bbd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_layers = [\n",
    "    'layer1.0',\n",
    "    'layer1.1',\n",
    "    'layer1.2',\n",
    "    'layer2.0',\n",
    "    'layer2.1',\n",
    "    'layer2.2',\n",
    "    'layer3.0',\n",
    "    'layer3.1',\n",
    "    'layer3.2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "316ca44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov2update_modules = {\n",
    "    'layer1': {\n",
    "        'output': {\n",
    "            'non_bn': ['conv1', 'layer1.0.conv2', 'layer1.1.conv2', 'layer1.2.conv2'],\n",
    "            'bn': ['bn1', 'layer1.0.bn2', 'layer1.1.bn2', 'layer1.2.bn2']\n",
    "        },\n",
    "        'input': {\n",
    "            'non_bn': ['layer1.0.conv1', 'layer1.1.conv1', 'layer1.2.conv1', \n",
    "                     'layer2.0.conv1', 'layer2.0.shortcut.0'],\n",
    "        }\n",
    "    },\n",
    "    'layer2': {\n",
    "        'output': {\n",
    "            'non_bn': ['layer2.0.conv2', 'layer2.1.conv2', 'layer2.2.conv2', 'layer2.0.shortcut.0'],\n",
    "            'bn': ['layer2.0.bn2', 'layer2.1.bn2', 'layer2.2.bn2', 'layer2.0.shortcut.1']\n",
    "        },\n",
    "        'input': {\n",
    "            'non_bn': ['layer2.1.conv1', 'layer2.2.conv1', 'layer3.0.conv1', 'layer3.0.shortcut.0']\n",
    "        }\n",
    "    },\n",
    "    'layer3': {\n",
    "        'output': {\n",
    "            'non_bn': ['layer3.0.conv2', 'layer3.1.conv2', 'layer3.2.conv2', 'layer3.0.shortcut.0'],\n",
    "            'bn': ['layer3.0.bn2', 'layer3.1.bn2', 'layer3.2.bn2', 'layer3.0.shortcut.1']\n",
    "        },\n",
    "        'input': {\n",
    "            'non_bn': ['layer3.1.conv1', 'layer3.2.conv1', 'linear']\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "for layer_name in intermediate_layers:\n",
    "    cov2update_modules[layer_name] = {\n",
    "        'output': {\n",
    "            'non_bn': [f'{layer_name}.conv1'],\n",
    "            'bn': [f'{layer_name}.bn1']\n",
    "        },\n",
    "        'input': {\n",
    "            'non_bn': [f'{layer_name}.conv2']\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d78d9732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9558\n",
      "0.9726\n"
     ]
    }
   ],
   "source": [
    "model0 = resnet20(w=4, text_head=True).to(DEVICE)\n",
    "model1 = resnet20(w=4, text_head=True).to(DEVICE)\n",
    "load_model(model0, f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}')\n",
    "load_model(model1, f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}')\n",
    "print(evaluate_texthead(model0, test_loader1, class_vecs1, remap_class_idxs=class_idxs))\n",
    "print(evaluate_texthead(model1, test_loader2, class_vecs2, remap_class_idxs=class_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25b86747",
   "metadata": {},
   "outputs": [],
   "source": [
    "spr20 = SinglePassResNet20(model=model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa5f3997",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = MagnitudeScoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d0260bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.67it/s]\n"
     ]
    }
   ],
   "source": [
    "scorer.get_intermediate_scores(\n",
    "    spr20.model,\n",
    "    train_aug_loader,\n",
    "    num_passes=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d6bbf2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['layer1.0', 'layer1.1', 'layer1.2', 'layer1', 'layer2.0', 'layer2.1', 'layer2.2', 'layer2', 'layer3.0', 'layer3.1', 'layer3.2', 'layer3'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.get_layer2score().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6c2bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = .9\n",
    "argmin_prune_wrapper = lambda x: prune_tensors_by_minimums(x, r=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "059c88ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "layer2merges_ = spr20.prepare_model(\n",
    "    layer2score=scorer.get_layer2score(), \n",
    "    score2update_modules=cov2update_modules, \n",
    "    transformer=argmin_prune_wrapper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4c3d0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9378\n"
     ]
    }
   ],
   "source": [
    "reset_bn_stats(spr20.model, loader=train_aug_loader)\n",
    "print(evaluate_texthead(spr20.model, test_loader1, class_vecs1, remap_class_idxs=class_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b12b61a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
