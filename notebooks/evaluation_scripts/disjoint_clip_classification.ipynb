{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e82daff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc6c677b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam, lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sys import platform\n",
    "\n",
    "DEVICE = 'mps' if platform == 'darwin' else 'cuda'\n",
    "if DEVICE == 'mps':\n",
    "    DOWNLOAD_PATH = '/Users/georgestoica/Downloads' \n",
    "else:\n",
    "    DOWNLOAD_PATH = '/srv/share/gstoica3/checkpoints/REPAIR/'\n",
    "    \n",
    "torch.autograd.set_grad_enabled(False)\n",
    "\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c4fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnets import resnet20\n",
    "from matching_algs import *\n",
    "from model_matchings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad5a5f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, i):\n",
    "    sd = model.state_dict()\n",
    "    path = os.path.join(\n",
    "        # '/Users/georgestoica/Downloads',\n",
    "        DOWNLOAD_PATH,\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def load_model(model, i):\n",
    "    path = os.path.join(\n",
    "        # '/Users/georgestoica/Downloads',\n",
    "        DOWNLOAD_PATH,\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    sd = torch.load(path, map_location=torch.device(DEVICE))\n",
    "    model.load_state_dict(sd)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5b319b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_info = {\n",
    "    'dir': '/nethome/gstoica3/research/pytorch-cifar100/data/cifar-100-python',\n",
    "    'classes1': np.arange(50),\n",
    "    'classes2': np.arange(50, 100),\n",
    "    'num_classes': 100,\n",
    "    'split_classes': 50,\n",
    "    'wrapper': torchvision.datasets.CIFAR100\n",
    "}\n",
    "\n",
    "cifar10_info = {\n",
    "    'dir': '/tmp',\n",
    "    'classes1': np.array([3, 2, 0, 6, 4]),\n",
    "    'classes2': np.array([5, 7, 9, 8, 1]),\n",
    "    'num_classes': 10,\n",
    "    'split_classes': 5,\n",
    "    'wrapper': torchvision.datasets.CIFAR10\n",
    "}\n",
    "\n",
    "ds_info = cifar10_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb29e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /tmp/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 170498071/170498071 [00:01<00:00, 87824910.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/cifar-10-python.tar.gz to /tmp\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CIFAR_MEAN = [125.307, 122.961, 113.8575]\n",
    "CIFAR_STD = [51.5865, 50.847, 51.255]\n",
    "normalize = T.Normalize(np.array(CIFAR_MEAN)/255, np.array(CIFAR_STD)/255)\n",
    "denormalize = T.Normalize(-np.array(CIFAR_MEAN)/np.array(CIFAR_STD), 255/np.array(CIFAR_STD))\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "train_dset = ds_info['wrapper'](root=ds_info['dir'], train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "test_dset = ds_info['wrapper'](root=ds_info['dir'], train=False,\n",
    "                                        download=True, transform=test_transform)\n",
    "\n",
    "train_aug_loader = torch.utils.data.DataLoader(train_dset, batch_size=500, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=500, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf8d2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:14, 3371.31it/s]\n",
      "50000it [00:14, 3406.61it/s]\n",
      "10000it [00:01, 5159.86it/s]\n",
      "10000it [00:01, 5208.17it/s]\n"
     ]
    }
   ],
   "source": [
    "train_aug_loader = torch.utils.data.DataLoader(train_dset, batch_size=500, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=500, shuffle=False, num_workers=8)\n",
    "\n",
    "model1_classes= ds_info['classes1']#np.array([3, 2, 0, 6, 4])\n",
    "model2_classes = ds_info['classes2']\n",
    "\n",
    "valid_examples1 = [i for i, (_, label) in tqdm(enumerate(train_dset)) if label in model1_classes]\n",
    "valid_examples2 = [i for i, (_, label) in tqdm(enumerate(train_dset)) if label in model2_classes]\n",
    "\n",
    "assert len(set(valid_examples1).intersection(set(valid_examples2))) == 0, 'sets should be disjoint'\n",
    "\n",
    "train_aug_loader1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dset, valid_examples1), batch_size=500, shuffle=True, num_workers=8\n",
    ")\n",
    "train_aug_loader2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dset, valid_examples2), batch_size=500, shuffle=True, num_workers=8\n",
    ")\n",
    "\n",
    "test_valid_examples1 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model1_classes]\n",
    "test_valid_examples2 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model2_classes]\n",
    "\n",
    "test_loader1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dset, test_valid_examples1), batch_size=500, shuffle=False, num_workers=8\n",
    ")\n",
    "test_loader2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dset, test_valid_examples2), batch_size=500, shuffle=False, num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "468b1405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 1, 0, 4, 0, 3, 1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "class_idxs = np.zeros(ds_info['num_classes'], dtype=int)\n",
    "class_idxs[model1_classes] = np.arange(ds_info['split_classes'])\n",
    "class_idxs[model2_classes] = np.arange(ds_info['split_classes'])\n",
    "class_idxs = torch.from_numpy(class_idxs)\n",
    "print(class_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e4d47ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates accuracy\n",
    "def evaluate_texthead(model, loader, class_vectors, remap_class_idxs=None, return_confusion=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    totals = [0] * class_vectors.shape[0]\n",
    "    corrects = [0] * class_vectors.shape[0]\n",
    "    \n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            encodings = model(inputs.to(DEVICE))\n",
    "            normed_encodings = encodings / encodings.norm(dim=-1, keepdim=True)\n",
    "            outputs = normed_encodings @ class_vectors.T\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            if remap_class_idxs is not None:\n",
    "                correct += (remap_class_idxs[labels].to(DEVICE) == pred).sum().item()\n",
    "            else:\n",
    "                for gt, p in zip(labels, pred):\n",
    "                    totals[gt] += 1\n",
    "                    \n",
    "                    if gt == p:\n",
    "                        correct += 1\n",
    "                        corrects[gt] += 1\n",
    "                \n",
    "            total += inputs.shape[0]\n",
    "    if return_confusion:\n",
    "        return correct / sum(totals), list(map(lambda a: a[0] / a[1], zip(corrects, totals)))\n",
    "    else:\n",
    "        return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f2c3e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in test_dset.classes]).to(DEVICE)\n",
    "model, preprocess = clip.load('ViT-B/32', DEVICE)\n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "class_vecs1 = text_features[model1_classes]\n",
    "class_vecs2 = text_features[model2_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a68cb316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9558\n",
      "0.9726\n"
     ]
    }
   ],
   "source": [
    "model1 = resnet20(w=4, text_head=True).to(DEVICE)\n",
    "model2 = resnet20(w=4, text_head=True).to(DEVICE)\n",
    "load_model(model1, f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}')\n",
    "load_model(model2, f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}')\n",
    "\n",
    "print(evaluate_texthead(model1, test_loader1, class_vecs1, remap_class_idxs=class_idxs))\n",
    "print(evaluate_texthead(model2, test_loader2, class_vecs2, remap_class_idxs=class_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c517eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_tensors_exact_bipartite_abs(\n",
    "    hull_tensor,\n",
    "    interleave=False,\n",
    "    random_perm=False\n",
    "):\n",
    "    hull_normed = hull_tensor / hull_tensor.norm(dim=-1, keepdim=True)\n",
    "    O = hull_tensor.shape[0]\n",
    "    remainder = int(hull_tensor.shape[0] * (1-r))\n",
    "    bound = O - remainder\n",
    "    sims = hull_normed @ hull_normed.transpose(-1, -2)\n",
    "    sims_abs = sims.abs()\n",
    "    torch.diagonal(sims_abs)[:] = -torch.inf\n",
    "    permutation_matrix = torch.zeros((O, O - bound), device=sims.device)\n",
    "    for i in range(bound):\n",
    "        best_idx = sims_abs.view(-1).argmax()\n",
    "        row_idx = best_idx % sims.shape[1]\n",
    "        col_idx = best_idx // sims.shape[1]\n",
    "        permutation_matrix[row_idx, i] = 1\n",
    "        permutation_matrix[col_idx, i] = 1 * sims[row_idx, col_idx].sign()\n",
    "        sims_abs[row_idx] = -torch.inf\n",
    "        sims_abs[col_idx] = -torch.inf\n",
    "        sims_abs[:, row_idx] = -torch.inf\n",
    "        sims_abs[:, col_idx] = -torch.inf\n",
    "    \n",
    "    unused = (sims_abs.max(-1)[0] > -torch.inf).to(torch.int).nonzero().view(-1)\n",
    "    for i in range(bound, O-bound):\n",
    "        permutation_matrix[unused[i-bound], i] = 1\n",
    "    merge = permutation_matrix / (permutation_matrix.abs().sum(dim=0, keepdim=True) + 1e-5)\n",
    "    unmerge = permutation_matrix\n",
    "    return merge.T, unmerge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c58b7d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_tensors_exact_bipartite_dist(\n",
    "    hull_tensor,\n",
    "    interleave=False,\n",
    "    random_perm=False\n",
    "):\n",
    "    cdists = torch.cdist(hull_tensor, hull_tensor)\n",
    "#     hull_normed = hull_tensor / hull_tensor.norm(dim=-1, keepdim=True)\n",
    "    O = hull_tensor.shape[0]\n",
    "    remainder = int(hull_tensor.shape[0] * (1-r))\n",
    "    bound = O - remainder\n",
    "#     sims = hull_normed @ hull_normed.transpose(-1, -2)\n",
    "    sims = -cdists\n",
    "    torch.diagonal(sims)[:] = -torch.inf\n",
    "    permutation_matrix = torch.zeros((O, O - bound), device=sims.device)\n",
    "    for i in range(bound):\n",
    "        best_idx = sims.view(-1).argmax()\n",
    "        row_idx = best_idx % sims.shape[1]\n",
    "        col_idx = best_idx // sims.shape[1]\n",
    "        permutation_matrix[row_idx, i] = 1\n",
    "        permutation_matrix[col_idx, i] = 1\n",
    "        sims[row_idx] = -torch.inf\n",
    "        sims[col_idx] = -torch.inf\n",
    "        sims[:, row_idx] = -torch.inf\n",
    "        sims[:, col_idx] = -torch.inf\n",
    "    \n",
    "    unused = (sims.max(-1)[0] > -torch.inf).to(torch.int).nonzero().view(-1)\n",
    "    for i in range(bound, O-bound):\n",
    "        permutation_matrix[unused[i-bound], i] = 1\n",
    "    merge = permutation_matrix / (permutation_matrix.sum(dim=0, keepdim=True) + 1e-5)\n",
    "    unmerge = permutation_matrix\n",
    "    return merge.T, unmerge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da6ed9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_tensors_exact_bipartite(\n",
    "    hull_tensor,\n",
    "    interleave=False,\n",
    "    random_perm=False\n",
    "):\n",
    "    hull_normed = hull_tensor / hull_tensor.norm(dim=-1, keepdim=True)\n",
    "    O = hull_tensor.shape[0]\n",
    "    remainder = int(hull_tensor.shape[0] * (1-r))\n",
    "    bound = O - remainder\n",
    "    sims = hull_normed @ hull_normed.transpose(-1, -2)\n",
    "    torch.diagonal(sims)[:] = -torch.inf\n",
    "    permutation_matrix = torch.zeros((O, O - bound), device=sims.device)\n",
    "    merged_sims = []\n",
    "    for i in range(bound):\n",
    "        best_idx = sims.view(-1).argmax()\n",
    "        row_idx = best_idx % sims.shape[1]\n",
    "        col_idx = best_idx // sims.shape[1]\n",
    "        permutation_matrix[row_idx, i] = 1\n",
    "        permutation_matrix[col_idx, i] = 1\n",
    "        sims[row_idx] = -torch.inf\n",
    "        sims[col_idx] = -torch.inf\n",
    "        sims[:, row_idx] = -torch.inf\n",
    "        sims[:, col_idx] = -torch.inf\n",
    "        merged_sims.append(sims.view(-1).max().cpu().numpy().tolist())\n",
    "    \n",
    "    unused = (sims.max(-1)[0] > -torch.inf).to(torch.int).nonzero().view(-1)\n",
    "    for i in range(bound, O-bound):\n",
    "        permutation_matrix[unused[i-bound], i] = 1\n",
    "    merge = permutation_matrix / (permutation_matrix.sum(dim=0, keepdim=True) + 1e-5)\n",
    "    unmerge_a, unmerge_b = permutation_matrix.chunk(2, dim=0)\n",
    "    unmerge_a = unmerge_a / (unmerge_a.sum(dim=0) + 1e-5)\n",
    "    unmerge_b = unmerge_b / (unmerge_b.sum(dim=0) + 1e-5)\n",
    "    unmerge = concat_mats((unmerge_a, unmerge_b), dim=0)\n",
    "#     print(np.round(merged_sims, 3))\n",
    "    return merge.T, unmerge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53cad3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_tensors_PAN(\n",
    "    hull_tensor,\n",
    "    interleave=False,\n",
    "    random_perm=False,\n",
    "):\n",
    "    hull_normed = hull_tensor / hull_tensor.norm(dim=-1, keepdim=True)\n",
    "    O = hull_tensor.shape[0]\n",
    "    remainder = int(hull_tensor.shape[0] * (1-r))\n",
    "    bound = O - remainder\n",
    "    sims = hull_normed @ hull_normed.transpose(-1, -2)\n",
    "    \n",
    "    hull_a, hull_b = hull_tensor.chunk(2, dim=0)\n",
    "    c_aa = hull_a.any(dim=0, keepdim=True).float()\n",
    "    c_bb = hull_b.any(dim=0, keepdim=True).float()\n",
    "    c_ab = (c_aa * c_bb)\n",
    "    \n",
    "    hull_a = F.normalize(hull_a * c_ab, dim=-1)\n",
    "    hull_b = F.normalize(hull_b * c_ab, dim=-1)\n",
    "    sims_ab = hull_a @ hull_b.transpose(-1, -2)\n",
    "    half_O = O // 2\n",
    "    sims[half_O:, :half_O] = sims_ab\n",
    "    sims[:half_O, half_O:] = sims_ab.T\n",
    "    \n",
    "    torch.diagonal(sims)[:] = -torch.inf\n",
    "    permutation_matrix = torch.zeros((O, O - bound), device=sims.device)\n",
    "    merged_sims = []\n",
    "    \n",
    "    for i in range(bound):\n",
    "        if i % 3 in {0}: # Get AB permutation\n",
    "            temp_sims = sims.clone()\n",
    "            temp_sims[:half_O, :half_O] = -torch.inf\n",
    "            temp_sims[half_O:, half_O:] = -torch.inf\n",
    "        elif i % 3 in {1}: # Get AA permutation\n",
    "            temp_sims = sims.clone()\n",
    "            temp_sims[half_O:] = -torch.inf\n",
    "            temp_sims[:half_O, half_O:] = -torch.inf\n",
    "        elif i % 3 in {2}: # Get BB permutation\n",
    "            temp_sims = sims.clone()\n",
    "            temp_sims[:, :half_O] = -torch.inf\n",
    "            temp_sims[:half_O, half_O:] = -torch.inf\n",
    "            \n",
    "        best_idx = temp_sims.view(-1).argmax()\n",
    "        row_idx = best_idx % sims.shape[1]\n",
    "        col_idx = best_idx // sims.shape[1]\n",
    "        permutation_matrix[row_idx, i] = 1\n",
    "        permutation_matrix[col_idx, i] = 1\n",
    "        sims[row_idx] = -torch.inf\n",
    "        sims[col_idx] = -torch.inf\n",
    "        sims[:, row_idx] = -torch.inf\n",
    "        sims[:, col_idx] = -torch.inf\n",
    "        merged_sims.append(sims.view(-1).max().cpu().numpy().tolist())\n",
    "    \n",
    "    unused = (sims.max(-1)[0] > -torch.inf).to(torch.int).nonzero().view(-1)\n",
    "    for i in range(bound, O-bound):\n",
    "        permutation_matrix[unused[i-bound], i] = 1\n",
    "    merge = permutation_matrix / (permutation_matrix.sum(dim=0, keepdim=True) + 1e-5)\n",
    "    \n",
    "    unmerge_a, unmerge_b = permutation_matrix.chunk(2, dim=0)\n",
    "    unmerge_a = unmerge_a / (unmerge_a.sum(dim=0) + 1e-5)\n",
    "    unmerge_b = unmerge_b / (unmerge_b.sum(dim=0) + 1e-5)\n",
    "    unmerge = concat_mats((unmerge_a, unmerge_b), dim=0)\n",
    "\n",
    "    return merge.T, unmerge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f91d113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_transform_differences(old_transforms, current_transforms):\n",
    "    if len(old_transforms) == 0:\n",
    "        return {}\n",
    "    transform2norm = {}\n",
    "    for key, old_transform in old_transforms.items():\n",
    "        current_transform = current_transforms[key]\n",
    "        old_align = old_transform.output_align\n",
    "        new_align = current_transform.output_align\n",
    "        cost = old_align.T @ new_align\n",
    "        row_ind, col_idx = scipy.optimize.linear_sum_assignment(cost.detach().cpu().numpy())\n",
    "        permutation = torch.eye(new_align.shape[1], device=old_align.device)[col_idx]\n",
    "        aligned_new = new_align @ permutation\n",
    "#         pdb.set_trace()\n",
    "        norm = torch.norm(old_align - aligned_new).cpu().numpy()\n",
    "        transform2norm[key] = norm\n",
    "    return transform2norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e9d5a78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/nethome/gstoica3/research/REPAIR/notebooks/evaluation_scripts/model_matchings.py\u001b[0m(105)\u001b[0;36mmerge_hidden_conv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    103 \u001b[0;31m        \u001b[0mc_ab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    104 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 105 \u001b[0;31m        \u001b[0mc_flat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc_ab\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_align\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mab_input_aligned_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc_ab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    106 \u001b[0;31m\u001b[0;31m#         print(f\"{prefix} joint AB: {c_ab.sum()}/{c_ab.shape[0]}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    107 \u001b[0;31m\u001b[0;31m#         if prefix == 'linear':\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c_ab.shape\n",
      "torch.Size([64])\n",
      "ipdb> c_flat.shape\n",
      "torch.Size([64, 576])\n",
      "ipdb> c_ab.sum()\n",
      "tensor(22, device='cuda:0')\n",
      "ipdb> c_flat[c_ab].shape\n",
      "torch.Size([22, 576])\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "r = 0.5\n",
    "fn = match_tensors_PAN\n",
    "ignore_mismatches=True\n",
    "set_r(r)\n",
    "set_match_fn(fn)\n",
    "\n",
    "match_tensors = match_wrapper(\n",
    "    fn, \n",
    "    backend_alg=match_tensors_PAN_incomplete,\n",
    "    interleave=True, \n",
    "    random_perm=False\n",
    ")\n",
    "layer_transform = lambda : LayerTransform(normalize_tensors=True, tensor_merge_type='concat')\n",
    "old_state_dict = {}\n",
    "state_dict = {}\n",
    "old_transforms = defaultdict(lambda: layer_transform())\n",
    "new_transforms = defaultdict(lambda: layer_transform())\n",
    "modelc = resnet20(w=4, text_head=True).to(DEVICE)\n",
    "accuracies = []\n",
    "steps = []\n",
    "distances = []\n",
    "best_info = {'acc': 0., 'dist': np.inf}\n",
    "step = 1\n",
    "is_converged = False\n",
    "prev_distance = np.inf\n",
    "same_window = 5\n",
    "same_span = 0\n",
    "while not is_converged:\n",
    "# for step in tqdm(range(121)):\n",
    "    old_transforms = new_transforms\n",
    "    old_state_dict = deepcopy(state_dict)\n",
    "    new_transforms = merge_resnet20(\n",
    "        state_dict, \n",
    "        model1, \n",
    "        model2, \n",
    "        transforms=deepcopy(old_transforms),\n",
    "        concat_head=False,\n",
    "        ignore_mismatches=ignore_mismatches\n",
    "    )\n",
    "    if step == 0:\n",
    "        original_computation = deepcopy(new_transforms)\n",
    "\n",
    "    transform2dist = find_transform_differences(old_transforms, new_transforms)\n",
    "    avg_distance = np.mean(list(transform2dist.values()))\n",
    "    \n",
    "    if abs(avg_distance - prev_distance) <= 1e-5:\n",
    "        same_span += 1\n",
    "    else:\n",
    "        same_span = 0\n",
    "    if same_span >= same_window:\n",
    "        is_converged = True\n",
    "    print(step, avg_distance)\n",
    "    prev_distance = avg_distance\n",
    "#     is_converged = True\n",
    "    if is_converged or step >= 100:\n",
    "        break\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1af42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "04c0412c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3c234100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4504"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelc.load_state_dict(state_dict)\n",
    "reset_bn_stats(modelc, loader=train_aug_loader)\n",
    "acc, perclass_acc = evaluate_texthead(\n",
    "    modelc, test_loader, class_vectors=text_features, return_confusion=True\n",
    ")\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cd30e758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.873, 0.0, 0.887, 0.847, 0.912, 0.0, 0.947, 0.0, 0.038, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(perclass_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884023f9",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6974e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_aligns = {k: new_transforms[k].output_align.chunk(2, dim=-1) for k in new_transforms.keys()}\n",
    "\n",
    "input_aligns = {k: new_transforms[k].next_input_align.chunk(2, dim=-1) for k in new_transforms.keys() if new_transforms[k].next_input_align is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb78b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "key2merges = {}\n",
    "for key, parts in output_aligns.items():\n",
    "    A, B = parts\n",
    "    A_merges = (A.sum(1)*2).abs().ceil().to(torch.int).bincount()[1:]\n",
    "    B_merges = (B.sum(1)*2).abs().ceil().to(torch.int).bincount()[1:]\n",
    "    merges = {}\n",
    "    if len(A_merges) == 2:\n",
    "        merges['A->A'] = A_merges[1].cpu().numpy()\n",
    "    if len(B_merges) == 2:\n",
    "        merges['B->B'] = B_merges[1].cpu().numpy()\n",
    "    try:\n",
    "        merges['A^B'] = A_merges[0].cpu().numpy()\n",
    "    except:\n",
    "        merges['A^B'] = B_merges[0].cpu().numpy()\n",
    "    key2merges[key] = merges\n",
    "\n",
    "key2merges_inp = {}\n",
    "for key, parts in input_aligns.items():\n",
    "    A, B = parts\n",
    "    A_merges = (A.sum(1)).abs().ceil().to(torch.int).bincount()[1:]\n",
    "    B_merges = (B.sum(1)).abs().ceil().to(torch.int).bincount()[1:]\n",
    "    merges = {}\n",
    "    if len(A_merges) == 2:\n",
    "        merges['A->A'] = A_merges[1].cpu().numpy()\n",
    "    if len(B_merges) == 2:\n",
    "        merges['B->B'] = B_merges[1].cpu().numpy()\n",
    "    merges['A^B'] = A_merges[0].cpu().numpy()\n",
    "    key2merges_inp[key] = merges\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9e6eabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 {'A->A': array(21), 'B->B': array(21), 'A^B': array(22)}\n",
      "block1.0 {'A->A': array(21), 'B->B': array(21), 'A^B': array(22)}\n",
      "block1.1 {'A->A': array(21), 'B->B': array(21), 'A^B': array(22)}\n",
      "block1.2 {'A->A': array(21), 'B->B': array(21), 'A^B': array(22)}\n",
      "block2.0 {'A->A': array(43), 'B->B': array(42), 'A^B': array(43)}\n",
      "block2 {'A->A': array(43), 'B->B': array(42), 'A^B': array(43)}\n",
      "block2.1 {'A->A': array(43), 'B->B': array(42), 'A^B': array(43)}\n",
      "block2.2 {'A->A': array(43), 'B->B': array(42), 'A^B': array(43)}\n",
      "block3.0 {'A->A': array(85), 'B->B': array(85), 'A^B': array(86)}\n",
      "block3 {'A->A': array(85), 'B->B': array(85), 'A^B': array(86)}\n",
      "block3.1 {'A->A': array(85), 'B->B': array(85), 'A^B': array(86)}\n",
      "block3.2 {'A->A': array(85), 'B->B': array(85), 'A^B': array(86)}\n",
      "linear {'A^B': array(512)}\n"
     ]
    }
   ],
   "source": [
    "for key, merges in key2merges.items():\n",
    "    print(key, merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "904ad1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 {'A^B': array(64)}\n",
      "block1.0 {'A^B': array(64)}\n",
      "block1.1 {'A^B': array(64)}\n",
      "block1.2 {'A^B': array(64)}\n",
      "block2.0 {'B->B': array(1), 'A^B': array(128)}\n",
      "block2 {'B->B': array(1), 'A^B': array(128)}\n",
      "block2.1 {'A^B': array(128)}\n",
      "block2.2 {'B->B': array(1), 'A^B': array(128)}\n",
      "block3.0 {'A^B': array(256)}\n",
      "block3 {'A^B': array(256)}\n",
      "block3.1 {'A^B': array(256)}\n",
      "block3.2 {'A^B': array(256)}\n"
     ]
    }
   ],
   "source": [
    "for key, merges in key2merges_inp.items():\n",
    "    print(key, merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "15130bde",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000], device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transforms['block1.0'].next_input_align.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9cd7ad78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000], device='cuda:0')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_transforms['conv1'].output_align[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61642ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
