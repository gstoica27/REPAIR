{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256b885f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam, lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sys import platform\n",
    "\n",
    "DEVICE = 'mps' if platform == 'darwin' else 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d7eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a983d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, i):\n",
    "    sd = model.state_dict()\n",
    "    path = os.path.join(\n",
    "        # '/Users/georgestoica/Downloads',\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def load_model(model, i):\n",
    "    path = os.path.join(\n",
    "        # '/Users/georgestoica/Downloads',\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    sd = torch.load(path, map_location=torch.device(DEVICE))\n",
    "    model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1028485",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_info = {\n",
    "    'dir': '/nethome/gstoica3/research/pytorch-cifar100/data/cifar-100-python',\n",
    "    'classes1': np.arange(50),\n",
    "    'classes2': np.arange(50, 100),\n",
    "    'num_classes': 100,\n",
    "    'split_classes': 50,\n",
    "    'wrapper': torchvision.datasets.CIFAR100\n",
    "}\n",
    "\n",
    "cifar10_info = {\n",
    "    'dir': '/tmp',\n",
    "    'classes1': np.array([3, 2, 0, 6, 4]),\n",
    "    'classes2': np.array([5, 7, 9, 8, 1]),\n",
    "    'num_classes': 10,\n",
    "    'split_classes': 5,\n",
    "    'wrapper': torchvision.datasets.CIFAR10\n",
    "}\n",
    "\n",
    "ds_info = cifar100_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9cd3aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CIFAR_MEAN = [125.307, 122.961, 113.8575]\n",
    "CIFAR_STD = [51.5865, 50.847, 51.255]\n",
    "normalize = T.Normalize(np.array(CIFAR_MEAN)/255, np.array(CIFAR_STD)/255)\n",
    "denormalize = T.Normalize(-np.array(CIFAR_MEAN)/np.array(CIFAR_STD), 255/np.array(CIFAR_STD))\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "train_dset = ds_info['wrapper'](root=ds_info['dir'], train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "test_dset = ds_info['wrapper'](root=ds_info['dir'], train=False,\n",
    "                                        download=True, transform=test_transform)\n",
    "\n",
    "train_aug_loader = torch.utils.data.DataLoader(train_dset, batch_size=500, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=500, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c1172d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:13, 3572.23it/s]\n",
      "50000it [00:14, 3569.48it/s]\n",
      "10000it [00:01, 5379.81it/s]\n",
      "10000it [00:01, 5362.74it/s]\n"
     ]
    }
   ],
   "source": [
    "train_aug_loader = torch.utils.data.DataLoader(train_dset, batch_size=500, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=500, shuffle=False, num_workers=8)\n",
    "\n",
    "model1_classes= ds_info['classes1']#np.array([3, 2, 0, 6, 4])\n",
    "model2_classes = ds_info['classes2']\n",
    "\n",
    "valid_examples1 = [i for i, (_, label) in tqdm(enumerate(train_dset)) if label in model1_classes]\n",
    "valid_examples2 = [i for i, (_, label) in tqdm(enumerate(train_dset)) if label in model2_classes]\n",
    "\n",
    "assert len(set(valid_examples1).intersection(set(valid_examples2))) == 0, 'sets should be disjoint'\n",
    "\n",
    "train_aug_loader1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dset, valid_examples1), batch_size=500, shuffle=True, num_workers=8\n",
    ")\n",
    "train_aug_loader2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dset, valid_examples2), batch_size=500, shuffle=True, num_workers=8\n",
    ")\n",
    "\n",
    "test_valid_examples1 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model1_classes]\n",
    "test_valid_examples2 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model2_classes]\n",
    "\n",
    "test_loader1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dset, test_valid_examples1), batch_size=500, shuffle=False, num_workers=8\n",
    ")\n",
    "test_loader2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dset, test_valid_examples2), batch_size=500, shuffle=False, num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff760c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,  0,  1,  2,  3,\n",
      "         4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
      "        22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n",
      "        40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n"
     ]
    }
   ],
   "source": [
    "class_idxs = np.zeros(ds_info['num_classes'], dtype=int)\n",
    "class_idxs[model1_classes] = np.arange(ds_info['split_classes'])\n",
    "class_idxs[model2_classes] = np.arange(ds_info['split_classes'])\n",
    "class_idxs = torch.from_numpy(class_idxs)\n",
    "print(class_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26093947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the train loader with data augmentation as this gives better results\n",
    "def reset_bn_stats(model, epochs=1, loader=train_aug_loader):\n",
    "    # resetting stats to baseline first as below is necessary for stability\n",
    "    for m in model.modules():\n",
    "        if type(m) == nn.BatchNorm2d:\n",
    "            m.momentum = None # use simple average\n",
    "            m.reset_running_stats()\n",
    "    # run a single train epoch with augmentations to recalc stats\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        with torch.no_grad(), autocast():\n",
    "            for images, _ in loader:\n",
    "                output = model(images.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6155682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates accuracy\n",
    "def evaluate_texthead(model, loader, class_vectors, remap_class_idxs=None, return_confusion=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    totals = [0] * class_vectors.shape[0]\n",
    "    corrects = [0] * class_vectors.shape[0]\n",
    "    \n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            encodings = model(inputs.to(DEVICE))\n",
    "            normed_encodings = encodings / encodings.norm(dim=-1, keepdim=True)\n",
    "            outputs = normed_encodings @ class_vectors.T\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            if remap_class_idxs is not None:\n",
    "                correct += (remap_class_idxs[labels].to(DEVICE) == pred).sum().item()\n",
    "            else:\n",
    "                for gt, p in zip(labels, pred):\n",
    "                    totals[gt] += 1\n",
    "                    \n",
    "                    if gt == p:\n",
    "                        correct += 1\n",
    "                        corrects[gt] += 1\n",
    "                \n",
    "            total += inputs.shape[0]\n",
    "    if return_confusion:\n",
    "        return correct / sum(totals), list(map(lambda a: a[0] / a[1], zip(corrects, totals)))\n",
    "    else:\n",
    "        return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d932fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in test_dset.classes]).to(DEVICE)\n",
    "model, preprocess = clip.load('ViT-B/32', DEVICE)\n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "class_vecs1 = text_features[model1_classes]\n",
    "class_vecs2 = text_features[model2_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4753f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnets import resnet20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9c7763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "522206b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given two networks net0, net1 which each output a feature map of shape NxCxWxH\n",
    "# this will reshape both outputs to (N*W*H)xC\n",
    "# and then compute a CxC correlation matrix between the outputs of the two networks\n",
    "def run_corr_matrix_og(net0, net1, epochs=1, norm=True, loader=train_aug_loader):\n",
    "    n = epochs*len(loader)\n",
    "    mean0 = mean1 = std0 = std1 = None\n",
    "    with torch.no_grad():\n",
    "        net0.eval()\n",
    "        net1.eval()\n",
    "        for _ in range(epochs):\n",
    "            for i, (images, _) in enumerate(tqdm(loader)):\n",
    "                img_t = images.float().to(DEVICE)\n",
    "                out0 = net0(img_t)\n",
    "                out0 = out0.reshape(out0.shape[0], out0.shape[1], -1).permute(0, 2, 1)\n",
    "                out0 = out0.reshape(-1, out0.shape[2])#.double()\n",
    "\n",
    "                out1 = net1(img_t)\n",
    "                out1 = out1.reshape(out1.shape[0], out1.shape[1], -1).permute(0, 2, 1)\n",
    "                out1 = out1.reshape(-1, out1.shape[2])#.double()\n",
    "\n",
    "                mean0_b = out0.mean(dim=0)\n",
    "                mean1_b = out1.mean(dim=0)\n",
    "                std0_b = out0.std(dim=0)\n",
    "                std1_b = out1.std(dim=0)\n",
    "                outer_b = (out0.T @ out1) / out0.shape[0]\n",
    "\n",
    "                if i == 0:\n",
    "                    mean0 = torch.zeros_like(mean0_b)\n",
    "                    mean1 = torch.zeros_like(mean1_b)\n",
    "                    std0 = torch.zeros_like(std0_b)\n",
    "                    std1 = torch.zeros_like(std1_b)\n",
    "                    outer = torch.zeros_like(outer_b)\n",
    "                mean0 += mean0_b / n\n",
    "                mean1 += mean1_b / n\n",
    "                std0 += std0_b / n\n",
    "                std1 += std1_b / n\n",
    "                outer += outer_b / n\n",
    "\n",
    "    cov = outer - torch.outer(mean0, mean1)\n",
    "    if norm:\n",
    "        cov = cov / (torch.outer(std0, std1) + 1e-4)\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4234543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given two networks net0, net1 which each output a feature map of shape NxCxWxH\n",
    "# this will reshape both outputs to (N*W*H)xC\n",
    "# and then compute a CxC correlation matrix between the outputs of the two networks\n",
    "def run_corr_matrix(net0, net1, epochs=1, norm=True, loader=train_aug_loader):\n",
    "    n = epochs*len(loader)\n",
    "    mean0 = mean1 = std0 = std1 = None\n",
    "    with torch.no_grad():\n",
    "        net0.eval()\n",
    "        net1.eval()\n",
    "        for _ in range(epochs):\n",
    "            for i, (images, _) in enumerate(tqdm(loader)):\n",
    "                img_t = images.float().to(DEVICE)\n",
    "                out0 = net0(img_t)\n",
    "                out0 = out0.reshape(out0.shape[0], out0.shape[1], -1).permute(0, 2, 1)\n",
    "                out0 = out0.reshape(-1, out0.shape[2]).double()\n",
    "\n",
    "                out1 = net1(img_t)\n",
    "                out1 = out1.reshape(out1.shape[0], out1.shape[1], -1).permute(0, 2, 1)\n",
    "                out1 = out1.reshape(-1, out1.shape[2]).double()\n",
    "\n",
    "                out = torch.cat((out0, out1), dim=-1)\n",
    "                mean_b = out.mean(dim=0)\n",
    "                std0_b = out0.std(dim=0)\n",
    "                std1_b = out1.std(dim=0)\n",
    "                std_b = torch.cat((std0_b, std1_b), dim=-1)\n",
    "                outer_b = (out.T @ out) / out.shape[0]\n",
    "                \n",
    "                if i == 0:\n",
    "                    mean = torch.zeros_like(mean_b)\n",
    "                    std = torch.zeros_like(std_b)\n",
    "                    outer = torch.zeros_like(outer_b)\n",
    "                \n",
    "                mean += mean_b / n\n",
    "                std += std_b / n\n",
    "                outer += outer_b / n\n",
    " \n",
    "    cov = outer - torch.outer(mean, mean)\n",
    "    if norm:\n",
    "        cov = cov / (torch.outer(std, std) + 1e-4)\n",
    "    torch.diagonal(cov)[:] = -torch.inf\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09b46741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cos_sim_matrix(net0, net1, epochs=1, loader=train_aug_loader):\n",
    "    n = epochs*len(loader)\n",
    "    with torch.no_grad():\n",
    "        net0.eval()\n",
    "        net1.eval()\n",
    "        for _ in range(epochs):\n",
    "            for i, (images, _) in enumerate(tqdm(loader)):\n",
    "                img_t = images.float().to(DEVICE)\n",
    "                out0 = net0(img_t)\n",
    "                out0 = out0.reshape(out0.shape[0], out0.shape[1], -1).permute(0, 2, 1)\n",
    "                out0 /= out0.norm(1, keepdim=True)\n",
    "                out0 = out0.reshape(-1, out0.shape[2]).double()\n",
    "\n",
    "                out1 = net1(img_t)\n",
    "                out1 = out1.reshape(out1.shape[0], out1.shape[1], -1).permute(0, 2, 1)\n",
    "                out1 /= out1.norm(1, keepdim=True)\n",
    "                out1 = out1.reshape(-1, out1.shape[2]).double()\n",
    "                \n",
    "                out = torch.cat((out0, out1), dim=-1)\n",
    "                \n",
    "                outer_b = (out.T @ out)# / out.shape[0]\n",
    "                \n",
    "                if i == 0:\n",
    "                    outer = torch.zeros_like(outer_b)\n",
    "                \n",
    "                outer += outer_b\n",
    "    cov = outer\n",
    "    torch.diagonal(cov)[:] = -torch.inf\n",
    "    return cov\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35478e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_tensors_exact_bipartite_cov(\n",
    "    covariance,\n",
    "    r=.5\n",
    "):\n",
    "    O = covariance.shape[0]\n",
    "    O_half = O // 2\n",
    "    remainder = int(O * (1-r))\n",
    "    bound = O - remainder\n",
    "    sims = covariance\n",
    "#     sims[:O_half, :O_half] = -torch.inf\n",
    "#     sims[O_half:, O_half:] = -torch.inf\n",
    "#     sims[:O_half, O_half:] = -torch.inf\n",
    "#     sims[O_half:, :O_half] = -torch.inf\n",
    "\n",
    "#     plot_sims(sims, filename=\"conv1_covar_sorted.png\")\n",
    "    \n",
    "    permutation_matrix = torch.zeros((O, O - bound), device=sims.device)\n",
    "\n",
    "    for i in range(bound):\n",
    "        best_idx = sims.view(-1).argmax()\n",
    "        row_idx = best_idx % sims.shape[1]\n",
    "        col_idx = best_idx // sims.shape[1]\n",
    "        permutation_matrix[row_idx, i] = 1\n",
    "        permutation_matrix[col_idx, i] = 1\n",
    "        sims[row_idx] = -torch.inf\n",
    "        sims[col_idx] = -torch.inf\n",
    "        sims[:, row_idx] = -torch.inf\n",
    "        sims[:, col_idx] = -torch.inf\n",
    "    \n",
    "    unused = (sims.max(-1)[0] > -torch.inf).to(torch.int).nonzero().view(-1)\n",
    "    for i in range(bound, O-bound):\n",
    "        permutation_matrix[unused[i-bound], i] = 1\n",
    "    merge = permutation_matrix / (permutation_matrix.sum(dim=0, keepdim=True) + 1e-5)\n",
    "    unmerge = permutation_matrix\n",
    "    return merge.T, unmerge\n",
    "\n",
    "def match_tensors_permute(\n",
    "    covariance\n",
    "):\n",
    "#     torch.diagonal(covariance)[:] = -torch.inf\n",
    "    corr_mtx_a = covariance.cpu().numpy()\n",
    "    O = corr_mtx_a.shape[0]# // 2\n",
    "    row_ind, col_ind = scipy.optimize.linear_sum_assignment(corr_mtx_a[:O, :O], maximize=True)\n",
    "#     assert (row_ind == np.arange(len(corr_mtx_a))).all()\n",
    "    unmerge = torch.tensor(col_ind).long()\n",
    "    unmerge = torch.eye(O, device=covariance.device)[unmerge]\n",
    "    unmerge = torch.cat(\n",
    "        (\n",
    "            torch.eye(O, device=covariance.device),\n",
    "            unmerge.T\n",
    "        ), \n",
    "        dim=0\n",
    "    )\n",
    "    merge = unmerge / (unmerge.sum(dim=0, keepdim=True) + 1e-5)\n",
    "    return merge.T, unmerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e728022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_col(x, idx):\n",
    "    return torch.cat([x[:, :idx], x[:, idx+1:]], dim=-1)\n",
    "\n",
    "def match_tensors_chain_cov(\n",
    "    covariance,\n",
    "    r=.5\n",
    "):\n",
    "    O = covariance.shape[0]\n",
    "    O_half = O // 2\n",
    "    remainder = int(O * (1-r))\n",
    "    bound = O - remainder\n",
    "    sims = covariance\n",
    "#     sims[:O_half, :O_half] = -torch.inf\n",
    "#     sims[O_half:, O_half:] = -torch.inf\n",
    "#     sims[:O_half, O_half:] = -torch.inf\n",
    "#     sims[O_half:, :O_half] = -torch.inf\n",
    "    \n",
    "    # result after alg should be (O, O-bound)\n",
    "    permutation_matrix = torch.eye(O, O, device=sims.device)\n",
    "\n",
    "    for i in range(bound):\n",
    "        best_idx = sims.reshape(-1).argmax()\n",
    "        row_idx = best_idx % sims.shape[1]\n",
    "        col_idx = best_idx // sims.shape[1]\n",
    "        \n",
    "        permutation_matrix[:, row_idx] += permutation_matrix[:, col_idx]\n",
    "        permutation_matrix = remove_col(permutation_matrix, col_idx)\n",
    "        \n",
    "        sims[:, row_idx] = (sims[:, row_idx] + sims[:, col_idx]) / 2\n",
    "        sims = remove_col(sims, col_idx)\n",
    "        \n",
    "        sims[row_idx, :] = (sims[row_idx, :] + sims[col_idx, :]) / 2\n",
    "        sims = remove_col(sims.T, col_idx).T\n",
    "    \n",
    "#     unused = (sims.max(-1)[0] > -torch.inf).to(torch.int).nonzero().view(-1)\n",
    "#     for i in range(bound, O-bound):\n",
    "#         permutation_matrix[unused[i-bound], i] = 1\n",
    "    merge = permutation_matrix / (permutation_matrix.sum(dim=0, keepdim=True) + 1e-5)\n",
    "    unmerge = permutation_matrix\n",
    "    return merge.T, unmerge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc218ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifies the weight matrices of a convolution and batchnorm\n",
    "# layer given a permutation of the output channels\n",
    "def permute_output(merge, convs, bns):\n",
    "    pre_weights = [\n",
    "        (convs[0].weight, convs[1].weight, convs[2].weight),\n",
    "        (bns[0].weight, bns[1].weight, bns[2].weight),\n",
    "        (bns[0].bias, bns[1].bias, bns[2].bias),\n",
    "        (bns[0].running_mean, bns[1].running_mean, bns[2].running_mean),\n",
    "        (bns[0].running_var, bns[1].running_var, bns[2].running_var)\n",
    "    ]\n",
    "    for a, b, c in pre_weights:\n",
    "        a_w, b_w = merge.chunk(2, dim=1)\n",
    "\n",
    "        if len(a.shape) == 4:\n",
    "            t_a = torch.einsum('ab,bcde->acde', a_w, a.to(DEVICE) * 2)\n",
    "            t_b = torch.einsum('ab,bcde->acde', b_w, b.to(DEVICE) * 2)\n",
    "        else:\n",
    "            t_a = a_w @ a.to(DEVICE) * 2\n",
    "            t_b = b_w @ b.to(DEVICE) * 2\n",
    "        \n",
    "        a.data = t_a\n",
    "        b.data = t_b\n",
    "\n",
    "\n",
    "# modifies the weight matrix of a convolution layer for a given\n",
    "# permutation of the input channels\n",
    "def permute_input(unmerge, after_convs):\n",
    "    if not isinstance(after_convs, list):\n",
    "        after_convs = [after_convs]\n",
    "    post_weights = [(c[0].weight, c[1].weight, c[2].weight) for c in after_convs]\n",
    "    for (a, b, c) in post_weights:\n",
    "        a_w, b_w = unmerge.chunk(2, dim=0)\n",
    "\n",
    "        if len(a.shape) == 4:\n",
    "            a.data = torch.einsum('abcd,be->aecd', a.to(DEVICE), a_w)\n",
    "            b.data = torch.einsum('abcd,be->aecd', b.to(DEVICE), b_w)\n",
    "        else:\n",
    "            a.data = (a.to(DEVICE) @ a_w)\n",
    "            b.data = (b.to(DEVICE) @ b_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0fe70bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the channel-permutation to make layer1's activations most closely\n",
    "# match layer0's.\n",
    "def layer_perm_baseline(net0, net1, method='max_weight', vizz=False, prune_threshold=-torch.inf):\n",
    "    corr_mtx = run_corr_matrix_og(net0, net1)\n",
    "    return match_tensors_permute(corr_mtx)\n",
    "\n",
    "def layer_perm_ours(net0, net1, method='max_weight', vizz=False, prune_threshold=-torch.inf):\n",
    "    corr_mtx = run_corr_matrix(net0, net1)\n",
    "    return match_tensors_exact_bipartite_cov(corr_mtx)\n",
    "\n",
    "def layer_cosine_perm_ours(net0, net1, method='max_weight', vizz=False, prune_threshold=-torch.inf):\n",
    "    corr_mtx = run_cos_sim_matrix(net0, net1)\n",
    "    return match_tensors_exact_bipartite_cov(corr_mtx)\n",
    "\n",
    "def layer_perm_chain_ours(net0, net1, method='max_weight', vizz=False, prune_threshold=-torch.inf):\n",
    "    corr_mtx = run_corr_matrix(net0, net1)\n",
    "    return match_tensors_chain_cov(corr_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a795d793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f13d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "825ac095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_weights(sd0, sd1, target, alpha):\n",
    "    sd_alpha = {}\n",
    "    for k in sd0.keys():\n",
    "        param0 = sd0[k].to(DEVICE)\n",
    "        param1 = sd1[k].to(DEVICE)\n",
    "        sd_alpha[k] = (1 - alpha) * param0 + alpha * param1\n",
    "        # TODO: alpha is ignored\n",
    "#         sd_alpha[k] = param0 + param1\n",
    "#     sd_alpha = {k: (1 - alpha) * sd0[k].to('mps') + alpha * sd1[k].to('mps')\n",
    "#                 for k in sd0.keys()}\n",
    "    target.load_state_dict(sd_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b36a785",
   "metadata": {},
   "source": [
    "# Find Bipartite Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c0eaa87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_equality(source, candidate, check=False, return_result=False):\n",
    "    source_sd, candidate_sd = source.state_dict(), candidate.state_dict()\n",
    "    match_dict = {}\n",
    "    for key, source_val in source_sd.items():\n",
    "        candidate_val = candidate_sd[key]\n",
    "        is_match = torch.allclose(source_val.cuda(), candidate_val.cuda())\n",
    "        match_dict[key] = is_match\n",
    "        \n",
    "    all_matched = True\n",
    "    for key, is_match in match_dict.items():\n",
    "        if is_match == check:\n",
    "            print(f'{key}: {is_match}')\n",
    "            all_matched = False\n",
    "    if all_matched:\n",
    "        print('All Matched')\n",
    "    if return_result:\n",
    "        return match_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a355a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778\n",
      "0.7758\n"
     ]
    }
   ],
   "source": [
    "model0 = resnet20(w=4, text_head=True).to(DEVICE)\n",
    "model1 = resnet20(w=4, text_head=True).to(DEVICE)\n",
    "model0_c = resnet20(w=4, text_head=True).to(DEVICE)\n",
    "model1_c = resnet20(w=4, text_head=True).to(DEVICE)\n",
    "load_model(model0, f'resnet20x4_CIFAR50_clses{model1_classes.tolist()}')\n",
    "load_model(model1, f'resnet20x4_CIFAR50_clses{model2_classes.tolist()}')\n",
    "load_model(model0_c, f'resnet20x4_CIFAR50_clses{model1_classes.tolist()}')\n",
    "load_model(model1_c, f'resnet20x4_CIFAR50_clses{model2_classes.tolist()}')\n",
    "\n",
    "print(evaluate_texthead(model0, test_loader1, class_vecs1, remap_class_idxs=class_idxs))\n",
    "print(evaluate_texthead(model1, test_loader2, class_vecs2, remap_class_idxs=class_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "540f0b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelc = resnet20(w=4, text_head=True).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1ce16982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d2260a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_layer_perm = layer_perm_ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a2db52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_model_equality(model0, model0_c, check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9835b29e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.61it/s]\n"
     ]
    }
   ],
   "source": [
    "class Subnet(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        self = self.model\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        return x\n",
    "\n",
    "models = [model0_c, model1_c, modelc]\n",
    "merge, unmerge = get_layer_perm(Subnet(model0), Subnet(model1))\n",
    "\n",
    "permute_output(\n",
    "    merge, \n",
    "    [m.conv1 for m in models], \n",
    "    [m.bn1 for m in models]\n",
    ")\n",
    "\n",
    "permute_output(\n",
    "    merge, \n",
    "    [m.layer1[0].conv2 for m in models], \n",
    "    [m.layer1[0].bn2 for m in models]\n",
    ")\n",
    "permute_output(\n",
    "    merge, \n",
    "    [m.layer1[1].conv2 for m in models], \n",
    "    [m.layer1[1].bn2 for m in models]\n",
    ")\n",
    "permute_output(\n",
    "    merge, \n",
    "    [m.layer1[2].conv2 for m in models], \n",
    "    [m.layer1[2].bn2 for m in models]\n",
    ")\n",
    "permute_input(\n",
    "    unmerge, \n",
    "    [\n",
    "        [m.layer1[0].conv1 for m in models], \n",
    "        [m.layer1[1].conv1 for m in models], \n",
    "        [m.layer1[2].conv1 for m in models]\n",
    "    ]\n",
    ")\n",
    "permute_input(\n",
    "    unmerge, \n",
    "    [\n",
    "        [m.layer2[0].conv1 for m in models], \n",
    "        [m.layer2[0].shortcut[0] for m in models]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# check_model_equality(model0, model0_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "88e5e757",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for cmap_id in plt.colormaps():\n",
    "def plot_sims(sims, cmap_id=\"twilight\", filename=None):\n",
    "    plt.figure()\n",
    "    plt.set_cmap(cmap_id)\n",
    "\n",
    "    sims_sort = sims.sort(-1, descending=True)[0]\n",
    "#     new_sort = F.relu(sims_sort[:, :-1]).norm(dim=-1).argsort(descending=True)\n",
    "#     new_sort = torch.special.entr(sims_sort[:, :-1].softmax(dim=-1)).sum(dim=-1).argsort(descending=False)\n",
    "    new_sort = sims_sort[:, 0].argsort(descending=True)\n",
    "    \n",
    "    sims_sort = sims_sort[new_sort,:]\n",
    "\n",
    "    plt.imshow(sims_sort.cpu().numpy(), vmin=-1, vmax=+1)\n",
    "    plt.colorbar()\n",
    "#     plt.title(cmap_id)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if filename is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(filename, dpi=1200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "785c42cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_merge_sets(merge):\n",
    "    A, B = merge.chunk(2, dim=-1)\n",
    "    A_merges = (A.sum(1)*2).abs().ceil().to(torch.int).bincount()[1:]\n",
    "    B_merges = (B.sum(1)*2).abs().ceil().to(torch.int).bincount()[1:]\n",
    "    merges = {}\n",
    "    if len(A_merges) == 2:\n",
    "        merges['A->A'] = A_merges[1].cpu().numpy()\n",
    "    if len(B_merges) == 2:\n",
    "        merges['B->B'] = B_merges[1].cpu().numpy()\n",
    "    try:\n",
    "        merges['A^B'] = A_merges[0].cpu().numpy()\n",
    "    except:\n",
    "        merges['A^B'] = B_merges[0].cpu().numpy()\n",
    "    \n",
    "    print(merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_merge_sets(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e45b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subnet(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        self = self.model\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "merge, unmerge = get_layer_perm(Subnet(model0), Subnet(model1))\n",
    "\n",
    "# combine_convs_and_fcs(\n",
    "#     elements=[\n",
    "#         [m.layer1[0].conv1 for m in models], \n",
    "#         [m.layer1[1].conv1 for m in models], \n",
    "#         [m.layer1[2].conv1 for m in models]\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "permute_output(\n",
    "    merge, \n",
    "    [m.layer2[0].conv2 for m in models], \n",
    "    [m.layer2[0].bn2 for m in models]\n",
    ")\n",
    "permute_output(\n",
    "    merge, \n",
    "    [m.layer2[0].shortcut[0] for m in models], \n",
    "    [m.layer2[0].shortcut[1] for m in models]\n",
    ")\n",
    "permute_output(\n",
    "    merge, \n",
    "    [m.layer2[1].conv2 for m in models], \n",
    "    [m.layer2[1].bn2 for m in models]\n",
    ")\n",
    "permute_output(\n",
    "    merge, \n",
    "    [m.layer2[2].conv2 for m in models], \n",
    "    [m.layer2[2].bn2 for m in models]\n",
    ")\n",
    "\n",
    "permute_input(\n",
    "    unmerge, \n",
    "    [\n",
    "        [m.layer2[1].conv1 for m in models], \n",
    "        [m.layer2[2].conv1 for m in models]\n",
    "    ]\n",
    ")\n",
    "permute_input(\n",
    "    unmerge, \n",
    "    [\n",
    "        [m.layer3[0].conv1 for m in models], \n",
    "        [m.layer3[0].shortcut[0] for m in models]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493166e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_merge_sets(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b794aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subnet(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        self = self.model\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "merge, unmerge = get_layer_perm(Subnet(model0), Subnet(model1))\n",
    "permute_output(\n",
    "    merge, \n",
    "    [m.layer3[0].conv2 for m in models], \n",
    "    [m.layer3[0].bn2 for m in models]\n",
    ")\n",
    "permute_output(\n",
    "    merge, \n",
    "    [m.layer3[0].shortcut[0] for m in models], \n",
    "    [m.layer3[0].shortcut[1] for m in models]\n",
    ")\n",
    "permute_output(\n",
    "    merge, \n",
    "    [m.layer3[1].conv2 for m in models], \n",
    "    [m.layer3[1].bn2 for m in models]\n",
    ")\n",
    "permute_output(\n",
    "    merge, \n",
    "    [m.layer3[2].conv2 for m in models], \n",
    "    [m.layer3[2].bn2 for m in models]\n",
    ")\n",
    "\n",
    "permute_input(\n",
    "    unmerge, \n",
    "    [\n",
    "        [m.layer3[1].conv1 for m in models], \n",
    "        [m.layer3[2].conv1 for m in models]\n",
    "    ]\n",
    ")\n",
    "\n",
    "a_w, b_w = unmerge.chunk(2, dim=0)\n",
    "model0_c.linear.weight.data = (model0_c.linear.weight.to(DEVICE) @ a_w)\n",
    "model1_c.linear.weight.data = (model1_c.linear.weight.to(DEVICE) @ b_w)\n",
    "\n",
    "# check_model_equality(model0, model0_c)\n",
    "# modelc.linear.weight.data = (torch.cat(\n",
    "#     (\n",
    "#         model0_c.linear.weight.to(DEVICE),\n",
    "#         model1_c.linear.weight.to(DEVICE)\n",
    "#     ), dim=-1\n",
    "# ) @ unmerge / 2.).cpu()\n",
    "\n",
    "\n",
    "# modelc.linear.weight.data = (torch.cat(\n",
    "#     (\n",
    "#         model0.linear.weight,\n",
    "#         model1.linear.weight\n",
    "#     ), dim=-1\n",
    "# ) @ unmerge / 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5089a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_merge_sets(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a07f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subnet(nn.Module):\n",
    "    def __init__(self, model, nb=9):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.blocks = []\n",
    "        self.blocks += list(model.layer1)\n",
    "        self.blocks += list(model.layer2)\n",
    "        self.blocks += list(model.layer3)\n",
    "        self.blocks = nn.Sequential(*self.blocks)\n",
    "        self.bn1 = model.bn1\n",
    "        self.conv1 = model.conv1\n",
    "        self.linear = model.linear\n",
    "        self.nb = nb\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.blocks[:self.nb](x)\n",
    "        block = self.blocks[self.nb]\n",
    "        x = block.conv1(x)\n",
    "        x = block.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "# model0_c = model0\n",
    "# model1_c = model1\n",
    "blocks0 = []\n",
    "blocks0 += list(model0_c.layer1)\n",
    "blocks0 += list(model0_c.layer2)\n",
    "blocks0 += list(model0_c.layer3)\n",
    "blocks0 = nn.Sequential(*blocks0)\n",
    "\n",
    "blocks1 = []\n",
    "blocks1 += list(model1_c.layer1)\n",
    "blocks1 += list(model1_c.layer2)\n",
    "blocks1 += list(model1_c.layer3)\n",
    "blocks1 = nn.Sequential(*blocks1)\n",
    "\n",
    "blocksc = []\n",
    "blocksc += list(modelc.layer1)\n",
    "blocksc += list(modelc.layer2)\n",
    "blocksc += list(modelc.layer3)\n",
    "blocksc = nn.Sequential(*blocksc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx2name = {\n",
    "    0: 'layer1.0',\n",
    "    1: 'layer1.1',\n",
    "    2: 'layer1.2',\n",
    "    3: 'layer2.0',\n",
    "    4: 'layer2.1',\n",
    "    5: 'layer2.2',\n",
    "    6: 'layer3.0',\n",
    "    7: 'layer3.1',\n",
    "    8: 'layer3.2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e06bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nb, (block_idx, layer_name) in zip(range(9), block_idx2name.items()):\n",
    "    merge, unmerge = get_layer_perm(Subnet(model0, nb=nb), Subnet(model1, nb=nb))\n",
    "    block0 = blocks0[nb]\n",
    "    block1 = blocks1[nb]\n",
    "    blockc = blocksc[nb]\n",
    "    blocks = [block0, block1, blockc]\n",
    "    permute_output(\n",
    "        merge, \n",
    "        [m.conv1 for m in blocks], \n",
    "        [m.bn1 for m in blocks]\n",
    "    )\n",
    "    permute_input(\n",
    "        unmerge, \n",
    "        [\n",
    "            [m.conv2 for m in blocks]\n",
    "        ]\n",
    "    )\n",
    "    find_merge_sets(merge)\n",
    "# check_model_equality(model0, model0_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6482cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluate_texthead(model0, test_loader1, class_vecs1, remap_class_idxs=class_idxs))\n",
    "print(evaluate_texthead(model1, test_loader2, class_vecs2, remap_class_idxs=class_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d9da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluate_texthead(model0_c, test_loader1, class_vecs1, remap_class_idxs=class_idxs))\n",
    "print(evaluate_texthead(model1_c, test_loader2, class_vecs2, remap_class_idxs=class_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083955b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_weights(sd0=model0_c.state_dict(), sd1=model1_c.state_dict(), target=modelc, alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e978aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelc = modelc.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c5b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebea300",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_bn_stats(modelc, loader=train_aug_loader)\n",
    "acc, perclass_acc = evaluate_texthead(\n",
    "    modelc, test_loader, class_vectors=text_features, return_confusion=True\n",
    ")\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac09d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perclass_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6678bc8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
