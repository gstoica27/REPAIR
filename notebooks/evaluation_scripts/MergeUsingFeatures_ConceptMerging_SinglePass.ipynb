{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256b885f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/share/gstoica3/miniconda3/envs/open-mmlab/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam, lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sys import platform\n",
    "\n",
    "DEVICE = 'mps' if platform == 'darwin' else 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d7eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a983d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, i):\n",
    "    sd = model.state_dict()\n",
    "    path = os.path.join(\n",
    "        # '/Users/georgestoica/Downloads',\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def load_model(model, i):\n",
    "    path = os.path.join(\n",
    "        # '/Users/georgestoica/Downloads',\n",
    "        '/srv/share/gstoica3/checkpoints/REPAIR/',\n",
    "        '%s.pth.tar' % i\n",
    "    )\n",
    "    sd = torch.load(path, map_location=torch.device(DEVICE))\n",
    "    model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1028485",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_info = {\n",
    "    'dir': '/nethome/gstoica3/research/pytorch-cifar100/data/cifar-100-python',\n",
    "    'classes1': np.arange(50),\n",
    "    'classes2': np.arange(50, 100),\n",
    "    'num_classes': 100,\n",
    "    'split_classes': 50,\n",
    "    'wrapper': torchvision.datasets.CIFAR100\n",
    "}\n",
    "\n",
    "cifar10_info = {\n",
    "    'dir': '/tmp',\n",
    "    'classes1': np.array([3, 2, 0, 6, 4]),\n",
    "    'classes2': np.array([5, 7, 9, 8, 1]),\n",
    "    'num_classes': 10,\n",
    "    'split_classes': 5,\n",
    "    'wrapper': torchvision.datasets.CIFAR10\n",
    "}\n",
    "\n",
    "ds_info = cifar10_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d3687c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "489caa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "\n",
    "\n",
    "class BalancedBatchSampler(BatchSampler):\n",
    "    \"\"\"\n",
    "    BatchSampler - from a MNIST-like dataset, samples n_classes and within these classes samples n_samples.\n",
    "    Returns batches of size n_classes * n_samples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, n_classes, n_samples):\n",
    "        loader = DataLoader(dataset)\n",
    "        self.labels_list = []\n",
    "        for _, label in loader:\n",
    "            self.labels_list.append(label)\n",
    "        self.labels = torch.LongTensor(self.labels_list)\n",
    "        self.labels_set = list(set(self.labels.numpy()))\n",
    "        self.label_to_indices = {label: np.where(self.labels.numpy() == label)[0]\n",
    "                                 for label in self.labels_set}\n",
    "        for l in self.labels_set:\n",
    "            np.random.shuffle(self.label_to_indices[l])\n",
    "        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n",
    "        self.count = 0\n",
    "        self.n_classes = n_classes\n",
    "        self.n_samples = n_samples\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = self.n_samples * self.n_classes\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.count = 0\n",
    "        while self.count + self.batch_size <= len(self.dataset):\n",
    "            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n",
    "            indices = []\n",
    "            for class_ in classes:\n",
    "                indices.extend(self.label_to_indices[class_][\n",
    "                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n",
    "                                                                         class_] + self.n_samples])\n",
    "                self.used_label_indices_count[class_] += self.n_samples\n",
    "                if self.used_label_indices_count[class_] + self.n_samples > len(self.label_to_indices[class_]):\n",
    "                    np.random.shuffle(self.label_to_indices[class_])\n",
    "                    self.used_label_indices_count[class_] = 0\n",
    "            yield indices\n",
    "            self.count += self.n_classes * self.n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9cd3aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /tmp/cifar-10-python.tar.gz\n",
      "Extracting /tmp/cifar-10-python.tar.gz to /tmp\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CIFAR_MEAN = [125.307, 122.961, 113.8575]\n",
    "CIFAR_STD = [51.5865, 50.847, 51.255]\n",
    "normalize = T.Normalize(np.array(CIFAR_MEAN)/255, np.array(CIFAR_STD)/255)\n",
    "denormalize = T.Normalize(-np.array(CIFAR_MEAN)/np.array(CIFAR_STD), 255/np.array(CIFAR_STD))\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "train_dset = ds_info['wrapper'](root=ds_info['dir'], train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "test_dset = ds_info['wrapper'](root=ds_info['dir'], train=False,\n",
    "                                        download=True, transform=test_transform)\n",
    "\n",
    "train_aug_loader = torch.utils.data.DataLoader(train_dset, batch_size=500, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=500, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c1172d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:16, 3058.19it/s]\n",
      "50000it [00:15, 3189.60it/s]\n",
      "10000it [00:02, 4535.10it/s]\n",
      "10000it [00:01, 5000.86it/s]\n"
     ]
    }
   ],
   "source": [
    "model1_classes= ds_info['classes1']#np.array([3, 2, 0, 6, 4])\n",
    "model2_classes = ds_info['classes2']\n",
    "\n",
    "valid_examples1 = [i for i, (_, label) in tqdm(enumerate(train_dset)) if label in model1_classes]\n",
    "valid_examples2 = [i for i, (_, label) in tqdm(enumerate(train_dset)) if label in model2_classes]\n",
    "\n",
    "assert len(set(valid_examples1).intersection(set(valid_examples2))) == 0, 'sets should be disjoint'\n",
    "\n",
    "train_aug_loader1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dset, valid_examples1), batch_size=500, shuffle=False, num_workers=8\n",
    ")\n",
    "train_aug_loader2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dset, valid_examples2), batch_size=500, shuffle=False, num_workers=8\n",
    ")\n",
    "\n",
    "test_valid_examples1 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model1_classes]\n",
    "test_valid_examples2 = [i for i, (_, label) in tqdm(enumerate(test_dset)) if label in model2_classes]\n",
    "\n",
    "test_loader1 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dset, test_valid_examples1), batch_size=500, shuffle=False, num_workers=8\n",
    ")\n",
    "test_loader2 = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(test_dset, test_valid_examples2), batch_size=500, shuffle=False, num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2c1a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_batched_sampler = BalancedBatchSampler(train_dset, n_classes=ds_info['num_classes'], n_samples=50)\n",
    "balanced_train_aug_loader = torch.utils.data.DataLoader(\n",
    "    train_dset, num_workers=8, batch_sampler=balanced_batched_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff760c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 1, 0, 4, 0, 3, 1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "class_idxs = np.zeros(ds_info['num_classes'], dtype=int)\n",
    "class_idxs[model1_classes] = np.arange(ds_info['split_classes'])\n",
    "class_idxs[model2_classes] = np.arange(ds_info['split_classes'])\n",
    "class_idxs = torch.from_numpy(class_idxs)\n",
    "print(class_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26093947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the train loader with data augmentation as this gives better results\n",
    "def reset_bn_stats(model, epochs=1, loader=train_aug_loader):\n",
    "    # resetting stats to baseline first as below is necessary for stability\n",
    "    for m in model.modules():\n",
    "        if type(m) == nn.BatchNorm2d:\n",
    "            m.momentum = None # use simple average\n",
    "            m.reset_running_stats()\n",
    "    # run a single train epoch with augmentations to recalc stats\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        with torch.no_grad(), autocast():\n",
    "            for images, _ in loader:\n",
    "                output = model(images.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6155682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates accuracy\n",
    "def evaluate_texthead(model, loader, class_vectors, remap_class_idxs=None, return_confusion=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    totals = [0] * class_vectors.shape[0]\n",
    "    corrects = [0] * class_vectors.shape[0]\n",
    "    \n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            encodings = model(inputs.to(DEVICE))\n",
    "            normed_encodings = encodings / encodings.norm(dim=-1, keepdim=True)\n",
    "            outputs = normed_encodings @ class_vectors.T\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            if remap_class_idxs is not None:\n",
    "                correct += (remap_class_idxs[labels].to(DEVICE) == pred).sum().item()\n",
    "            else:\n",
    "                for gt, p in zip(labels, pred):\n",
    "                    totals[gt] += 1\n",
    "                    \n",
    "                    if gt == p:\n",
    "                        correct += 1\n",
    "                        corrects[gt] += 1\n",
    "                \n",
    "            total += inputs.shape[0]\n",
    "    if return_confusion:\n",
    "        return correct / sum(totals), list(map(lambda a: a[0] / a[1], zip(corrects, totals)))\n",
    "    else:\n",
    "        return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d932fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in test_dset.classes]).to(DEVICE)\n",
    "model, preprocess = clip.load('ViT-B/32', DEVICE)\n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "class_vecs1 = text_features[model1_classes]\n",
    "class_vecs2 = text_features[model2_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4753f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnets import resnet20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35478e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_tensors_exact_bipartite_cov(\n",
    "    covariance,\n",
    "    r=.5\n",
    "):\n",
    "    O = covariance.shape[0]\n",
    "    O_half = O // 2\n",
    "    remainder = int(O * (1-r))\n",
    "    bound = O - remainder\n",
    "    sims = covariance\n",
    "\n",
    "#     plot_sims(sims, filename=\"conv1_covar_sorted.png\")\n",
    "    \n",
    "    permutation_matrix = torch.zeros((O, O - bound), device=sims.device)\n",
    "\n",
    "    for i in range(bound):\n",
    "        best_idx = sims.view(-1).argmax()\n",
    "        row_idx = best_idx % sims.shape[1]\n",
    "        col_idx = best_idx // sims.shape[1]\n",
    "        permutation_matrix[row_idx, i] = 1\n",
    "        permutation_matrix[col_idx, i] = 1\n",
    "        sims[row_idx] = -torch.inf\n",
    "        sims[col_idx] = -torch.inf\n",
    "        sims[:, row_idx] = -torch.inf\n",
    "        sims[:, col_idx] = -torch.inf\n",
    "    \n",
    "    unused = (sims.max(-1)[0] > -torch.inf).to(torch.int).nonzero().view(-1)\n",
    "    for i in range(bound, O-bound):\n",
    "        permutation_matrix[unused[i-bound], i] = 1\n",
    "    merge = permutation_matrix / (permutation_matrix.sum(dim=0, keepdim=True) + 1e-5)\n",
    "    unmerge = permutation_matrix\n",
    "    return merge.T, unmerge\n",
    "\n",
    "def match_tensors_permute(\n",
    "    covariance\n",
    "):\n",
    "#     torch.diagonal(covariance)[:] = -torch.inf\n",
    "    corr_mtx_a = covariance.cpu().numpy()\n",
    "    O = corr_mtx_a.shape[0]# // 2\n",
    "    row_ind, col_ind = scipy.optimize.linear_sum_assignment(corr_mtx_a[:O, :O], maximize=True)\n",
    "#     assert (row_ind == np.arange(len(corr_mtx_a))).all()\n",
    "    unmerge = torch.tensor(col_ind).long()\n",
    "    unmerge = torch.eye(O, device=covariance.device)[unmerge]\n",
    "    unmerge = torch.cat(\n",
    "        (\n",
    "            torch.eye(O, device=covariance.device),\n",
    "            unmerge.T\n",
    "        ), \n",
    "        dim=0\n",
    "    )\n",
    "    merge = unmerge / (unmerge.sum(dim=0, keepdim=True) + 1e-5)\n",
    "    return merge.T, unmerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "105fa76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_col(x, idx):\n",
    "    return torch.cat([x[:, :idx], x[:, idx+1:]], dim=-1)\n",
    "\n",
    "def match_tensors_chain_cov(\n",
    "    covariance,\n",
    "    r=.5\n",
    "):\n",
    "    O = covariance.shape[0]\n",
    "    O_half = O // 2\n",
    "    remainder = int(O * (1-r))\n",
    "    bound = O - remainder\n",
    "    sims = covariance.clone()\n",
    "\n",
    "    # result after alg should be (O, O-bound)\n",
    "    permutation_matrix = torch.eye(O, O, device=sims.device)\n",
    "\n",
    "    for i in range(bound):\n",
    "        best_idx = sims.reshape(-1).argmax()\n",
    "        row_idx = best_idx % sims.shape[1]\n",
    "        col_idx = best_idx // sims.shape[1]\n",
    "        \n",
    "#         sizes = permutation_matrix.sum(dim=0)\n",
    "        a = 0.5\n",
    "        \n",
    "        permutation_matrix[:, row_idx] += permutation_matrix[:, col_idx]\n",
    "        permutation_matrix = remove_col(permutation_matrix, col_idx)\n",
    "        \n",
    "#         row_size = sizes[row_idx]\n",
    "#         col_size = sizes[col_idx]\n",
    "#         total_size = row_size + col_size\n",
    "        \n",
    "#         sims[:, row_idx] = (sims[:, row_idx] * row_size + sims[:, col_idx] * col_size) / total_size\n",
    "        sims[:, row_idx] = torch.minimum(a * sims[:, row_idx], a * sims[:, col_idx])\n",
    "        sims = remove_col(sims, col_idx)\n",
    "        \n",
    "#         sims[row_idx, :] = (sims[row_idx, :] * row_size + sims[col_idx, :] * col_size) / total_size\n",
    "        sims[row_idx, :] = torch.minimum(a * sims[row_idx, :], a * sims[col_idx, :])\n",
    "        sims = remove_col(sims.T, col_idx).T\n",
    "    \n",
    "#     unused = (sims.max(-1)[0] > -torch.inf).to(torch.int).nonzero().view(-1)\n",
    "#     for i in range(bound, O-bound):\n",
    "#         permutation_matrix[unused[i-bound], i] = 1\n",
    "    merge = permutation_matrix / (permutation_matrix.sum(dim=0, keepdim=True) + 1e-5)\n",
    "    unmerge = permutation_matrix\n",
    "    return merge.T, unmerge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07957710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_tensors_consecutive_chain_cov(\n",
    "    covariance,\n",
    "    r=.5\n",
    "):\n",
    "    O = covariance.shape[0]\n",
    "    O_half = O // 2\n",
    "    remainder = int(O * (1-r))\n",
    "    bound = O - remainder\n",
    "    sims = covariance\n",
    "    \n",
    "    permutation_matrix = torch.zeros((O, O - bound), device=sims.device)\n",
    "    temp_sims = torch.ones((O), device=covariance.device) * -torch.inf\n",
    "    temp_count = 0\n",
    "    ignore_temp = True\n",
    "    for i in range(bound):\n",
    "        best_idx = sims.view(-1).argmax()\n",
    "        best_sim = sim.view(-1).max()\n",
    "        if not ignore_temp and temp_sims.max() > best_sim:\n",
    "            temp_best = temp_sims.max()\n",
    "            temp_idx = temp_sims.argmax()\n",
    "            permutation_matrix[temp_idx, i] = 1\n",
    "#             temp_sims = (temp_sims * temp_count + sims[temp_idx]) / (temp_count + 1)\n",
    "            temp_sims = torch.minimum(temp_sims, sims[temp_idx])\n",
    "            sims[temp_idx] = -torch.inf\n",
    "            sims[:, temp_idx] = -torch.inf\n",
    "#             temp_sims = torch.minimum(temp_sims, sims[temp_idx])\n",
    "            temp_count += 1\n",
    "        elif not ignore_temp:\n",
    "            temp_sims = torch.ones((O), device=covariance.device) * -torch.inf\n",
    "            temp_count = 0\n",
    "            ignore_temp = True\n",
    "        if ignore_temp:\n",
    "            row_idx = best_idx % sims.shape[1]\n",
    "            col_idx = best_idx // sims.shape[1]\n",
    "            \n",
    "#             temp_sims = (sims[row_idx] + sims[col_idx]) / 2\n",
    "            temp_sims = torch.minimum(sims[row_idx], sims[col_idx])\n",
    "            temp_count = 2\n",
    "            ignore_temp = False\n",
    "            \n",
    "            permutation_matrix[row_idx, i] = 1\n",
    "            permutation_matrix[col_idx, i] = 1\n",
    "\n",
    "            sims[row_idx] = -torch.inf\n",
    "            sims[col_idx] = -torch.inf\n",
    "            sims[:, row_idx] = -torch.inf\n",
    "            sims[:, col_idx] = -torch.inf\n",
    "            \n",
    "    \n",
    "    unused = (sims.max(-1)[0] > -torch.inf).to(torch.int).nonzero().view(-1)\n",
    "    for i in range(bound, O-bound):\n",
    "        permutation_matrix[unused[i-bound], i] = 1\n",
    "    merge = permutation_matrix / (permutation_matrix.sum(dim=0, keepdim=True) + 1e-5)\n",
    "    unmerge = permutation_matrix\n",
    "    return merge.T, unmerge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "825ac095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_weights(sd0, sd1, target, alpha):\n",
    "    sd_alpha = {}\n",
    "    for k in sd0.keys():\n",
    "        param0 = sd0[k].to(DEVICE)\n",
    "        param1 = sd1[k].to(DEVICE)\n",
    "        sd_alpha[k] = (1 - alpha) * param0 + alpha * param1\n",
    "    target.load_state_dict(sd_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dbee49",
   "metadata": {},
   "source": [
    "## Single Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6c5d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b8589b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fa94de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinglePassResNet20(object):\n",
    "    def __init__(self, model0, model1):\n",
    "        super(SinglePassResNet20, self).__init__()\n",
    "        self.model0 = model0\n",
    "        self.model1 = model1\n",
    "        self.layer2cov = defaultdict(lambda: None)\n",
    "        self.output_pattern = lambda model, x: F.relu(model.bn1(model.conv1(x)))\n",
    "        \n",
    "    def get_layer_intermediates(self, batch0, batch1, layer0, layer1, label, n):\n",
    "        zipped_layers = zip(list(layer0), list(layer1))\n",
    "        for i, (inter0, inter1) in enumerate(zipped_layers):\n",
    "            out0 = self.output_pattern(inter0, batch0)\n",
    "            out1 = self.output_pattern(inter1, batch1)\n",
    "            \n",
    "            self.batch_update_covs(\n",
    "                label+f'.{i}', \n",
    "                out0=out0, out1=out1,\n",
    "                n=n\n",
    "            )\n",
    "            \n",
    "            batch0 = inter0(batch0)\n",
    "            batch1 = inter1(batch1)\n",
    "        self.batch_update_covs(\n",
    "            label, out0=batch0, out1=batch1, n=n\n",
    "        )\n",
    "        return batch0, batch1\n",
    "   \n",
    "   # Jakob needs to write a capture intermediate value on the vit... Can do this with hooks.\n",
    "    def get_intermediate_scores(self, dataloader, num_passes=1, num_steps=None):\n",
    "        n = len(dataloader) * num_passes\n",
    "        with torch.no_grad():\n",
    "            self.model0.eval()\n",
    "            self.model1.eval()\n",
    "        \n",
    "        for _ in range(num_passes):\n",
    "            for i, (images, _) in enumerate(tqdm(dataloader)):\n",
    "                if num_steps is not None and i >= num_steps: break\n",
    "                inputs = images.float().to(DEVICE)\n",
    "                out0 = F.relu(self.model0.bn1(self.model0.conv1(inputs)))\n",
    "                out1 = F.relu(self.model1.bn1(self.model1.conv1(inputs)))\n",
    "\n",
    "                out0, out1 = self.get_layer_intermediates(\n",
    "                    out0, out1, self.model0.layer1, self.model1.layer1, 'layer1', n\n",
    "                )\n",
    "                out0, out1 = self.get_layer_intermediates(\n",
    "                    out0, out1, self.model0.layer2, self.model1.layer2, 'layer2', n\n",
    "                )\n",
    "                out0, out1 = self.get_layer_intermediates(\n",
    "                    out0, out1, self.model0.layer3, self.model1.layer3, 'layer3', n\n",
    "                )\n",
    "        \n",
    "        for layer, cov in tqdm(self.layer2cov.items()):\n",
    "            mean = cov['mean']\n",
    "            std = cov['std']\n",
    "            outer = cov['outer']\n",
    "            \n",
    "            cov = outer - torch.outer(mean, mean)\n",
    "            cov /= (torch.outer(std, std) + 1e-4)\n",
    "            torch.diagonal(cov)[:] = -torch.inf\n",
    "            self.layer2cov[layer] = cov\n",
    "    \n",
    "    def batch_update_covs(self, label, out0, out1, n):\n",
    "        out0 = out0.reshape(out0.shape[0], out0.shape[1], -1).permute(0, 2, 1)\n",
    "        out0 = out0.reshape(-1, out0.shape[2]).double()\n",
    "        out1 = out1.reshape(out1.shape[0], out1.shape[1], -1).permute(0, 2, 1)\n",
    "        out1 = out1.reshape(-1, out1.shape[2]).double()\n",
    "        out = torch.cat((out0, out1), dim=-1)\n",
    "        mean_b = out.mean(dim=0).detach().cpu()\n",
    "        std0_b = out0.std(dim=0).detach().cpu()\n",
    "        std1_b = out1.std(dim=0).detach().cpu()\n",
    "        std_b = torch.cat((std0_b, std1_b), dim=-1)\n",
    "        outer_b = ((out.T @ out) / out.shape[0]).detach().cpu()\n",
    "\n",
    "        if self.layer2cov[label] is None:\n",
    "            self.layer2cov[label] = {}\n",
    "            self.layer2cov[label]['mean'] = torch.zeros_like(mean_b)\n",
    "            self.layer2cov[label]['std'] = torch.zeros_like(std_b)\n",
    "            self.layer2cov[label]['outer'] = torch.zeros_like(outer_b)\n",
    "        \n",
    "        self.layer2cov[label]['mean'] += mean_b / n\n",
    "        self.layer2cov[label]['std'] += std_b / n\n",
    "        self.layer2cov[label]['outer'] += outer_b / n\n",
    "    \n",
    "    def prepare_models(self, cov2update_modules, transformer, precomputed_merges=None):\n",
    "        layer2merges = {}\n",
    "        for layer, cov in self.layer2cov.items():\n",
    "            if precomputed_merges is None:\n",
    "                merge, unmerge = transformer(cov)\n",
    "                layer2merges[layer] = (merge, unmerge)\n",
    "            else:\n",
    "                layer2merges[layer] = precomputed_merges[layer]\n",
    "                merge, unmerge = precomputed_merges[layer]\n",
    "            output_modules = self.get_model_attributes(cov2update_modules[layer]['output'])\n",
    "            input_modules = self.get_model_attributes(cov2update_modules[layer]['input'])\n",
    "            self.transform_output_space(merge, output_modules)\n",
    "            self.transform_input_space(unmerge, input_modules)\n",
    "        \n",
    "        return layer2merges\n",
    "    \n",
    "    def get_model_attributes(self, components):\n",
    "        parameter_tuples = []\n",
    "        # getattr(getattr(getattr(modelc, 'layer1'), '0'), 'conv2')\n",
    "        for component in components['non_bn']:\n",
    "            edges = component.split('.')\n",
    "            node0 = getattr(self.model0, edges[0])\n",
    "            node1 = getattr(self.model1, edges[0])\n",
    "            for edge in edges[1:]:\n",
    "                node0 = getattr(node0, edge)\n",
    "                node1 = getattr(node1, edge)\n",
    "            parameter_tuples.append(\n",
    "                [node0.weight, node1.weight]\n",
    "            )\n",
    "        \n",
    "        if 'bn' in components:\n",
    "            for component in components['bn']:\n",
    "                edges = component.split('.')\n",
    "                node0 = getattr(self.model0, edges[0])\n",
    "                node1 = getattr(self.model1, edges[0])\n",
    "                for edge in edges[1:]:\n",
    "                    node0 = getattr(node0, edge)\n",
    "                    node1 = getattr(node1, edge)\n",
    "                parameter_tuples.append(\n",
    "                    [n.weight for n in [node0, node1]]\n",
    "                )\n",
    "                parameter_tuples.append(\n",
    "                    [n.bias for n in [node0, node1]]\n",
    "                )\n",
    "                parameter_tuples.append(\n",
    "                    [n.running_mean for n in [node0, node1]]\n",
    "                )\n",
    "                parameter_tuples.append(\n",
    "                    [n.running_var for n in [node0, node1]]\n",
    "                )\n",
    "        return parameter_tuples\n",
    "    \n",
    "    def transform_output_space(self, merge, list_of_modules):\n",
    "        a_w, b_w = (merge * 2).to(list_of_modules[0][0].device).chunk(2, dim=1)\n",
    "        for modules in list_of_modules:\n",
    "            a, b = modules[0], modules[1]\n",
    "            if len(a.shape) == 4:\n",
    "                t_a = torch.einsum('ab,bcde->acde', a_w, a)\n",
    "                t_b = torch.einsum('ab,bcde->acde', b_w, b)\n",
    "            else:\n",
    "                t_a = a_w @ a\n",
    "                t_b = b_w @ b\n",
    "            a.data = t_a\n",
    "            b.data = t_b\n",
    "\n",
    "    def transform_input_space(self, unmerge, list_of_modules):\n",
    "        a_w, b_w = unmerge.to(list_of_modules[0][0].device).chunk(2, dim=0)\n",
    "        for modules in list_of_modules:\n",
    "            a, b = modules[0], modules[1]\n",
    "            try:\n",
    "                if len(a.shape) == 4:\n",
    "                    a.data = torch.einsum('abcd,be->aecd', a, a_w)\n",
    "                    b.data = torch.einsum('abcd,be->aecd', b, b_w)\n",
    "                else:\n",
    "                    a.data = (a @ a_w)\n",
    "                    b.data = (b @ b_w)\n",
    "            except:\n",
    "                pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc7bbd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_layers = [\n",
    "    'layer1.0',\n",
    "    'layer1.1',\n",
    "    'layer1.2',\n",
    "    'layer2.0',\n",
    "    'layer2.1',\n",
    "    'layer2.2',\n",
    "    'layer3.0',\n",
    "    'layer3.1',\n",
    "    'layer3.2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "316ca44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov2update_modules = {\n",
    "    'layer1': {\n",
    "        'output': {\n",
    "            'non_bn': ['conv1', 'layer1.0.conv2', 'layer1.1.conv2', 'layer1.2.conv2'],\n",
    "            'bn': ['bn1', 'layer1.0.bn2', 'layer1.1.bn2', 'layer1.2.bn2']\n",
    "        },\n",
    "        'input': {\n",
    "            'non_bn': ['layer1.0.conv1', 'layer1.1.conv1', 'layer1.2.conv1', \n",
    "                     'layer2.0.conv1', 'layer2.0.shortcut.0'],\n",
    "        }\n",
    "    },\n",
    "    'layer2': {\n",
    "        'output': {\n",
    "            'non_bn': ['layer2.0.conv2', 'layer2.1.conv2', 'layer2.2.conv2', 'layer2.0.shortcut.0'],\n",
    "            'bn': ['layer2.0.bn2', 'layer2.1.bn2', 'layer2.2.bn2', 'layer2.0.shortcut.1']\n",
    "        },\n",
    "        'input': {\n",
    "            'non_bn': ['layer2.1.conv1', 'layer2.2.conv1', 'layer3.0.conv1', 'layer3.0.shortcut.0']\n",
    "        }\n",
    "    },\n",
    "    'layer3': {\n",
    "        'output': {\n",
    "            'non_bn': ['layer3.0.conv2', 'layer3.1.conv2', 'layer3.2.conv2', 'layer3.0.shortcut.0'],\n",
    "            'bn': ['layer3.0.bn2', 'layer3.1.bn2', 'layer3.2.bn2', 'layer3.0.shortcut.1']\n",
    "        },\n",
    "        'input': {\n",
    "            'non_bn': ['layer3.1.conv1', 'layer3.2.conv1', 'linear']\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "for layer_name in intermediate_layers:\n",
    "    cov2update_modules[layer_name] = {\n",
    "        'output': {\n",
    "            'non_bn': [f'{layer_name}.conv1'],\n",
    "            'bn': [f'{layer_name}.bn1']\n",
    "        },\n",
    "        'input': {\n",
    "            'non_bn': [f'{layer_name}.conv2']\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d78d9732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9558\n",
      "0.9726\n"
     ]
    }
   ],
   "source": [
    "model0 = resnet20(w=4, text_head=True).to(DEVICE)\n",
    "model1 = resnet20(w=4, text_head=True).to(DEVICE)\n",
    "load_model(model0, f'resnet20x4_CIFAR5_clses{model1_classes.tolist()}')\n",
    "load_model(model1, f'resnet20x4_CIFAR5_clses{model2_classes.tolist()}')\n",
    "print(evaluate_texthead(model0, test_loader1, class_vecs1, remap_class_idxs=class_idxs))\n",
    "print(evaluate_texthead(model1, test_loader2, class_vecs2, remap_class_idxs=class_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa5f3997",
   "metadata": {},
   "outputs": [],
   "source": [
    "spr20 = SinglePassResNet20(model0=model0, model1=model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "059c88ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [01:05<00:00,  1.53it/s]\n",
      "100%|██████████████████████████████████████████| 12/12 [00:00<00:00, 712.41it/s]\n"
     ]
    }
   ],
   "source": [
    "spr20.get_intermediate_scores(balanced_train_aug_loader, num_passes=1, num_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4c3d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2merges_ = spr20.prepare_models(\n",
    "    cov2update_modules, transformer=match_tensors_chain_cov # match_tensors_permute this runs the git rebasin.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "740db007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7421"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelc = resnet20(w=4, text_head=True).to(DEVICE)\n",
    "mix_weights(sd0=spr20.model0.state_dict(), sd1=spr20.model1.state_dict(), target=modelc, alpha=.5)\n",
    "modelc = modelc.to(DEVICE)\n",
    "reset_bn_stats(modelc, loader=train_aug_loader)\n",
    "acc, perclass_acc = evaluate_texthead(\n",
    "    modelc, test_loader, class_vectors=text_features, return_confusion=True\n",
    ")\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfcb0562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87\n",
      "0.9298\n"
     ]
    }
   ],
   "source": [
    "reset_bn_stats(spr20.model0, loader=train_aug_loader)\n",
    "reset_bn_stats(spr20.model1, loader=train_aug_loader)\n",
    "print(evaluate_texthead(spr20.model0, test_loader1, class_vecs1, remap_class_idxs=class_idxs))\n",
    "print(evaluate_texthead(spr20.model1, test_loader2, class_vecs2, remap_class_idxs=class_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888fb68f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7ceeeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates accuracy\n",
    "def evaluate_texthead(model, loader, class_vectors, remap_class_idxs=None, return_confusion=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    totals = [0] * class_vectors.shape[0]\n",
    "    corrects = [0] * class_vectors.shape[0]\n",
    "    \n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            encodings = model(inputs.to(DEVICE))\n",
    "            normed_encodings = encodings / encodings.norm(dim=-1, keepdim=True)\n",
    "            outputs = normed_encodings @ class_vectors.T\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            if remap_class_idxs is not None:\n",
    "                correct += (remap_class_idxs[labels].to(DEVICE) == pred).sum().item()\n",
    "            else:\n",
    "                for gt, p in zip(labels, pred):\n",
    "                    totals[gt] += 1\n",
    "                    \n",
    "                    if gt == p:\n",
    "                        correct += 1\n",
    "                        corrects[gt] += 1\n",
    "                \n",
    "            total += inputs.shape[0]\n",
    "    if return_confusion:\n",
    "        return correct / sum(totals), list(map(lambda a: a[0] / a[1], zip(corrects, totals)))\n",
    "    else:\n",
    "        return correct / total\n",
    "\n",
    "def evaluate_ensemble(\n",
    "    modela,\n",
    "    modelb,\n",
    "    loader, \n",
    "    class_vectors, \n",
    "    remap_class_idxs=None,\n",
    "    return_confusion=False\n",
    "):\n",
    "    modela.eval()\n",
    "    modelb.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    totals = [0] * class_vectors.shape[0]\n",
    "    corrects = [0] * class_vectors.shape[0]\n",
    "    with torch.no_grad(), autocast():\n",
    "        for inputs, labels in loader:\n",
    "            encoding_a = modela(inputs.to(DEVICE))\n",
    "            encoding_b = modelb(inputs.to(DEVICE))\n",
    "            \n",
    "            normed_encodings_a = encoding_a / encoding_a.norm(dim=-1, keepdim=True)\n",
    "            outputs_a = normed_encodings_a @ class_vectors.T\n",
    "            \n",
    "            normed_encodings_b = encoding_b / encoding_b.norm(dim=-1, keepdim=True)\n",
    "            outputs_b = normed_encodings_b @ class_vectors.T\n",
    "            \n",
    "            preda_score, preda_idx = outputs_a.max(dim=1)\n",
    "            predb_score, predb_idx = outputs_b.max(dim=1)\n",
    "            pred = preda_idx\n",
    "            pred[preda_score < predb_score] = predb_idx[preda_score < predb_score]# + (num_classes // 2)\n",
    "            \n",
    "            if remap_class_idxs is not None:\n",
    "                correct += (remap_class_idxs[labels].to(DEVICE) == pred).sum().item()\n",
    "            else:\n",
    "                for gt, p in zip(labels, pred):\n",
    "                    totals[gt] += 1\n",
    "                    \n",
    "                    if gt == p:\n",
    "                        correct += 1\n",
    "                        corrects[gt] += 1\n",
    "                \n",
    "            total += inputs.shape[0]\n",
    "    if return_confusion:\n",
    "        return correct / sum(totals), list(map(lambda a: a[0] / a[1], zip(corrects, totals)))\n",
    "    else:\n",
    "        return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfc044e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = evaluate_ensemble(\n",
    "    spr20.model0, spr20.model1, test_loader, class_vectors=text_features, return_confusion=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e752161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3839"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b12b61a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "george-37-v3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "357a9754b3f9b43d18b25b66e5e92e883fce00c7f4cc1e64fb26a5d9fc9bfab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
